<!DOCTYPE html>
<html lang="en"><head>
<link href="../favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Dr.&nbsp;Silvio Fanzon">
  <title>Statistical Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
  <script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
  <script src="../site_libs/plotly-binding-4.10.4/plotly.js"></script>
  <script src="../site_libs/typedarray-0.1/typedarray.min.js"></script>
  <script src="../site_libs/jquery-3.5.1/jquery.min.js"></script>
  <link href="../site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
  <script src="../site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
  <link href="../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
  <script src="../site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <style>
  .TODO {
    --color1: #e7b1b4;
    --color2: #8c3236;
  }
  .Question {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Conjecture {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .DONE {
    --color1: #cce7b1;
    --color2: #86b754;
  }
  .Axiom {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Notation {
    --color1: #c6e6ed;
    --color2: #1995ad;
  }
  .Theorem {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Remark {
    --color1: #bce5de;
    --color2: #21aa93;
  }
  .Example {
    --color1: #bce5de;
    --color2: #21aa93;
  }
  .Idea {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Important {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Lemma {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Problem {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Proposition {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Corollary {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Warning {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Proof {
    --color1: #f1f1f2;
    --color2: #c0c0c1;
  }
  .Definition {
    --color1: #c6e6ed;
    --color2: #1995ad;
  }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Statistical Models</h1>
  <p class="subtitle">Lecture 8</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<a href="https://www.silviofanzon.com">Dr.&nbsp;Silvio Fanzon</a> 
</div>
<div class="quarto-title-author-email">
<a href="mailto:S.Fanzon@hull.ac.uk">S.Fanzon@hull.ac.uk</a>
</div>
        <p class="quarto-title-affiliation">
            University of Hull
          </p>
    </div>
</div>

</section>
<section>
<section id="lecture-8-the-maths-of-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Lecture 8: <br>The Maths of <br>Regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="outline-of-lecture-8" class="slide level2">
<h2>Outline of Lecture 8</h2>
<ol type="1">
<li>Simple linear regression</li>
<li>General linear regression</li>
<li>Simple regression as general regression</li>
<li>Multiple linear regression</li>
<li>Coefficient of determination <span class="math inline">R^2</span></li>
<li>Example of multiple regression</li>
<li>Two sample t-test as general regression</li>
</ol>
</section></section>
<section>
<section id="part-1-simple-linear-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 1: <br>Simple linear<br>regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="simple-linear-regression-motivation" class="slide level2 smaller">
<h2>Simple linear regression: Motivation</h2>
<ul>
<li><p><strong>Model:</strong> Suppose given two random variables <span class="math inline">X</span> and <span class="math inline">Y</span></p>
<div class="column" style="width:48%;">
<ul>
<li><span class="math inline">X</span> models <em>observed values</em></li>
</ul>
</div><div class="column" style="width:48%;">
<ul>
<li><span class="math inline">Y</span> models a <em>response</em></li>
</ul>
</div></li>
<li><p><strong>Goal of Regression:</strong> Learn (approximate) the conditional distribution <span class="math display">
Y | X
</span></p>
<ul>
<li><span class="math inline">Y | X</span> allows to predict values of <span class="math inline">Y</span> from values of <span class="math inline">X</span></li>
<li>To determine <span class="math inline">Y|X</span>, we need the <strong>joint distribution</strong> of <span class="math inline">(X,Y)</span></li>
</ul></li>
<li><p><strong>Problem:</strong> The joint distribution of <span class="math inline">(X,Y)</span> is <strong>unknown</strong>. We have partial knowledge in the form of paired observations <span class="math display">
(x_1,y_1) , \ldots, (x_n,y_n) \quad \text{ observed from } \quad (X,Y)
</span></p></li>
<li><p><strong>Goal:</strong> Use the observations (data) to learn <span class="math inline">Y|X</span></p></li>
</ul>
</section>
<section id="why-not-just-use-least-squares" class="slide level2 smaller">
<h2>Why not just use Least-Squares?</h2>
<div class="column" style="width:50%;">
<p><strong>Least-Squares:</strong></p>
<ul>
<li><p>Naive solution to regression problem</p></li>
<li><p>Find a line of best fit <span class="math display">
y = \hat \alpha + \hat \beta x
</span></p></li>
<li><p>Such line explains the data, i.e., <span class="math display">
y_i \approx \hat{y}_i \,, \qquad \hat{y}_i = \hat \alpha + \hat \beta x_i
</span></p></li>
</ul>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_8_files/figure-revealjs/unnamed-chunk-1-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="why-not-just-use-least-squares-1" class="slide level2 smaller">
<h2>Why not just use Least-Squares?</h2>
<div class="column" style="width:50%;">
<p><strong>Drawbacks of least squares:</strong></p>
<ul>
<li><p>Only predicts values of <span class="math inline">y</span> such that <span class="math display">
(x,y)  \, \in \, \text{ Line}
</span></p></li>
<li><p>Ignores that <span class="math inline">(x_i,y_i)</span> come from joint distribution <span class="math inline">(X,Y)</span></p></li>
<li><p>We don’t have meaningful estimates for the error (residuals) <span class="math display">
\varepsilon_i = y_i - \hat{y}_i \,, \qquad \hat{y}_i = \hat \alpha + \hat \beta x_i
</span></p></li>
</ul>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_8_files/figure-revealjs/unnamed-chunk-2-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="linear-regression-instead-of-least-squares" class="slide level2 smaller">
<h2>Linear Regression instead of Least Squares</h2>
<div class="column" style="width:50%;">
<p><strong>Linear Regression:</strong></p>
<ul>
<li><p>Find a <strong>regression line</strong> <span class="math display">
R(x) = \alpha + \beta x
</span></p></li>
<li><p><span class="math inline">R(x)</span> predicts <strong>most likely</strong> value of <span class="math inline">Y</span> when <span class="math inline">X = x</span></p></li>
<li><p>We will see that regression line coincides with line of best fit <span class="math display">
R(x) = \hat \alpha + \hat \beta x
</span></p></li>
<li><p><strong>Regression gives statistical meaning to Least Squares</strong></p></li>
</ul>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_8_files/figure-revealjs/unnamed-chunk-3-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="regression-function" class="slide level2 smaller">
<h2>Regression function</h2>
<h3 id="definition">Definition</h3>
<p>Suppose given two random variables <span class="math inline">X</span> and <span class="math inline">Y</span></p>
<div class="column" style="width:30%;">
<ul>
<li><span class="math inline">X</span> is the <strong>predictor</strong></li>
</ul>
</div><div class="column" style="width:49%;">
<ul>
<li><span class="math inline">Y</span> is the <strong>response</strong></li>
</ul>
</div><div id="Definition*-2.1" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The <strong>regression function</strong> of <span class="math inline">Y</span> on <span class="math inline">X</span> is the conditional expectation<p></p>
<p><span class="math display">
R \colon \mathbb{R}\to \mathbb{R}\,, \qquad \quad R(x) :=  {\rm I\kern-.3em E}[Y | X = x]
</span></p>
</div></details>
</div>
</section>
<section id="regression-function-1" class="slide level2 smaller">
<h2>Regression function</h2>
<h3 id="interpretation">Interpretation</h3>
<div id="Idea*-2.2" class="Idea">
<p></p><details class="Idea fbx-simplebox fbx-default" open=""><summary><strong>Idea</strong></summary><div>The regression function <span class="math display">
R(x) = {\rm I\kern-.3em E}[Y | X = x]
</span> predicts the most likely value of <span class="math inline">Y</span> when we observe <span class="math display">
X = x
</span><p></p>
</div></details>
</div>
<p><strong>Notation:</strong> We use the shorthand <span class="math display">
{\rm I\kern-.3em E}[Y|x] := {\rm I\kern-.3em E}[Y | X = x]
</span></p>
</section>
<section id="the-regression-problem" class="slide level2 smaller">
<h2>The regression problem</h2>
<p><strong>Assumption:</strong> Suppose given <span class="math inline">n</span> observations <span class="math inline">(x_1,y_1) \,, \ldots , (x_n, y_n)</span></p>
<div class="column" style="width:38%;">
<ul>
<li><span class="math inline">x_i</span> observed from <span class="math inline">X</span></li>
</ul>
</div><div class="column" style="width:48%;">
<ul>
<li><span class="math inline">y_i</span> observed from <span class="math inline">Y</span></li>
</ul>
</div><div id="Problem*-2.3" class="Problem">
<p></p><details class="Problem fbx-simplebox fbx-default" open=""><summary><strong>Problem</strong></summary><div>From <span class="math inline">(x_1,y_1) \,, \ldots , (x_n, y_n)</span>, learn a regression function <span class="math display">
R(x) = {\rm I\kern-.3em E}[Y | x]
</span> which explains the observations, that is, such that <span class="math display">
R(x_i) = {\rm I\kern-.3em E}[Y | x_i] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
</span><p></p>
</div></details>
</div>
<p><strong>Remember: We don’t know <span class="math inline">X</span> and <span class="math inline">Y</span></strong></p>
</section>
<section id="simple-linear-regression" class="slide level2 smaller">
<h2>Simple linear regression</h2>
<ul>
<li><p>Regression problem is difficult without prior knowledge on <span class="math inline">{\rm I\kern-.3em E}[Y | x]</span></p></li>
<li><p>A popular model is to assume that <span class="math inline">{\rm I\kern-.3em E}[Y | x]</span> is linear</p></li>
</ul>
<div id="Definition*-2.4" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The regression function of <span class="math inline">Y</span> on <span class="math inline">X</span> is <strong>linear</strong> if there exist <span class="math inline">\alpha</span> and <span class="math inline">\beta</span> s.t. <span class="math display">
{\rm I\kern-.3em E}[Y | x] = \alpha +  \beta x  \,, \qquad \forall \, x \in \mathbb{R}
</span><p></p>
</div></details>
</div>
<ul>
<li><p><span class="math inline">\alpha</span> and <span class="math inline">\beta</span> are called <strong>regression coefficients</strong></p></li>
<li><p>The above regression is called <strong>simple</strong> because only 2 variables are involved</p></li>
</ul>
</section>
<section id="what-do-we-mean-by-linear" class="slide level2 smaller">
<h2>What do we mean by linear?</h2>
<p>We said that the regression is <strong>linear</strong> if <span class="math display">
{\rm I\kern-.3em E}[Y | x ] = \alpha + \beta x
</span> Linearity in intended wrt the parameters <span class="math inline">\alpha</span> and <span class="math inline">\beta</span></p>
<p><strong>Examples:</strong></p>
<ul>
<li><p>Linear regression of <span class="math inline">Y</span> on <span class="math inline">X^2</span> is <span class="math display">
{\rm I\kern-.3em E}[Y | x^2 ] = \alpha + \beta x^2
</span></p></li>
<li><p>Linear regression of <span class="math inline">\log Y</span> on <span class="math inline">1/X</span> is <span class="math display">
{\rm I\kern-.3em E}[ \log Y | x ] = \alpha + \beta \frac{1}{ x }
</span></p></li>
</ul>
</section>
<section id="simple-linear-regression-1" class="slide level2 smaller">
<h2>Simple linear regression</h2>
<h3 id="model-assumptions">Model Assumptions</h3>
<p>Suppose given <span class="math inline">n</span> observations <span class="math inline">(x_1,y_1) \,, \ldots , (x_n, y_n)</span></p>
<div class="column" style="width:38%;">
<ul>
<li><span class="math inline">x_i</span> observed from <span class="math inline">X</span></li>
</ul>
</div><div class="column" style="width:48%;">
<ul>
<li><span class="math inline">y_i</span> observed from <span class="math inline">Y</span></li>
</ul>
</div><div id="Definition*-2.5" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>For each <span class="math inline">i = 1 , \ldots, n</span>, we denote by <span class="math inline">Y_i</span> a random variable with distribution <span class="math display">
Y | X = x_i
</span><p></p>
</div></details>
</div>
</section>
<section id="section" class="slide level2 smaller">
<h2></h2>
<p><strong>Model Assumptions:</strong> Recall, <span class="math inline">Y_i</span> is distributed like <span class="math inline">Y | X = x_i</span></p>
<ol type="1">
<li><p><strong>Predictor is known:</strong> The values <span class="math inline">x_1, \ldots, x_n</span> are known</p></li>
<li><p><strong>Normality:</strong> The conditional distribution <span class="math inline">Y_i</span> is normal</p></li>
<li><p><strong>Linear mean:</strong> There are parameters <span class="math inline">\alpha</span> and <span class="math inline">\beta</span> such that <span class="math display">
{\rm I\kern-.3em E}[Y_i] = \alpha + \beta x_i   \,, \qquad \forall \, i = 1, \ldots, n
</span></p></li>
<li><p><strong>Common variance (Homoscedasticity):</strong> There is a parameter <span class="math inline">\sigma^2</span> such that <span class="math display">
{\rm Var}[Y_i] = \sigma^2 \,, \qquad \forall \, i = 1, \ldots, n
</span></p></li>
<li><p><strong>Independence:</strong> The random variables <span class="math display">
Y_1   \,, \ldots \,, Y_n
</span> are independent</p></li>
</ol>
</section>
<section id="characterization-of-the-model" class="slide level2 smaller">
<h2>Characterization of the Model</h2>
<ul>
<li>Assumptions 1–5 look quite abstract</li>
<li>The following Proposition gives a handy characterization</li>
</ul>
<div id="Proposition*-2.6" class="Proposition">
<p></p><details class="Proposition fbx-simplebox fbx-default" open=""><summary><strong>Proposition</strong></summary><div>Assumptions 1-5 are satisfied if and only if <span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i
</span> for some random variables <span class="math display">
\varepsilon_1 , \ldots, \varepsilon_n  \,\, \text{ iid } \,\, N(0,\sigma^2)
</span><p></p>
</div></details>
</div>
<ul>
<li>The terms <span class="math inline">\varepsilon_i</span> are called <strong>errors</strong> or <strong>residuals</strong></li>
</ul>
</section>
<section id="proof" class="slide level2 smaller">
<h2>Proof</h2>
<ul>
<li><p>By Assumption 2, we have that <span class="math inline">Y_i</span> is normal</p></li>
<li><p>By Assumptions 3-4, we have <span class="math display">
{\rm I\kern-.3em E}[Y_i] = \alpha + \beta x_i \,, \qquad \quad
{\rm Var}[Y_i] = \sigma^2
</span></p></li>
<li><p>Therefore <span class="math inline">\, Y_i  \sim  N(\alpha + \beta x_i, \sigma^2)</span></p></li>
<li><p>Define the random variables <span class="math inline">\varepsilon_i</span> by <span class="math display">
\varepsilon_i := Y_i   -  (\alpha + \beta x_i)  \quad \qquad \left( \text{which implies } \,\,
Y_i   =  \alpha + \beta x_i + \varepsilon_i \right)
</span></p></li>
<li><p>By Assumption 5, we have that <span class="math inline">Y_1,\ldots,Y_n</span> are independent</p></li>
<li><p>Therefore <span class="math inline">\varepsilon_1,\ldots, \varepsilon_n</span> are independent</p></li>
<li><p>Since <span class="math inline">Y_i  \sim  N(\alpha + \beta x_i, \sigma^2)</span>, we conclude that <span class="math inline">\varepsilon_i</span> are iid <span class="math inline">N(0,\sigma^2)</span></p></li>
<li><p>Therefore, <span class="math inline">Y_i   =  \alpha + \beta x_i + \varepsilon_i</span> with <span class="math inline">\varepsilon_i</span> iid <span class="math inline">N(0,\sigma^2) \qquad \qquad \qquad \qquad \quad  \qquad  \square</span></p></li>
</ul>
</section>
<section id="likelihood-function" class="slide level2 smaller">
<h2>Likelihood function</h2>
<div style="font-size: 0.92em">
<p>Let <span class="math inline">X_1, \ldots, X_n</span> be continuous rv with joint pdf <span class="math display">
f = f(x_1, \ldots, x_n | \theta) \,, \qquad \theta \in \Theta \,\, \, \text{ parameter}
</span></p>
<div class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The likelihood function of <span class="math inline">(X_1, \ldots, X_n)</span> for a given sample <span class="math inline">(x_1, \ldots, x_n)</span> is <span class="math display">
L \colon \Theta \to \mathbb{R}\,, \qquad \quad L(\theta | x_1,\ldots, x_n ) := f(x_1, \ldots, x_n | \theta)
</span><p></p>
</div></details>
</div>
<div class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose Assumptions 1–5 hold. The likelihood function of <span class="math inline">(Y_1,\ldots,Y_n)</span> is<p></p>
<p><span class="math display">
L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n ) = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \Bigg(   -\frac{\sum_{i=1}^n(y_i-\alpha - \beta x_i)^2}{2\sigma^2}      \Bigg)
</span></p>
</div></details>
</div>
</div>
</section>
<section id="proof-1" class="slide level2 smaller">
<h2>Proof</h2>
<div style="font-size: 0.92em">
<ul>
<li><p>By the Assumptions, we have <span class="math inline">Y_i \sim N( \alpha + \beta x_i , \sigma^2 )</span></p></li>
<li><p>Therefore, the pdf of <span class="math inline">Y_i</span> is <span class="math display">
f_{Y_i} (y_i) =  \frac{1}{\sqrt{2\pi \sigma^2}} \exp \Bigg( -\frac{(y_i-\alpha-\beta{x_i})^2}{2\sigma^2} \Bigg)
</span></p></li>
<li><p>Since <span class="math inline">Y_1,\ldots, Y_n</span> are independent, we obtain <span class="math display">\begin{align*}
L(\alpha,\beta, \sigma^2 | y_1, \ldots,y_n) &amp; = f(y_1,\ldots,y_n)
                                 = \prod_{i=1}^n f_{Y_i}(y_i)  \\
                                &amp; = \prod_{i=1}^n
                                \frac{1}{\sqrt{2\pi \sigma^2}} \exp \Bigg( -\frac{(y_i-\alpha-\beta{x_i})^2}{2\sigma^2} \Bigg) \\
                                &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp  \Bigg(   -\frac{\sum_{i=1}^n(y_i- \alpha - \beta x_i)^2}{2\sigma^2}     \Bigg) \qquad \qquad \square
\end{align*}</span></p></li>
</ul>
</div>
</section>
<section id="model-summary" class="slide level2 smaller">
<h2>Model Summary</h2>
<ul>
<li><p>Simple linear regression of <span class="math inline">Y</span> on <span class="math inline">X</span> is the function <span class="math display">
{\rm I\kern-.3em E}[Y | x] = \alpha + \beta x
</span></p></li>
<li><p>Suppose given <span class="math inline">n</span> observations <span class="math inline">(x_1,y_1) \,, \ldots , (x_n, y_n)</span></p>
<div class="column" style="width:54%;">
<ul>
<li><span class="math inline">x_i</span> observed from <span class="math inline">X</span></li>
</ul>
</div><div class="column" style="width:46%;">
<ul>
<li><span class="math inline">y_i</span> observed from <span class="math inline">Y</span></li>
</ul>
</div></li>
<li><p>Denote by <span class="math inline">Y_i</span> the random variable <span class="math inline">Y | X = x_i</span></p></li>
<li><p>We suppose that <span class="math inline">Y_i</span> has the form <span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i \,, \qquad \varepsilon_i \, \text{ iid } \, N(0,\sigma^2)
</span></p></li>
<li><p>In particular <span class="math display">{\rm I\kern-.3em E}[Y|x_i] = {\rm I\kern-.3em E}[Y_i] = \alpha + \beta x_i</span></p></li>
</ul>
</section>
<section id="the-linear-regression-problem" class="slide level2 smaller">
<h2>The linear regression problem</h2>
<div id="Problem*-2.7" class="Problem">
<p></p><details class="Problem fbx-simplebox fbx-default" open=""><summary><strong>Problem</strong></summary><div>Given observations <span class="math inline">(x_1,y_1) \,, \ldots , (x_n, y_n)</span>, learn a linear regression function <span class="math display">
{\rm I\kern-.3em E}[Y | x] = \alpha + \beta x
</span> which explains the observations, that is, such that <span class="math display">\begin{equation} \tag{1}
{\rm I\kern-.3em E}[Y_i] = {\rm I\kern-.3em E}[Y | x_i] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
\end{equation}</span><p></p>
</div></details>
</div>
<div id="Question*-2.8" class="Question">
<p></p><details class="Question fbx-simplebox fbx-default" open=""><summary><strong>Question</strong></summary><div>How do we enforce (1)?<p></p>
</div></details>
</div>
</section>
<section id="section-1" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.88em">
<p><strong>Answer:</strong> Recall condition (1) from previous slide <span class="math display">\begin{equation} \tag{1}
{\rm I\kern-.3em E}[Y_i] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
\end{equation}</span></p>
<ul>
<li><p>If we want (1) to hold, we need to maximize the joint probability <span class="math display">\begin{equation}\tag{P}
P(Y_1 \approx y_1, \ldots, Y_n \approx y_n) =
\int_{A} f(y) \, dy \approx |A| f(y)
\end{equation}</span></p>
<ul>
<li>where <span class="math inline">f</span> is the joint pdf of <span class="math inline">(Y_1,\ldots, Y_n)</span></li>
<li><span class="math inline">A</span> is (small) open set in <span class="math inline">\mathbb{R}^n</span> containing the observations <span class="math inline">(y_1,\ldots,y_n)</span></li>
<li>|A| is the <span class="math inline">n</span>-dimensional volume of <span class="math inline">A</span></li>
</ul></li>
<li><p>To maximize the probability, by (P), it is enough to maximize <span class="math inline">f(y_1,\ldots,y_n)</span></p></li>
<li><p>Therefore, choose parameters <span class="math inline">\hat \alpha, \hat \beta, \hat \sigma</span> which <strong>maximize the likelihood function</strong> <span class="math display">
\max_{\alpha,\beta,\sigma} f(y_1,\ldots,y_n | \alpha,\beta, \sigma^2) = \max_{\alpha,\beta,\sigma} \ L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n )
</span> <strong>Maximum Likelihood Estimation:</strong> Find parameters that maximize the Likelihood, and so (P)</p></li>
</ul>
</div>
</section>
<section id="maximum-likelihood-estimation" class="slide level2 smaller">
<h2>Maximum Likelihood Estimation</h2>
<div style="font-size: 0.94em">
<div class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose Assumptions 1–5 hold. Assume given <span class="math inline">n</span> observations <span class="math inline">(x_1,y_1), \ldots, (x_n,y_n)</span>. The maximization problem <span class="math display">
\max_{\alpha,\beta,\sigma}  \ L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n )
</span> admits the unique solution <span class="math display">
\hat \alpha = \overline{y} - \hat  \beta \, \overline{x} \,, \qquad
\hat \beta = \frac{S_{xy}}{S_{xx}} \,, \qquad
\hat{\sigma}^2  = \frac{1}{n} \sum_{i=1}^n \left(  y_i - \hat \alpha - \hat \beta x_i  \right)^2
</span><p></p>
</div></details>
</div>
<ul>
<li><p>The constants <span class="math inline">\hat \alpha, \hat \beta, \hat{\sigma}^2</span> are called <em>Maximum Likelihood Estimators (MLE)</em></p></li>
<li><p><strong>Important:</strong> <span class="math inline">\hat \alpha</span> and <span class="math inline">\hat \beta</span> are the Least Squares coefficients!</p></li>
</ul>
</div>
</section>
<section id="proof-of-theorem" class="slide level2 smaller">
<h2>Proof of Theorem</h2>
<ul>
<li><p>The <span class="math inline">\log</span> function is strictly increasing. Therefore <span class="math display">
\max_{\alpha,\beta,\sigma} \ L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n ) \quad \text{ is equivalent to } \quad
\max_{\alpha,\beta,\sigma} \ \log L( \alpha,\beta, \sigma^2 | y_1, \ldots, y_n )
</span></p></li>
<li><p>Recall that the likelihood is <span class="math display">
L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n ) =  \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   - \frac{\sum_{i=1}^n(y_i-\alpha - \beta x_i)^2}{2\sigma^2}      \right)
</span></p></li>
<li><p>Hence the log–likelihood is <span class="math display">
\log L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n )
= - \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \sum_{i=1}^n(y_i-\alpha - \beta x_i)^2 }{2 \sigma^2}
</span></p></li>
</ul>
</section>
<section id="section-2" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Suppose first that <span class="math inline">\sigma</span> is fixed. In this case the problem <span class="math display">
\max_{\alpha,\beta} \ \left\{ \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \sum_{i=1}^n(y_i-\alpha - \beta x_i)^2 }{2 \sigma^2} \right\}
</span> is equivalent to <span class="math display">
\min_{\alpha, \beta} \ \sum_{i=1}^n(y_i-\alpha - \beta x_i)^2
</span></p></li>
<li><p>This is the Least Squares problem! Hence the solution is <span class="math display">
\hat \alpha = \overline{y} - \hat  \beta \, \overline{x} \,, \qquad
\hat \beta = \frac{S_{xy}}{S_{xx}}
</span></p></li>
</ul>
</section>
<section id="section-3" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Substituting <span class="math inline">\hat \alpha</span> and <span class="math inline">\hat \beta</span> we obtain <span class="math display">\begin{align*}
\max_{\alpha,\beta,\sigma} \ &amp; \log L(\alpha,\beta, \sigma^2 | y_1, \ldots, y_n )
= \max_{\sigma} \ \log L(\hat \alpha, \hat \beta, \sigma^2 | y_1, \ldots, y_n ) \\[10pt]
&amp; = \max_{\sigma} \ \left\{ - \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \sum_{i=1}^n(y_i-\hat\alpha - \hat\beta x_i)^2 }{2 \sigma^2}  \right\}
\end{align*}</span></p></li>
<li><p>The above is a one-dimensional minimization problem in <span class="math inline">\sigma</span></p></li>
<li><p>Taking the first order derivative wrt <span class="math inline">\sigma</span>, it can be shown the unique solution is <span class="math display">
\hat{\sigma}^2  = \frac{1}{n} \sum_{i=1}^n \left(  y_i - \hat \alpha - \hat \beta x_i  \right)^2
</span></p></li>
<li><p>This concludes the proof</p></li>
</ul>
</section>
<section id="least-squares-vs-linear-regression" class="slide level2 smaller">
<h2>Least-squares vs Linear regression</h2>
<div style="font-size: 0.94em">
<p>Linear regression and least-squares give seemingly the same answer</p>
<div class="column" style="width:73%;">
<table class="caption-top">
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Least-squares line</strong></th>
<th style="text-align: left;"><span class="math inline">y = \hat \alpha + \hat \beta x</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Linear regression line</strong></td>
<td style="text-align: left;"><span class="math inline">{\rm I\kern-.3em E}[Y | x ] =  \hat \alpha + \hat \beta x</span></td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:25%;">

</div><p><strong>Question:</strong> Why did we define regression if it gives same answer as least-squares?</p>
<p><strong>Answer:</strong> There is actually a big difference</p>
<ul>
<li>Least-squares line <span class="math inline">y = \hat \alpha + \hat \beta x</span> is just a geometric object
<ul>
<li>We don’t have meaningful estimates for the error (residuals) <span class="math display">
\varepsilon_i = y_i - \hat{y_i} \,, \qquad  \hat{y}_i = \hat \alpha + \hat \beta_n
</span></li>
</ul></li>
<li>Regression line <span class="math inline">{\rm I\kern-.3em E}[Y | x ] =  \hat \alpha + \hat \beta x</span> is Statistical model for <span class="math inline">Y|X</span>
<ul>
<li>Can quantify in probability how well the linear model fits the data</li>
</ul></li>
</ul>
</div>
</section></section>
<section>
<section id="part-2-general-linear-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 2: <br>General linear<br>regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="simple-vs-general-regression" class="slide level2 smaller">
<h2>Simple vs General regression</h2>
<p><strong>Simple regression:</strong> Response variable <span class="math inline">Y</span> depends on one predictor <span class="math inline">X</span></p>
<ul>
<li><p>The goal is to learn the distribution of</p>
<p><span class="math display">
Y | X
</span></p></li>
<li><p><span class="math inline">Y | X</span> allows to predict values of <span class="math inline">Y</span>, knowing values of <span class="math inline">X</span></p></li>
</ul>
<p><strong>General regression:</strong> Response variable <span class="math inline">Y</span> depends on <span class="math inline">p</span> predictors <span class="math inline">Z_1 , \ldots,  Z_p</span></p>
<ul>
<li><p>The goal is to learn the distribution of <span class="math display">
Y | Z_1, \ldots, Z_p
</span></p></li>
<li><p><span class="math inline">Y | Z_1 , \dots, Z_p</span> allows to predict values of <span class="math inline">Y</span>, knowing values of <span class="math inline">Z_1 , \dots, Z_p</span></p></li>
</ul>
</section>
<section id="general-regression-function" class="slide level2 smaller">
<h2>General regression function</h2>
<p>Suppose given random variables <span class="math inline">Z_1 , \ldots, Z_p</span> and <span class="math inline">Y</span></p>
<div class="column" style="width:45%;">
<ul>
<li><span class="math inline">Z_1,\ldots, Z_p</span> are the <strong>predictors</strong></li>
</ul>
</div><div class="column" style="width:49%;">
<ul>
<li><span class="math inline">Y</span> is the <strong>response</strong></li>
</ul>
</div><p><strong>Notation:</strong> We denote points of <span class="math inline">\mathbb{R}^p</span> by <span class="math display">
z = (z_1, \ldots, z_p)
</span></p>
<div id="Definition*-3.1" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The <strong>regression function</strong> of <span class="math inline">Y</span> on <span class="math inline">Z_1,\ldots,Z_p</span> is the conditional expectation<p></p>
<p><span class="math display">
R \colon \mathbb{R}^p \to \mathbb{R}\,, \qquad \quad R(z) :=  {\rm I\kern-.3em E}[Y | Z_1 = z_1, \ldots , Z_p = z_p]
</span></p>
</div></details>
</div>
</section>
<section id="general-regression-function-1" class="slide level2 smaller">
<h2>General regression function</h2>
<div id="Idea*-3.2" class="Idea">
<p></p><details class="Idea fbx-simplebox fbx-default" open=""><summary><strong>Idea</strong></summary><div>The regression function <span class="math display">
R(z) =  {\rm I\kern-.3em E}[Y | Z_1 = z_1, \ldots , Z_p = z_p]
</span> predicts the most likely value of <span class="math inline">Y</span> when we observe <span class="math display">
Z_1 = z_1, \,\,\ldots , \,\, Z_p = z_p
</span><p></p>
</div></details>
</div>
<p><strong>Notation</strong>: We use the shorthand <span class="math display">
{\rm I\kern-.3em E}[Y | z_1, \ldots, z_p] := {\rm I\kern-.3em E}[Y | Z_1 = z_1, \ldots , Z_p = z_p]
</span></p>
</section>
<section id="the-general-regression-problem" class="slide level2 smaller">
<h2>The general regression problem</h2>
<p><strong>Assumption:</strong> For each <span class="math inline">i =1 , \ldots, n</span> we assume given observations</p>
<div class="column" style="width:42%;">
<ul>
<li>data point <span class="math inline">(z_{i1}, \ldots, z_{ip}, y_i)</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">z_{ij}</span> is from <span class="math inline">Z_j</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">y_i</span> is from <span class="math inline">Y</span></li>
</ul>
</div><div id="Problem*-3.3" class="Problem">
<p></p><details class="Problem fbx-simplebox fbx-default" open=""><summary><strong>Problem</strong></summary><div>From the above data, learn a regression function <span class="math display">
R(z) = {\rm I\kern-.3em E}[Y | z_1, \ldots, z_p]
</span> which explains the observations, that is, such that <span class="math display">
{\rm I\kern-.3em E}[Y | z_{i1}, \ldots, z_{ip}] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
</span><p></p>
</div></details>
</div>
</section>
<section id="general-linear-regression" class="slide level2 smaller">
<h2>General linear regression</h2>
<p><strong>Key assumption:</strong> The regression function <span class="math inline">R(z) = {\rm I\kern-.3em E}[Y | z_1, \ldots, z_p]</span> is <strong>linear</strong></p>
<div id="Definition*-3.4" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The regression of <span class="math inline">Y</span> on <span class="math inline">Z_1 , \ldots, Z_p</span> is <strong>linear</strong> if there exist <span class="math inline">\beta_1, \ldots, \beta_p</span> s.t.<p></p>
<p><span class="math display">
{\rm I\kern-.3em E}[Y | z_1, \ldots, z_p] =  \beta_1 z_1 + \ldots + \beta_p z_p  \,, \quad \forall \, z \in \mathbb{R}^p
</span></p>
<p><span class="math inline">\beta_1, \ldots, \beta_p</span> are called <strong>regression coefficients</strong></p>
</div></details>
</div>
<p><strong>Note:</strong></p>
<ul>
<li><p>In simple regression we have 2 coefficients <span class="math inline">\alpha</span> and <span class="math inline">\beta</span></p></li>
<li><p>In multiple regression we have <span class="math inline">p</span> coefficients <span class="math inline">\beta_1, \ldots, \beta_p</span></p></li>
</ul>
</section>
<section id="general-linear-regression-1" class="slide level2 smaller">
<h2>General linear regression</h2>
<h3 id="model-assumptions-1">Model Assumptions</h3>
<p>For each <span class="math inline">i =1 , \ldots, n</span> we assume given</p>
<div class="column" style="width:42%;">
<ul>
<li>data point <span class="math inline">(z_{i1}, \ldots, z_{ip}, y_i)</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">z_{ij}</span> is from <span class="math inline">Z_j</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">y_i</span> is from <span class="math inline">Y</span></li>
</ul>
</div><div id="Definition*-3.5" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>For each <span class="math inline">i = 1, \ldots, n</span>, we denote by <span class="math inline">Y_i</span> a random variable with distribution <span class="math display">
Y | Z_1 = z_{i1} , \ldots, Z_p = z_{ip}
</span><p></p>
</div></details>
</div>
</section>
<section id="section-4" class="slide level2 smaller">
<h2></h2>
<p><strong>Model Assumptions:</strong> Recall, <span class="math inline">Y_i</span> is distributed like <span class="math inline">Y | Z_1 = z_{i1} , \ldots, Z_p = z_{ip}</span></p>
<ol type="1">
<li><p><strong>Predictor is known:</strong> The values <span class="math inline">z_{i1}, \ldots, z_{ip}</span> are known</p></li>
<li><p><strong>Normality:</strong> The conditional distribution <span class="math inline">Y_i</span> is normal</p></li>
<li><p><strong>Linear mean:</strong> There are parameters <span class="math inline">\beta_1,\ldots,\beta_p</span> such that <span class="math display">
{\rm I\kern-.3em E}[Y_i] = \beta_1 z_{i1} + \ldots + \beta_p z_{ip}  \,, \qquad \forall \, i = 1, \ldots, n
</span></p></li>
<li><p><strong>Common variance (Homoscedasticity):</strong> There is a parameter <span class="math inline">\sigma^2</span> such that <span class="math display">
{\rm Var}[Y_i] = \sigma^2 \,, \qquad \forall \, i = 1, \ldots, n
</span></p></li>
<li><p><strong>Independence:</strong> The random variables <span class="math display">
Y_1   \,, \ldots \,, Y_n
</span> are independent</p></li>
</ol>
</section>
<section id="characterization-of-the-model-1" class="slide level2 smaller">
<h2>Characterization of the Model</h2>
<ul>
<li>Assumptions 1–5 look quite abstract</li>
<li>The following Proposition gives a handy characterization</li>
</ul>
<div id="Proposition*-3.6" class="Proposition">
<p></p><details class="Proposition fbx-simplebox fbx-default" open=""><summary><strong>Proposition</strong></summary><div>Assumptions 1-5 are satisfied if and only if <span class="math display">
Y_i =  \beta_1 z_{i1} + \ldots + \beta_p z_{ip}  + \varepsilon_{i}
</span> for some <strong>errors</strong> or <strong>residuals</strong> <span class="math display">
\varepsilon_1 , \ldots, \varepsilon_n  \,\, \text{ iid } \,\, N(0,\sigma^2)
</span><p></p>
</div></details>
</div>
<p><strong>Proof:</strong> Similar to the proof of Proposition in Slide 14. Omitted</p>
</section>
<section id="likelihood-function-1" class="slide level2 smaller">
<h2>Likelihood function</h2>
<p>Introduce the column vectors <span class="math display">
\beta := (\beta_1, \ldots, \beta_p)^T \,, \qquad
y := (y_1,\ldots,y_n)^T
</span></p>
<div id="Theorem*-3.7" class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose Assumptions 1–5 hold. The likelihood function of <span class="math inline">(Y_1,\ldots,Y_n)</span> is <span class="math display">
L(\beta, \sigma^2 | y ) = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{\sum_{i=1}^n(y_i- \beta_1 z_{i1} - \ldots - \beta_p z_{ip})^2}{2\sigma^2}  \right)
</span><p></p>
</div></details>
</div>
</section>
<section id="proof-2" class="slide level2 smaller">
<h2>Proof</h2>
<ul>
<li><p>By the Assumptions, we have <span class="math inline">Y_i \sim N(\beta_1 z_{i1} + \ldots + \beta_p z_{ip} , \sigma^2 )</span></p></li>
<li><p>Therefore, the pdf of <span class="math inline">Y_i</span> is <span class="math display">
f_{Y_i} (y_i) =  \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(y_i - \beta_1 z_{i1} - \ldots - \beta_p z_{ip})^2}{2\sigma^2} \right)
</span></p></li>
<li><p>Since <span class="math inline">Y_1,\ldots, Y_n</span> are independent, we obtain <span class="math display">\begin{align*}
L(\beta, \sigma^2 | y) &amp; = f(y_1,\ldots,y_n)
                                  = \prod_{i=1}^n f_{Y_i}(y_i)  \\
                                &amp; = \prod_{i=1}^n
                                \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(y_i - \beta_1 z_{i1} - \ldots - \beta_p z_{ip})^2}{2\sigma^2} \right) \\
                                &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{\sum_{i=1}^n(y_i- \beta_1 z_{i1} - \ldots - \beta_p z_{ip})^2}{2\sigma^2}      \right) \qquad \quad \square
\end{align*}</span></p></li>
</ul>
</section>
<section id="design-matrix" class="slide level2 smaller">
<h2>Design matrix</h2>
<p>For each <span class="math inline">i = 1 , \ldots, n</span> suppose given <span class="math inline">p</span> observations <span class="math display">
z_{i1}, \ldots, z_{ip}
</span></p>
<div id="Definition*-3.8" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The <strong>design matrix</strong> is the <span class="math inline">n \times p</span> matrix <span class="math display">
Z :=
\left(
\begin{array}{ccc}
z_{11} &amp; \ldots &amp; z_{1p} \\
z_{21} &amp; \ldots &amp; z_{2p} \\
\ldots &amp; \ldots &amp; \ldots \\
z_{n1} &amp; \ldots &amp; z_{np} \\
\end{array}
\right)
</span><p></p>
</div></details>
</div>
</section>
<section id="vectorial-notation" class="slide level2 smaller">
<h2>Vectorial notation</h2>
<p><span class="math display">\begin{align*}
y - Z\beta &amp; =
\left(
\begin{array}{c}
y_1 \\
y_2 \\
\ldots \\
y_n \\
\end{array}
\right)
-
\left(
\begin{array}{ccc}
z_{11} &amp; \ldots &amp; z_{1p} \\
z_{21} &amp; \ldots &amp; z_{2p} \\
\ldots &amp; \ldots &amp; \ldots \\
z_{n1} &amp; \ldots &amp; z_{np} \\
\end{array}
\right)
\left(
\begin{array}{c}
\beta_1 \\
\ldots \\
\beta_p \\
\end{array}
\right)
\\[20pt]
&amp; =
\left(
\begin{array}{c}
y_1 \\
y_2 \\
\ldots \\
y_n \\
\end{array}
\right)
-
\left(
\begin{array}{c}
\beta_1 z_{11} + \ldots + \beta_p z_{1p}\\
\beta_1 z_{21} + \ldots + \beta_p z_{2p} \\
\ldots \\
\beta_1 z_{n1} + \ldots + \beta_p z_{np} \\
\end{array}
\right) \\[20pt]
&amp; =
\left(
\begin{array}{c}
y_1 - \beta_1 z_{11} - \ldots - \beta_p z_{1p}\\
y_2 - \beta_1 z_{21} - \ldots - \beta_p z_{2p} \\
\ldots \\
y_n - \beta_1 z_{n1} - \ldots - \beta_p z_{np} \\
\end{array}
\right) \, \in \, \mathbb{R}^n
\end{align*}</span></p>
</section>
<section id="rss-residual-sum-of-squares" class="slide level2 smaller">
<h2>RSS: Residual Sum of Squares</h2>
<p>From the previous calculation, we get</p>
<p><span class="math display">
(y - Z \beta)^T \, (y - Z\beta) =
\sum_{i=1}^n \left( y_i - \beta_1 z_{i1} - \ldots - \beta_p z_{ip}   \right)^2
</span></p>
<div id="Definition*-3.9" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>Assume given<p></p>
<div class="column" style="width:42%;">
<ul>
<li><span class="math inline">n \times p</span> design matrix <span class="math inline">Z</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li>vector <span class="math inline">y \in \mathbb{R}^n</span></li>
</ul>
</div><p>The <strong>residual sum of squares</strong> associated to the parameter <span class="math inline">\beta</span> is the function <span class="math display">
\mathop{\mathrm{RSS}}\colon \mathbb{R}^p \to \mathbb{R}\,, \qquad
\mathop{\mathrm{RSS}}(\beta) :=  (y - Z \beta)^T \, (y - Z\beta)
</span></p>
</div></details>
</div>
</section>
<section id="likelihood-function-2" class="slide level2 smaller">
<h2>Likelihood function</h2>
<h3 id="vectorial-notation-1">Vectorial notation</h3>
<p>Using vectorial notation, the likelihood function can be re-written as</p>
<p><span class="math display">\begin{align*}
L(\beta, \sigma^2 | y ) &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{\sum_{i=1}^n(y_i - \beta_1 z_{i1} - \ldots - \beta_p z_{ip})^2}{2\sigma^2}  \right) \\[20pt]
&amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left( - \frac{ (y - Z \beta)^T \, (y - Z\beta) }{2 \sigma^2}  \right) \\[20pt]
&amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left( - \frac{\mathop{\mathrm{RSS}}(\beta) }{2 \sigma^2}  \right)
\end{align*}</span></p>
</section>
<section id="model-summary-1" class="slide level2 smaller">
<h2>Model Summary</h2>
<ul>
<li><p>General linear regression of <span class="math inline">Y</span> on <span class="math inline">Z_1, \ldots, Z_p</span> is the function <span class="math display">
{\rm I\kern-.3em E}[Y | z_1,\ldots,z_p] = \beta_1 z_{1} + \ldots + \beta_p z_p
</span></p></li>
<li><p>For each <span class="math inline">i=1, \ldots, n</span> suppose given the observations</p>
<ul>
<li><span class="math inline">(z_{i1}, \ldots, z_{ip}, y_i)</span> observed from <span class="math inline">(Z_1,\ldots, Z_p,Y)</span></li>
</ul></li>
<li><p>Denote by <span class="math inline">Y_i</span> the random variable <span class="math inline">Y | z_{i1} ,\ldots, z_{ip}</span></p></li>
<li><p>We suppose that <span class="math inline">Y_i</span> has the form <span class="math display">
Y_i = \beta_1 z_{i1} + \ldots + \beta_p z_{ip} + \varepsilon_i \,, \qquad \varepsilon_i \,\, \text{ iid } \,\, N(0,\sigma^2)
</span></p></li>
<li><p>In particular, <span class="math display">
{\rm I\kern-.3em E}[Y | z_{i1}, \ldots, z_{ip}] = {\rm I\kern-.3em E}[Y_i] = \beta_1 z_{i1} + \ldots + \beta_p z_{ip}
</span></p></li>
</ul>
</section>
<section id="the-general-linear-regression-problem" class="slide level2 smaller">
<h2>The general linear regression problem</h2>
<p>For each <span class="math inline">i = 1 , \ldots, n</span> suppose given data points <span class="math inline">(z_{i1}, \ldots, z_{ip}, y_i)</span></p>
<div id="Problem*-3.10" class="Problem">
<p></p><details class="Problem fbx-simplebox fbx-default" open=""><summary><strong>Problem</strong></summary><div>From the above data, learn a general linear regression function <span class="math display">
{\rm I\kern-.3em E}[Y | z_1, \ldots, z_p] = \beta_1 z_1 +
\ldots + \beta_p z_p
</span> which explains the observations, that is, such that <span class="math display">\begin{equation} \tag{2}
{\rm I\kern-.3em E}[Y_i] = {\rm I\kern-.3em E}[Y | z_{i1}, \ldots, z_{ip}] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
\end{equation}</span><p></p>
</div></details>
</div>
<div id="Question*-3.11" class="Question">
<p></p><details class="Question fbx-simplebox fbx-default" open=""><summary><strong>Question</strong></summary><div>How do we enforce (2)?<p></p>
</div></details>
</div>
</section>
<section id="section-5" class="slide level2 smaller">
<h2></h2>
<p><strong>Answer:</strong> Recall condition (2) from the previous slide <span class="math display">\begin{equation} \tag{2}
{\rm I\kern-.3em E}[Y_i] \ \approx \ y_i \,, \qquad \forall \, i = 1 , \ldots, n
\end{equation}</span></p>
<ul>
<li><p>If we want (2) to hold, we need to maximize the joint probability <span class="math display">\begin{equation}\tag{P}
P(Y_1 \approx y_1, \ldots, Y_n \approx y_n) =
\int_{A} f(y) \, dy \approx |A| f(y)
\end{equation}</span></p>
<ul>
<li>where <span class="math inline">f</span> is the joint pdf of <span class="math inline">(Y_1,\ldots,Y_n)</span></li>
<li><span class="math inline">A</span> is a (small) open set in <span class="math inline">\mathbb{R}^n</span> containing the observations <span class="math inline">(y_1,\ldots,y_n)</span></li>
<li><span class="math inline">|A|</span> is the n-dimensional volume of <span class="math inline">A</span></li>
</ul></li>
<li><p>To maximize the probability, by (P), it is enough to maximize <span class="math inline">f(y_1,\ldots,y_n)</span></p></li>
<li><p>Therefore, choose parameters <span class="math inline">\hat \beta,  \hat \sigma</span> which <strong>maximize the likelihood function</strong> <span class="math display">
\max_{\beta,\sigma} \ f(y | \beta, \sigma^2) =
\max_{\beta,\sigma} \ L(\beta, \sigma^2 | y )
</span></p></li>
</ul>
</section>
<section id="maximum-likelihood-estimation-1" class="slide level2 smaller">
<h2>Maximum Likelihood Estimation</h2>
<div id="Theorem*-3.12" class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose Assumptions 1–5 hold. Assume given observations <span class="math display">
(z_{i1}, \ldots, z_{ip} ,y_i) \,, \quad \forall \, i =1 ,\ldots n \,, \qquad \text{ s.t. } \,\,
\det (Z Z^T) \neq 0
</span> The maximization problem <span class="math display">
\max_{\beta,\sigma}  \ L(\beta, \sigma^2 | y )
</span> admits the unique solution <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y  \,, \qquad
\hat{\sigma}^2  = \frac{1}{n} \mathop{\mathrm{RSS}}(\hat \beta)
</span><p></p>
</div></details>
</div>
<ul>
<li>The constants <span class="math inline">\hat \beta, \hat{\sigma}^2</span> are called <em>Maximum Likelihood Estimators (MLE)</em></li>
</ul>
</section>
<section id="minimizing-the-rss" class="slide level2 smaller">
<h2>Minimizing the RSS</h2>
<p>The proof of previous Theorem relies on the following Lemma</p>
<div id="Lemma*-3.13" class="Lemma">
<p></p><details class="Lemma fbx-simplebox fbx-default" open=""><summary><strong>Lemma</strong></summary><div>Assume given observations <span class="math display">
(z_{i1}, \ldots, z_{ip} ,y_i) \,, \quad \forall \, i =1 ,\ldots n \,, \qquad \text{ s.t. } \,\,
\det (Z Z^T) \neq 0
</span> The minimization problem <span class="math display">
\min_{\beta} \ \mathop{\mathrm{RSS}}(\beta)
</span> admits the unique solution <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span><p></p>
</div></details>
</div>
</section>
<section id="results-from-matrix-calculus" class="slide level2 smaller">
<h2>Results from matrix calculus</h2>
<ul>
<li><p>To prove the Lemma we need some auxiliary results</p></li>
<li><p>In the following, <span class="math inline">x</span> denotes an <span class="math inline">n \times 1</span> column vector</p></li>
</ul>
<p><span class="math display">
x =
\left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{array}
\right)
</span></p>
</section>
<section id="results-from-matrix-calculus-1" class="slide level2 smaller">
<h2>Results from matrix calculus</h2>
<h3 id="first-result">First result</h3>
<ul>
<li><p>Suppose given an <span class="math inline">n \times 1</span> column vector <span class="math inline">a</span></p></li>
<li><p>Define the scalar function</p></li>
</ul>
<p><span class="math display">
f \colon \mathbb{R}^n \to \mathbb{R}\,, \qquad f(x) := a^T x
</span></p>
<ul>
<li>Then <span class="math inline">f</span> is differentiable and the gradient is constant</li>
</ul>
<p><span class="math display">
\nabla f (x) = a^T
</span></p>
</section>
<section id="results-from-matrix-calculus-2" class="slide level2 smaller">
<h2>Results from matrix calculus</h2>
<h3 id="second-result">Second result</h3>
<ul>
<li><p>Suppose given an <span class="math inline">m \times n</span> matrix <span class="math inline">A</span></p></li>
<li><p>Define the vectorial affine function</p></li>
</ul>
<p><span class="math display">
g \colon \mathbb{R}^n \to \mathbb{R}^m \,, \qquad g(x) := A x
</span></p>
<ul>
<li>Then <span class="math inline">g</span> is differentiable and the Jacobian is constant</li>
</ul>
<p><span class="math display">
J g (x) = A
</span></p>
</section>
<section id="results-from-matrix-calculus-3" class="slide level2 smaller">
<h2>Results from matrix calculus</h2>
<h3 id="third-result">Third result</h3>
<ul>
<li><p>Suppose given an <span class="math inline">n \times n</span> matrix <span class="math inline">M</span></p></li>
<li><p>Define the quadratic form</p></li>
</ul>
<p><span class="math display">
h \colon \mathbb{R}^n \to \mathbb{R}\,, \qquad
h(x) := x^T M x
</span></p>
<ul>
<li>Then <span class="math inline">h</span> is differentiable and the Jacobian is</li>
</ul>
<p><span class="math display">
J h(x) = x^T (M + M^T)
</span></p>
</section>
<section id="additional-results-on-the-matrix-transpose" class="slide level2 smaller">
<h2>Additional results on the matrix transpose</h2>
<ol type="1">
<li><p>For any <span class="math inline">m \times n</span> matrix <span class="math inline">A</span> <span class="math display">
(A^T)^T= A
</span></p></li>
<li><p>A square matrix <span class="math inline">M</span> of size <span class="math inline">n \times n</span> is <strong>symmetric</strong> iff <span class="math inline">M^T = M</span></p></li>
<li><p>Scalars can be seen as <span class="math inline">1 \times 1</span> symmetric matrices. Therefore <span class="math display">
c^T = c \,, \qquad \forall \, c \in \mathbb{R}
</span></p></li>
<li><p>For any <span class="math inline">m \times n</span> matrix <span class="math inline">A</span> and <span class="math inline">n \times p</span> matrix <span class="math inline">B</span> <span class="math display">
(AB)^T=B^T A^T
</span></p></li>
<li><p>The matrix <span class="math inline">A^T A</span> is symmetric by point (2) <span class="math display">
(A^T A)^T = A^T (A^T)^T = A^T A
</span></p></li>
</ol>
</section>
<section id="optimality-conditions" class="slide level2 smaller">
<h2>Optimality conditions</h2>
<p>We also need the <span class="math inline">n</span>-dimensional version of the Lemma in Slide 103 Lecture 7</p>
<div id="Lemma*-3.14" class="Lemma">
<p></p><details class="Lemma fbx-simplebox fbx-default" open=""><summary><strong>Lemma</strong></summary><div>Suppose <span class="math inline">f \colon \mathbb{R}^n \to \mathbb{R}</span> has positive semi-definite Hessian. They are equivalent<p></p>
<ol type="1">
<li>The point <span class="math inline">\hat x</span> is a minimizer of <span class="math inline">f</span>, that is, such that</li>
</ol>
<p><span class="math display">
f( \hat x ) = \min_{x \in \mathbb{R}^n} f(x)
</span></p>
<ol start="2" type="1">
<li>The point <span class="math inline">\hat x</span> satisfies the <strong>optimality conditions</strong></li>
</ol>
<p><span class="math display">
\nabla f (\hat x) = 0
</span></p>
</div></details>
</div>
</section>
<section id="proof-minimizing-the-rss" class="slide level2 smaller">
<h2>Proof: Minimizing the RSS</h2>
<ul>
<li><p>Recall the definition of Residual Sum of Squares <span class="math display">
\mathop{\mathrm{RSS}}\colon \mathbb{R}^{p} \to \mathbb{R}\,, \qquad \mathop{\mathrm{RSS}}(\beta) = (y - Z \beta)^T (y - Z \beta)
</span></p></li>
<li><p>We are finally ready to minimize the <span class="math inline">\mathop{\mathrm{RSS}}</span> <span class="math display">
\min_{\beta \in \mathbb{R}^p} \ \mathop{\mathrm{RSS}}(\beta)
</span></p></li>
<li><p>It is not too difficult to show that <span class="math inline">\nabla^2 \mathop{\mathrm{RSS}}</span> is positive-semidefinite (omitted)</p></li>
<li><p>By the Lemma on Optimality Conditions in Slide 50 <span class="math display">
\beta \,\, \text{ minimizes } \,\, \mathop{\mathrm{RSS}}\qquad \iff \qquad
\nabla \mathop{\mathrm{RSS}}(\beta) = 0
</span></p></li>
</ul>
</section>
<section id="section-6" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>To compute <span class="math inline">\nabla \mathop{\mathrm{RSS}}</span>, we first expand <span class="math inline">\mathop{\mathrm{RSS}}</span> <span class="math display">\begin{align*}
\mathop{\mathrm{RSS}}(\beta) &amp; = (y-Z \beta)^T (y-Z \beta) \\[5pt]
          &amp; = (y^T - (Z\beta)^T ) (y-Z \beta) \\[5pt]
          &amp; = (y^T - \beta^T Z^T ) (y-Z \beta) \\[5pt]
          &amp; = y^T y - y^T Z \beta - \beta^T Z^T y
              + \beta^T Z^T Z \beta
\end{align*}</span></p></li>
<li><p>Note that</p>
<ul>
<li><span class="math inline">\beta</span> has size <span class="math inline">p \times 1 \quad \implies \quad \beta^T</span> has size <span class="math inline">1 \times p</span></li>
<li><span class="math inline">Z</span> has size <span class="math inline">n \times p \quad \implies \quad Z^T</span> has size <span class="math inline">p \times n</span></li>
<li><span class="math inline">y</span> has size <span class="math inline">n \times 1 \quad \implies \quad \beta^T Z^T y</span> has size <span class="math display">
\left( 1 \times p \right) \times
\left( p \times n \right) \times
\left( n \times 1 \right)  = 1 \times 1
</span></li>
</ul></li>
</ul>
</section>
<section id="section-7" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<ul>
<li><p><span class="math inline">\beta^T Z^T y \,</span> is a scalar <span class="math inline">\quad \implies \quad</span> it is symmetric and we get <span class="math display">
\left( \beta^T Z^T y  \right)^T = \beta^T Z^T y
</span></p></li>
<li><p>Using the properties of transposition we also get <span class="math display">
\left( \beta^T Z^T y  \right)^T =  y^T Z \beta
</span></p></li>
<li><p>From the last 2 equations we conclude <span class="math display">
\beta^T Z^T y = y^T Z \beta
</span></p></li>
<li><p>The <span class="math inline">\mathop{\mathrm{RSS}}</span> can now be written as <span class="math display">\begin{align*}
\mathop{\mathrm{RSS}}(\beta) &amp; = y^T y - y^T Z \beta
              - \textcolor{magenta}{\beta^T Z^T y} + \beta^T Z^T Z \beta \\[5pt]
          &amp; = y^T y - y^T Z \beta - \textcolor{magenta}{y^T Z \beta}
            + \beta^T Z^T Z \beta \\[5pt]
          &amp; = y^T y - 2 y^T Z \beta + \beta^T Z^T Z \beta
\end{align*}</span></p></li>
</ul>
</div>
</section>
<section id="section-8" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Therefore, we have <span class="math display">\begin{align*}
\nabla \mathop{\mathrm{RSS}}(\beta) &amp; = \nabla ( y^T y )
                    - 2  \nabla (y^T Z     \beta ) + \nabla (\beta^T Z^T Z \beta ) \\[5pt]
                  &amp; = - 2  \nabla (y^T Z     \beta ) + \nabla (\beta^T Z^T Z \beta )
\end{align*}</span></p></li>
<li><p>We need to compute <span class="math display">
\nabla (y^T Z     \beta )  \qquad \quad \text{ and } \qquad \quad \nabla (\beta^T Z^T Z \beta )
</span></p></li>
<li><p>Note that <span class="math inline">y^T Z</span> has dimension <span class="math inline">\, ( 1 \times n ) \times ( n \times p ) = 1 \times p</span></p></li>
<li><p>Since <span class="math inline">\beta</span> has dimension <span class="math inline">p \times 1</span>, we can define the function <span class="math display">
f \colon \mathbb{R}^p \to \mathbb{R}\,, \qquad
f(\beta) := y^T Z \beta
</span></p></li>
<li><p>By the First Result on Matrix Calculus in Slide 46 <span class="math display">
\nabla f  = \nabla ( \textcolor{magenta}{y^T Z} \beta) = \textcolor{magenta}{y^T Z}
</span></p></li>
</ul>
</section>
<section id="section-9" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Note that <span class="math inline">Z^T Z</span> has dimension <span class="math inline">\, ( p \times n ) \times ( n \times p ) = p \times p</span></p></li>
<li><p>Since <span class="math inline">\beta</span> has dimension <span class="math inline">p \times 1</span>, we can define the function</p></li>
</ul>
<p><span class="math display">
h \colon \mathbb{R}^p \to \mathbb{R}\,, \qquad
h(\beta) := \beta^T Z^T Z \beta
</span></p>
<ul>
<li><p>By the Third Result on Matrix Calculus in Slide 48 <span class="math display">\begin{align*}
\nabla h  &amp; = \nabla (\beta^T \textcolor{magenta}{Z^T Z} \beta) = \beta^T (\textcolor{magenta}{Z^T Z} + (\textcolor{magenta}{Z^T Z})^T ) \\[5pt]
&amp; = \beta^T ( Z^T Z + Z^T Z ) = 2 \beta^T (Z^T Z)
\end{align*}</span></p></li>
<li><p>Putting together these results we obtain</p></li>
</ul>
<p><span class="math display">\begin{align*}
\nabla \mathop{\mathrm{RSS}}(\beta) &amp; = - 2  \nabla (y^T Z     \beta ) + \nabla (\beta^T Z^T Z \beta ) \\[5pt]
                    &amp; = -2 y^T Z + 2 \beta^T (Z^T Z)
\end{align*}</span></p>
</section>
<section id="section-10" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>We can finally solve the optimality conditions: <span class="math display">\begin{align*}
\nabla \mathop{\mathrm{RSS}}(\beta) = 0 \qquad &amp; \iff \qquad
-2 y^T Z + 2 \beta^T (Z^T Z) = 0  \\[5pt]
&amp; \iff \qquad
\beta^T (Z^T Z) =  y^T Z
\end{align*}</span></p></li>
<li><p>Transposing both sides of the last equation yields <span class="math display">\begin{equation} \tag{3}
(Z^T Z) \beta = Z^T y
\end{equation}</span></p></li>
<li><p>The matrix <span class="math inline">Z^T Z</span> is invertible, since we are assuming <span class="math display">
\det (Z^T Z) \neq 0
</span></p></li>
<li><p>Multiplying by <span class="math inline">(Z^T Z)^{-1}</span> both sides of (3), we get <span class="math display">
\beta = (Z^T Z)^{-1} Z^T y
</span></p></li>
</ul>
</section>
<section id="section-11" class="slide level2 smaller">
<h2></h2>
<ul>
<li>In conclusion, we have shown that</li>
</ul>
<p><span class="math display">
\nabla \mathop{\mathrm{RSS}}(\beta) = 0 \qquad \iff \qquad
\beta = (Z^T Z)^{-1} Z^T y
</span></p>
<ul>
<li>By the Lemma on Optimality Conditions in Slide 50, we infer</li>
</ul>
<p><span class="math display">
\beta = (Z^T Z)^{-1} Z^T y  \,\,\, \text{ minimizes } \,\,\, \mathop{\mathrm{RSS}}
</span></p>
<ul>
<li>This concludes the proof</li>
</ul>
</section>
<section id="maximum-likelihood-estimation-2" class="slide level2 smaller">
<h2>Maximum Likelihood Estimation</h2>
<p>We are finally in position to prove the main Theorem. We recall the statement</p>
<div id="Theorem*-3.15" class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose Assumptions 1–5 hold. Assume given observations <span class="math display">
(z_{i1}, \ldots, z_{ip} ,y_i) \,, \quad \forall \, i =1 ,\ldots n \,, \qquad \text{ s.t. } \,\,
\det (Z Z^T) \neq 0
</span> The maximization problem <span class="math display">
\max_{\beta,\sigma}  \ L(\beta, \sigma^2 | y )
</span> admits the unique solution <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y  \,, \qquad
\hat{\sigma}^2  = \frac{1}{n} \mathop{\mathrm{RSS}}(\hat \beta)
</span><p></p>
</div></details>
</div>
</section>
<section id="proof-of-theorem-1" class="slide level2 smaller">
<h2>Proof of Theorem</h2>
<ul>
<li><p>The <span class="math inline">\log</span> function is strictly increasing. Therefore <span class="math display">
\max_{\beta,\sigma} \ L(\beta, \sigma^2 | y )
\quad
\text{ is equivalent to } \quad
\max_{\beta,\sigma} \ \log L( \beta, \sigma^2 | y )
</span></p></li>
<li><p>Recall that the likelihood is <span class="math display">
L(\beta, \sigma^2 | y ) =  \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   - \frac{ \mathop{\mathrm{RSS}}(\beta) }{2\sigma^2}      \right)
</span></p></li>
<li><p>Hence, the log–likelihood is <span class="math display">
\log L(\beta, \sigma^2 | y )
= - \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \mathop{\mathrm{RSS}}(\beta) }{2 \sigma^2}
</span></p></li>
</ul>
</section>
<section id="section-12" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Suppose first that <span class="math inline">\sigma</span> is fixed. In this case the problem <span class="math display">
\max_{\beta} \ \left\{ \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \mathop{\mathrm{RSS}}(\beta) }{2 \sigma^2} \right\}
</span> is equivalent to <span class="math display">
\min_{\beta} \ \mathop{\mathrm{RSS}}(\beta)
</span></p></li>
<li><p>We have already proven that the <span class="math inline">\mathop{\mathrm{RSS}}</span> is minimized at <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p></li>
</ul>
</section>
<section id="section-13" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Substituting <span class="math inline">\hat \beta</span>, we obtain</li>
</ul>
<p><span class="math display">\begin{align*}
\max_{\beta,\sigma} \ &amp; \log L(\beta, \sigma^2 | y )
= \max_{\sigma} \ \log L(\hat \beta, \sigma^2 | y ) \\[5pt]
&amp; = \max_{\sigma} \ \left\{ - \frac{n}{2} \log (2 \pi) - \frac{n}{2} \log \sigma^2 -
\frac{ \mathop{\mathrm{RSS}}(\hat \beta) }{2 \sigma^2}  \right\}
\end{align*}</span></p>
<ul>
<li><p>The above is a one-dimensional minimization problem in <span class="math inline">\sigma</span></p></li>
<li><p>Taking the first order derivative wrt <span class="math inline">\sigma</span>, it can be shown the unique solution is <span class="math display">
\hat{\sigma}^2  = \frac{1}{n} \mathop{\mathrm{RSS}}(\hat \beta)
</span></p></li>
<li><p>This concludes the proof</p></li>
</ul>
</section></section>
<section>
<section id="part-3-simple-regression-as-general-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 3: <br>Simple regression as<br> general regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="general-linear-regression-model" class="slide level2 smaller">
<h2>General linear regression model</h2>
<ul>
<li>The general linear regression model is</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1} +  \ldots +  \beta_p z_{ip} + \varepsilon_i \,,  \quad \varepsilon_i \sim N(0,\sigma^2) \quad \, \forall \,  i = 1 , \ldots, n
</span></p>
<ul>
<li><p>The design matrix, and data and parameters vectors are <span class="math display">
Z =
\left(
\begin{array}{ccc}
z_{11} &amp; \ldots &amp; z_{1p} \\
\ldots &amp; \ldots &amp; \ldots \\
z_{n1} &amp; \ldots &amp; z_{np} \\
\end{array}
\right) \in \mathbb{R}^{n \times p} \,, \qquad
y =
\left(
\begin{array}{c}
y_1   \\
\ldots  \\
y_{n} \\
\end{array}
\right)\,, \qquad
\beta =
\left(
\begin{array}{c}
\beta_1  \\
\ldots  \\
\beta_{p} \\
\end{array}
\right)
</span></p></li>
<li><p>The likelihood function for general linear regression is maximized by <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p></li>
</ul>
</section>
<section id="simple-linear-regression-model" class="slide level2 smaller">
<h2>Simple linear regression model</h2>
<ul>
<li>The simple linear regression model is</li>
</ul>
<p><span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i \,,  \,,  \quad \varepsilon_i \sim N(0,\sigma^2) \quad \, \forall \,  i = 1 , \ldots, n
</span></p>
<ul>
<li><p>The data is given by <span class="math display">
x =
\left(
\begin{array}{c}
x_1   \\
\ldots  \\
x_{n} \\
\end{array}
\right)
\qquad \quad
y =
\left(
\begin{array}{c}
y_1   \\
\ldots  \\
y_{n} \\
\end{array}
\right)
</span></p></li>
<li><p>The likelihood function for simple linear regression is maximized by <span class="math display">
\hat \alpha = \overline{y} - \hat \beta \, \overline{x} \,,
\qquad \quad \hat \beta = \frac{S_{xy}}{S_{xx}}
</span></p></li>
</ul>
</section>
<section id="simple-linear-regression-from-general" class="slide level2 smaller">
<h2>Simple linear regression from general</h2>
<ul>
<li><p>The general regression model comprises the simple regression one</p></li>
<li><p>To see this, consider a general linear model with <span class="math inline">p = 2</span> parameters</p></li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \beta_2 z_{i2} + \varepsilon_i \,, \qquad i = 1 , \ldots, n
</span></p>
<ul>
<li>We want to compare the above to</li>
</ul>
<p><span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i \,, \qquad i = 1 , \ldots, n
</span></p>
<ul>
<li>The 2 models are equivalent iff</li>
</ul>
<p><span class="math display">
z_{i1} = 1 \,, \qquad z_{i2} = x_i \,, \qquad \forall \, i = 1 , \ldots, n
</span></p>
</section>
<section id="section-14" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.94em">
<p>Therefore, the design matrix is <span class="math display">
Z =
\left(
\begin{array}{cc}
1 &amp; x_{1}  \\
\ldots &amp; \ldots \\
1 &amp; x_{n} \\
\end{array}
\right) \in \mathbb{R}^{n \times 2}
</span></p>
<div class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>With the above definition of <span class="math inline">Z</span>, it holds that <span class="math display">
(Z^T Z)^{-1} Z^T y
=
\left(
\begin{array}{cc}
\hat \alpha \\
\hat \beta
\end{array}
\right) \,, \qquad
\hat \alpha = \overline{y} - \hat \beta \overline{x} \,,
\qquad \hat \beta = \frac{S_{xy}}{S_{xx}}
</span><p></p>
</div></details>
</div>
<p>In other words, the multiple linear regression estimator <span class="math display">
(Z^T Z)^{-1} Z^T y
</span> coincides with the simple linear regression estimators <span class="math inline">\hat \alpha, \hat \beta</span></p>
</div>
</section>
<section id="proof-calculating-zt-y" class="slide level2 smaller">
<h2>Proof: Calculating <span class="math inline">Z^T y</span></h2>
<div style="font-size: 0.94em">
<ul>
<li><span class="math inline">Z</span> has size <span class="math inline">n \times 2 \qquad \implies \qquad</span> <span class="math inline">Z^T</span> has size <span class="math inline">2 \times n</span></li>
<li><span class="math inline">y</span> has size <span class="math inline">n \times 1 \qquad \implies \qquad Z^T y</span> has size <span class="math inline">\, ( 2 \times n )  \times (n \times 1) = 2 \times 1</span></li>
</ul>
<p><span class="math display">\begin{align*}
Z^T y
&amp; =
\left(
\begin{array}{cc}
    1 &amp; x_1 \\
    \ldots &amp; \ldots\\
    1 &amp; x_n
\end{array}
\right)^T
\left(
  \begin{array}{l}
     y_1  \\
     \ldots\\
     y_n
\end{array}\right) \\[15pt]
&amp; =
\left(
\begin{array}{ccc}
1 &amp; \ldots &amp; 1 \\
x_1 &amp; \ldots &amp; x_n
\end{array}
\right)
\left(
  \begin{array}{l}
     y_1  \\
     \ldots\\
     y_n
\end{array}\right) \\[15pt]
&amp; =
\left(\begin{array}{c}
1 \times y_1 + 1 \times y_2 + \ldots + 1 \times y_n \\
x_1 y_1 + x_2 y_2 + \ldots + x_n y_n
\end{array} \right) \\[15pt]
&amp; =
\left(
  \begin{array}{c}
     n \overline{y}  \\
     \sum_{i=1}^n x_i y_i
\end{array}
\right)
\end{align*}</span></p>
</div>
</section>
<section id="calculating-zt-z" class="slide level2 smaller">
<h2>Calculating <span class="math inline">Z^T Z</span></h2>
<div style="font-size: 0.94em">
<ul>
<li><p><span class="math inline">Z</span> has size <span class="math inline">n \times 2 \qquad \implies \qquad</span> <span class="math inline">Z^T</span> has size <span class="math inline">2 \times n</span></p></li>
<li><p>Therefore <span class="math inline">Z^T Z</span> has size <span class="math inline">\, ( 2 \times n )  \times (n \times 2) = 2 \times 2</span></p></li>
</ul>
<p><span class="math display">\begin{align*}
Z^T Z &amp; =
\left(
\begin{array}{cc}
    1 &amp; x_1 \\
    \ldots &amp; \ldots\\
    1 &amp; x_n
\end{array}
\right)^T
\left(
\begin{array}{cc}
    1 &amp; x_1 \\
    \ldots &amp; \ldots\\
    1 &amp; x_n
\end{array}
\right) \\[15pt]
&amp; =
\left(
\begin{array}{ccc}
1 &amp; \ldots &amp; 1 \\
x_1 &amp; \ldots &amp; x_n
\end{array}
\right)
\left(
\begin{array}{cc}
    1 &amp; x_1 \\
    \ldots &amp; \ldots\\
    1 &amp; x_n
\end{array}
\right) \\[15pt]
&amp; =
\left(
\begin{array}{cc}
    1 \times 1 + \ldots + 1 \times 1 &amp; 1 \times x_1 + \ldots + 1 \times x_n \\
    x_1 \times 1 + \ldots + x_n \times 1 &amp;  x_1 \times x_1 + \ldots + x_n \times x_n
\end{array}
\right) \\[15pt]
&amp; =
\left(
\begin{array}{cc}
    n &amp; n \overline{x} \\
    n \overline{x} &amp; \sum_{i=1}^n x_i^2
\end{array}
\right)
\end{align*}</span></p>
</div>
</section>
<section id="matrix-inverse-general-formula" class="slide level2 smaller">
<h2>Matrix inverse: General formula</h2>
<ul>
<li>Suppose to have a <span class="math inline">2 \times n</span> matrix</li>
</ul>
<p><span class="math display">
M
=
\left(
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right)
</span></p>
<ul>
<li><span class="math inline">M</span> is invertible iff</li>
</ul>
<p><span class="math display">
\det M = ad - bc \neq 0
</span></p>
<ul>
<li>If <span class="math inline">\det M \neq 0</span>, the inverse of <span class="math inline">M</span> is</li>
</ul>
<p><span class="math display">
M^{-1}
=
\frac{1}{ ad - bc}  
\left(
\begin{array}{cc}
d &amp; -b \\
-c &amp; a
\end{array}\right)
</span></p>
</section>
<section id="resume-the-proof-calculating-zt-z-1" class="slide level2 smaller">
<h2>Resume the proof: Calculating <span class="math inline">(Z^T Z)^{-1}</span></h2>
<p><span class="math display">
\det  \left( Z^T Z \right)  =
\det
\left(
\begin{array}{cc}
    n &amp; n \overline{x} \\
    n \overline{x} &amp; \sum_{i=1}^n x_i^2
\end{array}
\right)
=
n \sum_{i=1}^n x^2_i - n^2 \overline{x}^2
= n S_{xx}
</span></p>
<ul>
<li><p>Note: <span class="math inline">\, S_{xx} = \sum_{i=1}^n (x_i - \overline{x})^2 = 0 \quad \iff \quad x_1 = \ldots = x_n = \overline{x}</span></p></li>
<li><p>WLOG we can discard the trivial case <span class="math inline">S_{xx} = 0</span> because:</p>
<ul>
<li>The predictors <span class="math inline">x_1, \ldots, x_n</span> are either chosen, or random</li>
<li>If they are chosen, it makes no sense to choose them all equal</li>
<li>If they are random, they will all be equal with probability <span class="math inline">0</span></li>
</ul></li>
<li><p>Therefore, we have <span class="math display">
\det \left( Z^T Z \right) = n S_{xx} &gt; 0  \quad \implies \quad Z^T Z \, \text{ is invertible}
</span></p></li>
</ul>
</section>
<section id="calculating-zt-z-1" class="slide level2 smaller">
<h2>Calculating <span class="math inline">(Z^T Z)^{-1}</span></h2>
<ul>
<li><p>Therefore, we assume <span class="math inline">S_{xx} &gt; 0</span></p></li>
<li><p>This way, we have</p></li>
</ul>
<p><span class="math display">
\det \left( Z^T Z \right) = n S_{xx} &gt; 0
</span></p>
<ul>
<li>Thus <span class="math inline">Z^T Z</span> is invertible, with inverse</li>
</ul>
<p><span class="math display">\begin{align*}
(Z^T Z)^{-1} &amp; =
\left(
\begin{array}{cc}
    n &amp; n \overline{x} \\
    n \overline{x} &amp; \sum_{i=1}^n x_i^2
\end{array}
\right)^{-1} \\[15pt]
&amp; =
\frac{1}{n S_{xx} }
\left(
\begin{array}{cc}
\sum_{i=1}^n x^2_i &amp; -n \overline{x}\\
-n\overline{x} &amp; n
\end{array}
\right)
\end{align*}</span></p>
</section>
<section id="calculating-zt-z-1-zt-y" class="slide level2 smaller">
<h2>Calculating <span class="math inline">(Z^T Z)^{-1} Z^T y</span></h2>
<ul>
<li><p><span class="math inline">(Z^T Z)^{-1}</span> has size <span class="math inline">2 \times 2</span></p></li>
<li><p><span class="math inline">Z^T y</span> has size <span class="math inline">2 \times 1</span></p></li>
<li><p><span class="math inline">(Z^T Z)^{-1} Z^T y</span> therefore has dimensions <span class="math display">
(2 \times 2) \times (2 \times 1) = (2 \times 1)
</span></p></li>
<li><p>We expect <span class="math inline">(Z^T Z)^{-1} Z^T y</span> to contain the simple regression estimators <span class="math inline">\hat \alpha, \hat \beta</span></p></li>
</ul>
<p><span class="math display">
(Z^T Z)^{-1} Z^T y
=
\left(
\begin{array}{cc}
\hat \alpha \\
\hat \beta
\end{array}
\right)
</span></p>
</section>
<section id="calculating-zt-z-1-zt-y-1" class="slide level2 smaller">
<h2>Calculating <span class="math inline">(Z^T Z)^{-1} Z^T y</span></h2>
<ul>
<li><p>We have already computed <span class="math inline">(Z^T Z)^{-1}</span> and <span class="math inline">Z^T y</span></p></li>
<li><p>Their product is</p></li>
</ul>
<p><span class="math display">
(Z^T Z)^{-1} Z^T y = \frac{1}{n S_{xx} }
\left(
\begin{array}{cc}
\sum_{i=1}^n x^2_i &amp; -n \overline{x}\\
-n\overline{x} &amp; n
\end{array}
\right) \left(
  \begin{array}{c}
     n \overline{y}  \\
     \sum_{i=1}^n x_i y_i
\end{array}
\right)
</span></p>
</section>
<section id="calculating-zt-z-1-zt-y-2" class="slide level2 smaller">
<h2>Calculating <span class="math inline">(Z^T Z)^{-1} Z^T y</span></h2>
<ul>
<li>The first entry of <span class="math inline">(Z^T Z)^{-1} Z^T y</span> is therefore</li>
</ul>
<p><span class="math display">\begin{align*}
\frac{ \sum_{i=1}^n x_i^2 n \overline{y} - n \overline{x} \sum_{i=1}^n x_i y_i  }{n S_{xx}}
&amp; =
\frac{ \sum_{i=1}^n x_i^2  \overline{y} - \overline{x} \sum_{i=1}^n x_i y_i  }{ S_{xx}} \\[10pt]
&amp; = \frac{ \sum_{i=1}^n x_i^2  \overline{y}
\textcolor{magenta}{- \overline{y} n \overline{x}^2 +  \overline{y} n \overline{x}^2}
- \overline{x} \sum_{i=1}^n x_i y_i  }{ S_{xx}} \\[10pt]
&amp; = \overline{y} \ \frac{ \sum_{i=1}^n x_i^2 - n \overline{x}^2}{ S_{xx} } -
\overline{x} \ \frac{ \sum_{i=1}^n x_i y_i - n \overline{x} \overline{y} }{ S_{xx} } \\[10pt]
&amp; =  \overline{y} \ \frac{ S_{xx} }{ S_{xx} } -
\overline{x} \ \frac{ S_{xy} }{ S_{xx} }  \\[10pt]
&amp; = \overline{y} - \hat \beta \, \overline{x} = \hat{\alpha}
\end{align*}</span></p>
</section>
<section id="calculating-zt-z-1-zt-y-3" class="slide level2 smaller">
<h2>Calculating <span class="math inline">(Z^T Z)^{-1} Z^T y</span></h2>
<ul>
<li>The second entry of <span class="math inline">(Z^T Z)^{-1} Z^T y</span> is</li>
</ul>
<p><span class="math display">
\frac{ - n \overline{x} n \overline{y} + n \sum_{i=1}^n x_i y_i}{ n S_{xx} } =
\frac{  \sum_{i=1}^n x_i y_i - n\overline{x} \overline{y} }{ S_{xx} }
= \frac{ S_{xy} }{S_{xx}}
= \hat{\beta}
</span></p>
<ul>
<li>We have finally proven that</li>
</ul>
<p><span class="math display">
(Z^T Z)^{-1} Z^T y =
\left(
\begin{array}{cc}
\hat \alpha \\
\hat \beta
\end{array}
\right)
</span></p>
<ul>
<li><strong>Conclusion</strong>
<ul>
<li>Simple linear regression is special case of general regression with <span class="math inline">p = 2</span></li>
<li>Estimator for general regression recovers estimators for simple regression</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="part-4-multiple-linear-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 4: <br>Multiple linear<br> regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="mutiple-linear-regression" class="slide level2 smaller">
<h2>Mutiple linear regression</h2>
<p>Response variable <span class="math inline">Y</span> depends on <span class="math inline">p-1</span> predictors <span class="math inline">X_2, \ldots, X_p</span></p>
<ul>
<li><p>The goal is to learn the distribution of <span class="math display">
Y | X_2, \ldots, X_p
</span></p></li>
<li><p><span class="math inline">Y | X_2, \ldots, X_p</span> allows to predict values of <span class="math inline">Y</span>, knowing values of <span class="math inline">X_2, \ldots, X_p</span></p></li>
</ul>
<p><strong>Note:</strong> We start counting from <span class="math inline">2</span> for notational convenience</p>
</section>
<section id="mutiple-linear-regression-model" class="slide level2 smaller">
<h2>Mutiple linear regression model</h2>
<p><strong>Assumption:</strong> For each <span class="math inline">i=1, \ldots, n</span> we assume given observations</p>
<div class="column" style="width:42%;">
<ul>
<li>data point <span class="math inline">(x_{i2}, \ldots, x_{ip}, y_i)</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">x_{ij}</span> is from <span class="math inline">X_j</span></li>
</ul>
</div><div class="column" style="width:26%;">
<ul>
<li><span class="math inline">y_i</span> is from <span class="math inline">Y</span></li>
</ul>
</div><ul>
<li>Denote by <span class="math inline">Y_i</span> the random variable <span class="math inline">Y | x_{i2} ,\ldots, x_{ip}</span></li>
</ul>
<div id="Definition*-5.1" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The multiple linear regression model is <span class="math display">
Y_i = \beta_1 + \beta_2 x_{i2} + \ldots + \beta_p x_{ip} + \varepsilon_i
</span> where the <strong>residuals</strong> satisfy <span class="math display">
\varepsilon_1,\ldots, \varepsilon_n \,\, \text{ iid } \,\, N(0,\sigma^2)
</span><p></p>
</div></details>
</div>
</section>
<section id="mutiple-vs-general-linear-regression" class="slide level2 smaller">
<h2>Mutiple vs General linear regression</h2>
<ul>
<li><p>Multiple linear regression is special case of general linear regression</p></li>
<li><p>To see this, consider a <em>general linear model</em> with <span class="math inline">p</span> parameters</p></li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \beta_2 z_{i2} + \ldots  + \beta_p z_{ip}  + \varepsilon_i \,, \qquad i = 1 , \ldots, n
</span></p>
<ul>
<li>We want to compare the above to the <em>multiple regression model</em></li>
</ul>
<p><span class="math display">
Y_i = \beta_1 + \beta_2 x_{i2} + \ldots + \beta_p x_{ip} + \varepsilon_i
</span></p>
<ul>
<li>The 2 models are equivalent iff</li>
</ul>
<p><span class="math display">
z_{i1} = 1 \,, \qquad z_{i2} = x_{i2} \,, \qquad \ldots  \qquad  z_{ip} = x_{ip} \qquad \forall \, i = 1 , \ldots, n
</span></p>
</section>
<section id="mutiple-linear-regression-estimator" class="slide level2 smaller">
<h2>Mutiple linear regression estimator</h2>
<ul>
<li>Hence the design matrix <span class="math inline">Z</span> and data vector <span class="math inline">y</span> are</li>
</ul>
<p><span class="math display">
Z =
\left(
\begin{array}{cccc}
1 &amp; x_{12} &amp; \ldots &amp; x_{1p} \\
1 &amp; x_{22} &amp; \ldots &amp; x_{2p} \\
\ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
1 &amp; x_{n2} &amp; \ldots &amp; x_{np} \\
\end{array}
\right) \,, \qquad
y = \left(
\begin{array}{c}
y_1 \\
\ldots \\
y_n \\
\end{array}
\right)
</span> <strong>The design matrix includes a first column of 1s to account for the intercept</strong></p>
<ul>
<li><p><span class="math inline">Z</span> has size <span class="math inline">n \times p</span></p></li>
<li><p><span class="math inline">y</span> has size <span class="math inline">n \times 1</span></p></li>
<li><p>The <strong>MLE</strong> for multiple regression is therefore <span class="math inline">\hat \beta \in \mathbb{R}^p</span> <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p></li>
</ul>
</section></section>
<section>
<section id="part-5-coefficient-of-determination-r2" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 5: <br>Coefficient of <br>determination <span class="math inline">R^2</span></h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="how-good-is-the-model" class="slide level2 smaller">
<h2>How good is the model?</h2>
<ul>
<li>Consider the general linear regression model</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1}  + \ldots + \beta_p \, z_{ip} + \varepsilon_i
</span></p>
<ul>
<li>Given the observed values <span class="math inline">y = (y_1, \ldots, y_n)</span>, compute the MLE by</li>
</ul>
<p><span class="math display">
\hat \beta = (\hat \beta_1, \ldots, \hat \beta_p ) = (Z^T Z)^{-1} Z^T y
</span></p>
<div id="Problem*-6.1" class="Problem">
<p></p><details class="Problem fbx-simplebox fbx-default" open=""><summary><strong>Problem</strong></summary><div>Quantify how well the model fits the <strong>observed values</strong><p></p>
<p><span class="math display">
y_1 , \ldots, y_n
</span></p>
</div></details>
</div>
</section>
<section id="section-15" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>The <strong>predicted values</strong> are <span class="math display">
\hat y_i := {\rm I\kern-.3em E}[ Y | z_{i1}, \ldots , z_{ip} ]
        =  \hat \beta_1 \, z_{i1} + \ldots + \hat \beta_p \, z_{ip}  \quad \implies \quad \hat y = Z \hat \beta
</span></p></li>
<li><p>Recall: the <strong>Residual sum of squares</strong> is <span class="math display">
\mathop{\mathrm{RSS}}:= \sum_{i=1}^n ( y_i - \hat y_i )^2
</span> <span class="math inline">\mathop{\mathrm{RSS}}</span> measures deviation of predicted values from observed values</p></li>
</ul>
<p><span class="math display">
\text{Model is good } \,\, \iff \,\,  \hat{y}_i \approx y_i \, \quad \forall \, i \,\, \iff \,\, \mathop{\mathrm{RSS}}\, \text{ is small}
</span></p>
<ul>
<li><strong>However:</strong> <span class="math inline">\mathop{\mathrm{RSS}}</span> is a relative measure of precision
<ul>
<li>Need to rescale <span class="math inline">\mathop{\mathrm{RSS}}</span>, which will lead to the coefficient of determination <span class="math inline">R^2</span></li>
<li>To this end, we need some preliminary results</li>
</ul></li>
</ul>
</section>
<section id="normal-equation-for-general-regression" class="slide level2 smaller">
<h2>Normal equation for General Regression</h2>
<div id="Lemma*-6.2" class="Lemma">
<p></p><details class="Lemma fbx-simplebox fbx-default" open=""><summary><strong>Lemma</strong></summary><div>Suppose given the general linear regression model<p></p>
<p><span class="math display">
Y_i =  \beta_1 z_{i1} + \ldots + \beta_p z_{ip}  + \varepsilon_{i}
</span> for errors <span class="math inline">\varepsilon_1 , \ldots, \varepsilon_n</span> iid <span class="math inline">N(0,\sigma^2)</span>. Define the <strong>observed errors</strong> <span class="math display">
\hat{\varepsilon}_i = y_i - \hat{y}_i
</span> Then the <strong>normal equation</strong> is satisfied <span class="math display">
\hat{\varepsilon}^T Z = \mathbf{0}
</span></p>
</div></details>
</div>
</section>
<section id="proof-3" class="slide level2 smaller">
<h2>Proof</h2>
<p><span class="math display">\begin{align*}
\hat{\varepsilon}^T Z &amp; = (y - \hat y)^T Z &amp; \hat{\varepsilon} = y - \hat{y} \\
             &amp; = (y - Z \hat{\beta})^T Z &amp;  \hat{y} = Z\hat{\beta} \\
             &amp; = (y - Z (Z^T Z)^{-1} Z^T y)^T Z &amp; \hat{\beta} = (Z^T Z)^{-1} Z^T y \\
             &amp; = y^T (I - Z (Z^T Z)^{-1} Z^T )^T Z   &amp; \text{factor } \,y \\
             &amp; = y^T (I - Z (Z^T Z)^{-1} Z^T )^T (Z^T)^T  &amp; Z = (Z^T)^T\\
             &amp; = y^T [  Z^T (I  - Z (Z^T Z)^{-1} Z^T ) ]^T   &amp; (AB)^T = B^TA^T \\
             &amp; = y^T [  Z^T - \underbrace{Z^T Z (Z^T Z)^{-1}}_{I} \ Z^T ]^T \\[10pt]
             &amp; = y^T \left[  Z^T - Z^T  \right]^T = \mathbf{0}
\end{align*}</span></p>
</section>
<section id="total-sum-of-squares" class="slide level2 smaller">
<h2>Total sum of squares</h2>
<ul>
<li>The <strong>total sum of squares</strong> is</li>
</ul>
<p><span class="math display">
\mathop{\mathrm{TSS}}:= \sum_{i=1}^n ( y_i - \overline{y} )^2
</span></p>
<ul>
<li><p><span class="math inline">\mathop{\mathrm{TSS}}</span> measures deviation of observed values from the grand mean</p></li>
<li><p>Hence <span class="math inline">\mathop{\mathrm{TSS}}</span> measures variability of the observed data <span class="math inline">y_1 , \ldots, y_n</span></p>
<ul>
<li>If data very variable, then usually <span class="math inline">y_i</span> is far from <span class="math inline">\overline{y} \implies \mathop{\mathrm{TSS}}</span> is large</li>
<li>If data not very variable, then <span class="math inline">y_i \approx \overline{y} \implies \mathop{\mathrm{TSS}}</span> is small</li>
</ul></li>
</ul>
<p><strong>Goal:</strong> Decompose the <span class="math inline">\mathop{\mathrm{TSS}}</span></p>
</section>
<section id="mathopmathrmrss-and-mathopmathrmess" class="slide level2 smaller">
<h2><span class="math inline">\mathop{\mathrm{RSS}}</span> and <span class="math inline">\mathop{\mathrm{ESS}}</span></h2>
<ul>
<li><p>Recall: the <strong>Residual sum of squares</strong> is <span class="math display">
\mathop{\mathrm{RSS}}:= \sum_{i=1}^n ( y_i - \hat y_i )^2
</span> The <span class="math inline">\mathop{\mathrm{RSS}}</span> measures deviation of predicted values from observed values</p></li>
<li><p>Introduce the <strong>explained sum of squares</strong> by <span class="math display">
\mathop{\mathrm{ESS}}:= \sum_{i=1}^n ( \hat y_i - \overline{y} )^2
</span> <span class="math inline">\mathop{\mathrm{ESS}}</span> measures deviation of predicted values from the grand mean</p></li>
</ul>
</section>
<section id="decomposition-of-mathopmathrmtss" class="slide level2 smaller">
<h2>Decomposition of <span class="math inline">\mathop{\mathrm{TSS}}</span></h2>
<div id="Theorem*-6.3" class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose given the general linear regression model<p></p>
<p><span class="math display">
Y_i =  \beta_1 z_{i1} + \ldots + \beta_p z_{ip}  + \varepsilon_{i}
</span> for errors <span class="math inline">\varepsilon_1 , \ldots, \varepsilon_n</span> iid <span class="math inline">N(0,\sigma^2)</span>. Then</p>
<p><span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}-  2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
</span> where the observed errors are <span class="math display">
\hat{\varepsilon}_i = y_i - \hat{y}_i
</span></p>
</div></details>
</div>
</section>
<section id="proof-4" class="slide level2 smaller">
<h2>Proof</h2>
<p><strong>Trick:</strong> Add and substract <span class="math inline">\hat{y}_i</span>, then expand:</p>
<p><span class="math display">\begin{align*}
\mathop{\mathrm{TSS}}&amp; = \sum_{i=1}^n (y_i - \overline{y})^2 \\
&amp; = \sum_{i=1}^n \left[ (\hat{y}_i - \overline{y})  + (y_i - \hat{y}_i) \right]^2 \\
  &amp; = \sum_{i=1}^n (\hat{y}_i - \overline{y})^2  + (y_i - \hat{y}_i)^2 + 2 (\hat{y}_i - \overline{y})  \underbrace{(y_i - \hat{y}_i)}_{\hat{\varepsilon}_i} \\
  &amp; = \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}+ 2 \sum_{i=1}^n \hat{y}_i \hat{\varepsilon}_i - 2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
\end{align*}</span></p>
</section>
<section id="section-16" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Recall the <strong>normal equation</strong></li>
</ul>
<p><span class="math display">
\hat{\varepsilon}^T Z = \mathbf{0}
</span></p>
<ul>
<li>Using again that <span class="math inline">\hat y = Z \hat{\beta}</span>, we get</li>
</ul>
<p><span class="math display">
\sum_{i=1}^n \hat{y}_i \hat{\varepsilon}_i =
\hat{\varepsilon}^T \hat{y} =
\hat{\varepsilon}^T Z \hat{\beta} =
\mathbf{0} \hat{\beta} = 0
</span></p>
<ul>
<li>From the above, we conclude the thesis: <span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}+ 2 \underbrace{ \sum_{i=1}^n \hat{y}_i \hat{\varepsilon}_i}_{0} - 2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
  = \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}- 2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
</span></li>
</ul>
</section>
<section id="multiple-regression-mathopmathrmtss-mathopmathrmess-mathopmathrmrss" class="slide level2 smaller">
<h2>Multiple regression: <span class="math inline">\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}</span></h2>
<div id="Theorem*-6.4" class="Theorem">
<p></p><details class="Theorem fbx-simplebox fbx-default" open=""><summary><strong>Theorem</strong></summary><div>Suppose given the multiple regression linear model<p></p>
<p><span class="math display">
Y_i =  \beta_1 + \beta_2 x_{i2} + \ldots + \beta_p x_{ip}  + \varepsilon_{i}
</span> for errors <span class="math inline">\varepsilon_1 , \ldots, \varepsilon_n</span> iid <span class="math inline">N(0,\sigma^2)</span>. Then, the sum of errors is zero <span class="math display">
\sum_{i=1}^n \hat{\varepsilon}_i = 0 \,,
</span> where <span class="math inline">\hat{\varepsilon}_i = y_i - \hat{y}_i</span>. In particular, the following decomposition holds <span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}
</span></p>
</div></details>
</div>
</section>
<section id="proof-5" class="slide level2 smaller">
<h2>Proof</h2>
<ul>
<li>Since we are dealing with multiple linear regression, <span class="math inline">Z</span> has the form</li>
</ul>
<p><span class="math display">
Z =
\left(
\begin{array}{cccc}
1 &amp; x_{12} &amp; \ldots &amp; x_{1p} \\
1 &amp; x_{22} &amp; \ldots &amp; x_{2p} \\
\ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
1 &amp; x_{n2} &amp; \ldots &amp; x_{np} \\
\end{array}
\right)
</span></p>
<ul>
<li>Therefore, we have that</li>
</ul>
<p><span class="math display">
\hat{\varepsilon}^T Z =
(\hat{\varepsilon}_1 , \ldots, \hat{\varepsilon}_n)
\left(
\begin{array}{cccc}
1 &amp; x_{12} &amp; \ldots &amp; x_{1p} \\
1 &amp; x_{22} &amp; \ldots &amp; x_{2p} \\
\ldots &amp; \ldots &amp; \ldots &amp; \ldots \\
1 &amp; x_{n2} &amp; \ldots &amp; x_{np} \\
\end{array}
\right) = \left(  \sum_{i=1}^n \hat{\varepsilon}_i , \ast , \ldots, \ast  \right)
</span></p>
</section>
<section id="section-17" class="slide level2 smaller">
<h2></h2>
<ul>
<li>The normal equation says that</li>
</ul>
<p><span class="math display">
\hat{\varepsilon}^T Z = \mathbf{0}
</span></p>
<ul>
<li>Therefore, we conclude that</li>
</ul>
<p><span class="math display">
\hat{\varepsilon}^T Z  = \left(  \sum_{i=1}^n \hat{\varepsilon}_i , \ast , \ldots, \ast  \right) = (0, 0, \ldots, 0)
</span></p>
<ul>
<li>From the above, we infer that the <strong>sum of the errors is zero</strong></li>
</ul>
<p><span class="math display">
\sum_{i=1}^n \hat{\varepsilon}_i = 0
</span></p>
</section>
<section id="section-18" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Multiple linear regression is a special case of general linear regression</p></li>
<li><p>Therefore, we can apply the previous Theorem to get <span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}-  2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
</span></p></li>
<li><p>In the previous slide we have shown that</p></li>
</ul>
<p><span class="math display">
\sum_{i=1}^n \hat{\varepsilon}_i = 0
</span></p>
<ul>
<li>Therefore, the thesis follows</li>
</ul>
<p><span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}-  2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i =  \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}
</span></p>
</section>
<section id="coefficient-of-determination-r2" class="slide level2 smaller">
<h2>Coefficient of determination <span class="math inline">R^2</span></h2>
<p>Consider the general linear regression model <span class="math display">
Y_i = \beta_1 z_{i1}  + \ldots + \beta_p \, z_{ip} + \varepsilon_i
</span> For observed data <span class="math inline">y = (y_1, \ldots, y_n)</span>, define the predictions by <span class="math display">
\hat{y} = Z\hat{\beta}  \,, \qquad \hat{\beta} = (Z^TZ)^{-1} Z^T y
</span></p>
<div id="Definition*-6.5" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The <strong>coefficient of determination</strong> is <span class="math display">
R^2 := 1 -  \frac{ \mathop{\mathrm{RSS}}}{ \mathop{\mathrm{TSS}}} = 1 - \frac{ \sum_{i=1}^n ( y_i - \hat y_i  )^2 }{ \sum_{i=1}^n ( y_i - \overline{y} )^2 }
</span><p></p>
</div></details>
</div>
</section>
<section id="properties-of-r2" class="slide level2 smaller">
<h2>Properties of <span class="math inline">R^2</span></h2>
<div id="Proposition*-6.6" class="Proposition">
<p></p><details class="Proposition fbx-simplebox fbx-default" open=""><summary><strong>Proposition</strong></summary><div>For the general linear regression model, we have that<p></p>
<p><span class="math display">
R^2 \leq 1
</span></p>
<p>Moreover</p>
<p><span class="math display">
R^2 = 1 \qquad \iff \qquad y_i = \hat y_i \quad \,\, \forall \, i = 1 , \ldots, n
</span></p>
</div></details>
</div>
</section>
<section id="proof-6" class="slide level2 smaller">
<h2>Proof</h2>
<ul>
<li><p>Since <span class="math inline">\mathop{\mathrm{RSS}}</span> and <span class="math inline">\mathop{\mathrm{TSS}}</span> are sums of squares, we have that <span class="math inline">\mathop{\mathrm{TSS}},  \, \mathop{\mathrm{RSS}}\geq 0</span></p></li>
<li><p>Therefore, the first part of the statemet follows immediately <span class="math display">
R^2 := 1 - \frac{\mathop{\mathrm{RSS}}}{\mathop{\mathrm{TSS}}}  \leq 1
</span></p></li>
<li><p>Moreover, recalling the definition of <span class="math inline">\mathop{\mathrm{RSS}}</span>, we have that <span class="math display">
\mathop{\mathrm{RSS}}= \sum_{i=1}^n (y_i - \hat{y}_i)^2 = 0 \quad \iff \quad
\hat{y}_i = y_i \quad \forall \, i
</span></p></li>
<li><p>The thesis immediately follows: <span class="math display">
R^2 = 1 \,\, \iff \,\, 1 - \frac{\mathop{\mathrm{RSS}}}{\mathop{\mathrm{TSS}}} = 1  \,\, \iff \,\, \mathop{\mathrm{RSS}}= 0 \,\, \iff \,\,
\hat{y}_i = y_i \quad \forall \, i
</span></p></li>
</ul>
</section>
<section id="r2-might-be-negative" class="slide level2 smaller">
<h2><span class="math inline">R^2</span> might be negative</h2>
<div id="Proposition*-6.7" class="Proposition">
<details class="Proposition fbx-simplebox fbx-default" open=""><summary><strong>Proposition</strong></summary><div>
<ol type="1">
<li><p>For the <strong>general</strong> linear regression model, it might hold that <span class="math display">
R^2 &lt; 0
</span></p></li>
<li><p>For the <strong>multiple</strong> regression model, it always holds that <span class="math display">
0 \leq R^2 \leq 1
</span></p></li>
</ol>
</div></details>
</div>
<p>Bottom line:</p>
<ul>
<li><p><span class="math inline">R^2</span> can be negative for general regression (i.e.&nbsp;when no intercept is present)</p></li>
<li><p><span class="math inline">0 \leq R^2 \leq 1</span> for multiple regression (i.e.&nbsp;when intercept is present)</p></li>
</ul>
</section>
<section id="proof-7" class="slide level2 smaller">
<h2>Proof</h2>
<ol type="1">
<li>For general linear regression, the following decomposition holds (Thm Slide 85) <span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}-  2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i
</span></li>
</ol>
<ul>
<li><p>By definition of <span class="math inline">R^2</span>, we have <span class="math display">
R^2 := 1 - \frac{ \mathop{\mathrm{RSS}}}{ \mathop{\mathrm{TSS}}} = \underbrace{\frac{\mathop{\mathrm{ESS}}}{\mathop{\mathrm{TSS}}}}_{\geq 0} - \underbrace{\frac{2 \overline{y} \sum_{i=1}^n \hat{\varepsilon}_i}{\mathop{\mathrm{TSS}}}}_{\text{can have any sign}}
</span></p></li>
<li><p>Since the last term can have any sign, it might hold that <span class="math inline">R^2 &lt; 0</span></p></li>
</ul>
</section>
<section id="section-19" class="slide level2 smaller">
<h2></h2>
<ol start="2" type="1">
<li>For multiple linear regression, the following decomposition holds (Thm Slide 88) <span class="math display">
\mathop{\mathrm{TSS}}= \mathop{\mathrm{ESS}}+ \mathop{\mathrm{RSS}}
</span></li>
</ol>
<ul>
<li>By definition of <span class="math inline">R^2</span>, we have</li>
</ul>
<p><span class="math display">
R^2 := 1 - \frac{ \mathop{\mathrm{RSS}}}{ \mathop{\mathrm{TSS}}} = \frac{\mathop{\mathrm{ESS}}}{\mathop{\mathrm{TSS}}} \geq 0
</span></p>
<ul>
<li>Therefore, we conclude that</li>
</ul>
<p><span class="math display">
0 \leq R^2 \leq 1
</span></p>
</section>
<section id="conclusion" class="slide level2 smaller">
<h2>Conclusion</h2>
<p>We have shown that</p>
<ul>
<li><p><span class="math inline">R^2 \leq 1</span></p></li>
<li><p><span class="math inline">R^2 = 1 \quad \iff \quad y_i = \hat y_i \quad \,\, \forall \, i = 1 , \ldots, n</span></p></li>
</ul>
<p><strong>Conclusion:</strong> <span class="math inline">R^2</span> measures how well the model fits the data</p>
<p><span class="math display">
R^2  \, \text{ close to } \, 1 \quad \implies \quad \text{  model fits data well}
</span></p>
<p><br></p>
<p><strong>Warning:</strong> <span class="math inline">R^2</span> can be negative for general regression (no intercept)</p>
</section></section>
<section>
<section id="part-6-example-of-multiple-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 6: <br>Example of <br>multiple regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="example-predicting-unemployment" class="slide level2 smaller">
<h2>Example: Predicting unemployment</h2>
<div class="column" style="width:55%;">
<p><strong>Goal:</strong> Predict unemployment rates</p>
<ul>
<li>Unemp. related to Productivity Index</li>
<li>Other factors might also play a role</li>
<li>These factors likely depend on the year</li>
<li>Use year as surrogate for other factors</li>
</ul>
</div><div class="column" style="width:42%;">
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 30%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Unemp.</th>
<th style="text-align: center;">Product.</th>
<th style="text-align: center;">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">113</td>
<td style="text-align: center;">1950</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">1951</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">1952</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">138</td>
<td style="text-align: center;">1953</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">1954</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">146</td>
<td style="text-align: center;">1955</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">151</td>
<td style="text-align: center;">1956</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.9</td>
<td style="text-align: center;">152</td>
<td style="text-align: center;">1957</td>
</tr>
<tr class="odd">
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">1958</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">159</td>
<td style="text-align: center;">1959</td>
</tr>
</tbody>
</table>
</div></section>
<section id="enter-the-data" class="slide level2 smaller">
<h2>Enter the data</h2>
<ul>
<li>Enter the data in 3 vectors</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Unemployment data</span></span>
<span id="cb1-2"><a aria-hidden="true" tabindex="-1"></a>unemployment <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.1</span>, <span class="fl">1.9</span>, <span class="fl">1.7</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">2.7</span>, <span class="fl">2.6</span>, <span class="fl">2.9</span>, <span class="fl">4.7</span>, <span class="fl">3.8</span>)</span>
<span id="cb1-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Productivity data</span></span>
<span id="cb1-5"><a aria-hidden="true" tabindex="-1"></a>productivity <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">113</span>, <span class="dv">123</span>, <span class="dv">127</span>, <span class="dv">138</span>, <span class="dv">130</span>, <span class="dv">146</span>, <span class="dv">151</span>, <span class="dv">152</span>, <span class="dv">141</span>, <span class="dv">159</span>)</span>
<span id="cb1-6"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Year data</span></span>
<span id="cb1-8"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1950</span>, <span class="dv">1959</span>, <span class="at">by =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="plotting-the-data" class="slide level2 smaller">
<h2>Plotting the data</h2>
<ul>
<li>Want to see if either <em>Productivity</em> or <em>Year</em> predict <em>Unemployment</em>. Therefore, plot
<ul>
<li>Productivity Vs Unemployment</li>
<li>Year Vs Unemployment</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the layout with two plot panels side by side</span></span>
<span id="cb2-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb2-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot: Productivity vs Unemployment</span></span>
<span id="cb2-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(productivity, unemployment, </span>
<span id="cb2-6"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Productivity"</span>, <span class="at">ylab =</span> <span class="st">"Unemployment"</span>,</span>
<span id="cb2-7"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Productivity vs Unemployment"</span>, </span>
<span id="cb2-8"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb2-9"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot: Year vs Unemployment</span></span>
<span id="cb2-11"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, unemployment, </span>
<span id="cb2-12"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Year"</span>, <span class="at">ylab =</span> <span class="st">"Unemployment"</span>,</span>
<span id="cb2-13"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Year vs Unemployment"</span>, </span>
<span id="cb2-14"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="output" class="slide level2 smaller">
<h2>Output</h2>
<h3 id="there-appears-to-be-some-linear-relationship">There appears to be some linear relationship</h3>

<img data-src="lecture_8_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch"></section>
<section id="plotting-the-data-in-3d" class="slide level2 smaller">
<h2>Plotting the data in 3D</h2>
<p>To better understand the data we can do a 3D scatter plot using either</p>
<ul>
<li><code>scatterplot3D</code>
<ul>
<li>installed via <code>install.packages("scatterplot3d")</code></li>
<li>produces static plots</li>
</ul></li>
<li><code>plotly</code>
<ul>
<li>installed via <code>install.packages("plotly")</code></li>
<li>produces interactive plots</li>
</ul></li>
</ul>
</section>
<section id="plotting-the-data-with-scatterplot3d" class="slide level2 smaller">
<h2>Plotting the data with <code>scatterplot3d</code></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Load the scatterplot3d library</span></span>
<span id="cb3-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scatterplot3d)</span>
<span id="cb3-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Create 3D scatter plot</span></span>
<span id="cb3-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">scatterplot3d</span>(<span class="at">x =</span> productivity,</span>
<span id="cb3-6"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">y =</span> year,</span>
<span id="cb3-7"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">z =</span> unemployment, </span>
<span id="cb3-8"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">main =</span> <span class="st">"Productivity and Year vs Unemployment"</span>, </span>
<span id="cb3-9"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">xlab =</span> <span class="st">"Productivity"</span>, </span>
<span id="cb3-10"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">ylab =</span> <span class="st">"Year"</span>, </span>
<span id="cb3-11"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">zlab =</span> <span class="st">"Unemployment"</span>,</span>
<span id="cb3-12"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb3-13"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb3-14"><a aria-hidden="true" tabindex="-1"></a>              <span class="at">angle =</span> <span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="plotting-the-data-with-scatterplot3d-1" class="slide level2 smaller">
<h2>Plotting the data with <code>scatterplot3d</code></h2>
<h3 id="the-data-is-clearly-close-to-a-plane">The data is clearly close to a plane</h3>

<img data-src="lecture_8_files/figure-revealjs/unnamed-chunk-5-1.png" width="960" class="r-stretch"></section>
<section id="plotting-the-data-with-plotly" class="slide level2 smaller">
<h2>Plotting the data with <code>plotly</code></h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Load the plotly library</span></span>
<span id="cb4-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb4-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot using plot_ly</span></span>
<span id="cb4-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(<span class="at">x =</span> productivity, </span>
<span id="cb4-6"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> year, </span>
<span id="cb4-7"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">z =</span> unemployment, </span>
<span id="cb4-8"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">"scatter3d"</span>, </span>
<span id="cb4-9"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">"markers"</span>,</span>
<span id="cb4-10"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">marker =</span> <span class="fu">list</span>(<span class="at">size =</span> <span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb4-11"><a aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(<span class="at">scene =</span> <span class="fu">list</span>(<span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Productivity"</span>),</span>
<span id="cb4-12"><a aria-hidden="true" tabindex="-1"></a>                      <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Year"</span>),</span>
<span id="cb4-13"><a aria-hidden="true" tabindex="-1"></a>                      <span class="at">zaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Unemployment"</span>)),</span>
<span id="cb4-14"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">width =</span> <span class="dv">1000</span>, </span>
<span id="cb4-15"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">height =</span> <span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="plotting-the-data-with-plotly-1" class="slide level2 smaller">
<h2>Plotting the data with <code>plotly</code></h2>
<h3 id="the-data-is-clearly-close-to-a-plane-1">The data is clearly close to a plane</h3>
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-a6ad63af541db2d57584" style="width:960px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-a6ad63af541db2d57584">{"x":{"visdat":{"91bb268e0e09":["function () ","plotlyVisDat"]},"cur_data":"91bb268e0e09","attrs":{"91bb268e0e09":{"x":[113,123,127,138,130,146,151,152,141,159],"y":[1950,1951,1952,1953,1954,1955,1956,1957,1958,1959],"z":[3.1000000000000001,1.8999999999999999,1.7,1.6000000000000001,3.2000000000000002,2.7000000000000002,2.6000000000000001,2.8999999999999999,4.7000000000000002,3.7999999999999998],"mode":"markers","marker":{"size":5,"color":"black"},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d"}},"layout":{"width":1000,"height":500,"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Productivity"},"yaxis":{"title":"Year"},"zaxis":{"title":"Unemployment"}},"hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[113,123,127,138,130,146,151,152,141,159],"y":[1950,1951,1952,1953,1954,1955,1956,1957,1958,1959],"z":[3.1000000000000001,1.8999999999999999,1.7,1.6000000000000001,3.2000000000000002,2.7000000000000002,2.6000000000000001,2.8999999999999999,4.7000000000000002,3.7999999999999998],"mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(31,119,180,1)"}},"type":"scatter3d","error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
<section id="setting-up-multiple-regression-model" class="slide level2 smaller">
<h2>Setting up multiple regression model</h2>
<ul>
<li><p>We saw that the data points <span class="math display">
( \text{Productivity}, \text{Year}, \text{Unemployment}  ) \in R^3
</span> roughly lie on a <strong>plane</strong></p></li>
<li><p><strong>Goal:</strong> Use multiple regression to compute such plane</p>
<ul>
<li>Unemployment is modelled by response variable <span class="math inline">Y</span></li>
<li>Productivity is modelled by predictor <span class="math inline">X_2</span></li>
<li>Year is modelled by predictor <span class="math inline">X_3</span></li>
<li>The multiple regression model is <span class="math display">
{\rm I\kern-.3em E}[Y | x_2, x_3] = \beta_1 + \beta_2 \, x_2 + \beta_3 \, x_3
</span></li>
</ul></li>
</ul>
</section>
<section id="exercise" class="slide level2 smaller">
<h2>Exercise</h2>
<div class="column" style="width:54%;">
<p>Multiple regression model is <span class="math display">
{\rm I\kern-.3em E}[Y | x_2, x_3] = \beta_1 + \beta_2 \, x_2 + \beta_3 \, x_3
</span></p>
<ul>
<li>Enter design matrix <code>Z</code> into R</li>
<li>Enter data <code>y</code> into R</li>
<li>Compute estimator <span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span>
<ul>
<li>Matrix product in R is <span class="math inline">\,</span><code>%*%</code></li>
<li>Transpose matrix of <span class="math inline">\,</span><code>A</code><span class="math inline">\,</span> is <span class="math inline">\,</span><code>t(A)</code></li>
<li>Inverse of matrix <span class="math inline">\,</span><code>A</code><span class="math inline">\,</span> is <span class="math inline">\,</span><code>solve(A)</code></li>
</ul></li>
</ul>
</div><div class="column" style="width:45%;">
<div style="font-size: 0.85em">
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 30%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Unemp.</th>
<th style="text-align: center;">Product.</th>
<th style="text-align: center;">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">y_i</span></td>
<td style="text-align: center;"><span class="math inline">x_{i2}</span></td>
<td style="text-align: center;"><span class="math inline">x_{i3}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">113</td>
<td style="text-align: center;">1950</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">1951</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">1952</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">138</td>
<td style="text-align: center;">1953</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">1954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">146</td>
<td style="text-align: center;">1955</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">151</td>
<td style="text-align: center;">1956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.9</td>
<td style="text-align: center;">152</td>
<td style="text-align: center;">1957</td>
</tr>
<tr class="even">
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">1958</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">159</td>
<td style="text-align: center;">1959</td>
</tr>
</tbody>
</table>
</div>
</div></section>
<section id="solution" class="slide level2 smaller">
<h2>Solution</h2>
<div class="column" style="width:54%;">
<p>The design matrix is <span class="math display">
Z=\left(\begin{array}{cccc}
    1 &amp; 113 &amp; 1950 \\
    1 &amp; 123 &amp; 1951 \\
    1 &amp; 127 &amp; 1952 \\
    1 &amp; 138 &amp; 1953 \\
    1 &amp; 130 &amp; 1954 \\
    1 &amp; 146 &amp; 1955 \\
    1 &amp; 151 &amp; 1956 \\
    1 &amp; 152 &amp; 1957 \\
    1 &amp; 141 &amp; 1958 \\
    1 &amp; 159 &amp; 1959 \\
\end{array}\right)
</span></p>
</div><div class="column" style="width:45%;">
<div style="font-size: 0.85em">
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 30%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Unemp.</th>
<th style="text-align: center;">Product.</th>
<th style="text-align: center;">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">y_i</span></td>
<td style="text-align: center;"><span class="math inline">x_{i2}</span></td>
<td style="text-align: center;"><span class="math inline">x_{i3}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">113</td>
<td style="text-align: center;">1950</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">1951</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">1952</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">138</td>
<td style="text-align: center;">1953</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">1954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">146</td>
<td style="text-align: center;">1955</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">151</td>
<td style="text-align: center;">1956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.9</td>
<td style="text-align: center;">152</td>
<td style="text-align: center;">1957</td>
</tr>
<tr class="even">
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">1958</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">159</td>
<td style="text-align: center;">1959</td>
</tr>
</tbody>
</table>
</div>
</div></section>
<section id="solution-1" class="slide level2 smaller">
<h2>Solution</h2>
<div class="column" style="width:54%;">
<p>The data vector is <span class="math display">
y =
\left(\begin{array}{c}
3.1 \\
1.9 \\
1.7 \\
1.6 \\
3.2 \\
2.7 \\
2.6 \\
2.9 \\
4.7 \\
3.8 \\
\end{array}\right)
</span></p>
</div><div class="column" style="width:45%;">
<div style="font-size: 0.85em">
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 30%">
<col style="width: 35%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Unemp.</th>
<th style="text-align: center;">Product.</th>
<th style="text-align: center;">Year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">y_i</span></td>
<td style="text-align: center;"><span class="math inline">x_{i2}</span></td>
<td style="text-align: center;"><span class="math inline">x_{i3}</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">113</td>
<td style="text-align: center;">1950</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">1951</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">1952</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">138</td>
<td style="text-align: center;">1953</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">1954</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">146</td>
<td style="text-align: center;">1955</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">151</td>
<td style="text-align: center;">1956</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.9</td>
<td style="text-align: center;">152</td>
<td style="text-align: center;">1957</td>
</tr>
<tr class="even">
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">1958</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.8</td>
<td style="text-align: center;">159</td>
<td style="text-align: center;">1959</td>
</tr>
</tbody>
</table>
</div>
</div></section>
<section id="solution-2" class="slide level2 smaller">
<h2>Solution</h2>
<div style="font-size: 0.93em">
<ul>
<li>Data vector <span class="math inline">y</span> is stored in R as usual</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Store vector y</span></span>
<span id="cb5-2"><a aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.1</span>, <span class="fl">1.9</span>, <span class="fl">1.7</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">2.7</span>, <span class="fl">2.6</span>, <span class="fl">2.9</span>, <span class="fl">4.7</span>, <span class="fl">3.8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Design matrix is stored as follows</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Store design matrix Z as long vector</span></span>
<span id="cb6-2"><a aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">113</span>, <span class="dv">1950</span>,</span>
<span id="cb6-3"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">123</span>, <span class="dv">1951</span>,</span>
<span id="cb6-4"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">127</span>, <span class="dv">1952</span>,</span>
<span id="cb6-5"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">138</span>, <span class="dv">1953</span>,</span>
<span id="cb6-6"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">130</span>, <span class="dv">1954</span>,</span>
<span id="cb6-7"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">146</span>, <span class="dv">1955</span>,</span>
<span id="cb6-8"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">151</span>, <span class="dv">1956</span>,</span>
<span id="cb6-9"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">152</span>, <span class="dv">1957</span>,</span>
<span id="cb6-10"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">141</span>, <span class="dv">1958</span>,</span>
<span id="cb6-11"><a aria-hidden="true" tabindex="-1"></a>       <span class="dv">1</span>, <span class="dv">159</span>, <span class="dv">1959</span>)</span>
<span id="cb6-12"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Make Z into a matrix with 3 columns</span></span>
<span id="cb6-14"><a aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">matrix</span>(Z, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="solution-3" class="slide level2 smaller">
<h2>Solution</h2>
<ul>
<li>We need to compute the estimator</li>
</ul>
<p><span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p>
<ul>
<li>The matrix transpose is computed with <span class="math inline">\,</span><code>t(A)</code></li>
<li>The product of two matrices <span class="math inline">A</span> and <span class="math inline">B</span> is computed with <span class="math inline">\,</span> <code>A %*% B</code></li>
<li>We use these two operators to compute <span class="math inline">Z^T Z</span> and store it into <code>m1</code></li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate m1</span></span>
<span id="cb7-2"><a aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">t</span>(Z) <span class="sc">%*%</span> Z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="solution-4" class="slide level2 smaller">
<h2>Solution</h2>
<ul>
<li>The inverse of a matrix <span class="math inline">A</span> is computed with <span class="math inline">\,</span> <code>solve(A)</code></li>
<li>We use this function to compute <span class="math inline">(Z^T Z)^{-1}</span> and store it into <code>m2</code></li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate m2</span></span>
<span id="cb8-2"><a aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">solve</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>We can compute <span class="math inline">Z^T y</span> with <span class="math inline">\,</span><code>%*%</code></li>
<li>This is because R automatically interprets vectors as matrices</li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate m3</span></span>
<span id="cb9-2"><a aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">t</span>(Z) <span class="sc">%*%</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="solution-5" class="slide level2 smaller">
<h2>Solution</h2>
<ul>
<li>We compute the estimator <span class="math display">\hat{\beta}=(Z^T Z)^{-1} Z^T y
</span> and store it as <span class="math inline">\,</span> <code>beta</code></li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate estimator beta</span></span>
<span id="cb10-2"><a aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> m2 <span class="sc">%*%</span> m3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>We then print the result to screen</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print estimator beta</span></span>
<span id="cb11-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"The estimator is"</span>, beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>The estimator is -1271.75 -0.1033386 0.6594171</code></pre>
</div>
</div>
</section>
<section id="solution-6" class="slide level2 smaller">
<h2>Solution</h2>
<ul>
<li>The computed regression model is</li>
</ul>
<p><span class="math display">\begin{align*}
{\rm I\kern-.3em E}[Y | x_2, x_3] &amp; = \hat\beta_1 + \hat\beta_2 \, x_2 + \hat\beta_3 \, x_3 \\[15pt]
&amp; = -1271.75 + (-0.1033386) \times x_2 + 0.6594171 \times x_3
\end{align*}</span></p>
<ul>
<li>This means</li>
</ul>
<p><span class="math display">\begin{align*}
\text{Predicted Unemployment}  =
-1271.75 &amp; + (-0.1033386) \times \text{Productivity}  \\[15pt]
  &amp; + (0.6594171) \times \text{Year}
\end{align*}</span></p>
<ul>
<li>Previous code can be downloaded here <a href="codes/multiple_regression.R">multiple_regression.R</a></li>
</ul>
</section>
<section id="plot-of-data-and-regression-plane" class="slide level2 smaller">
<h2>Plot of data and regression plane</h2>
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Load the plotly library</span></span>
<span id="cb13-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb13-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb13-5"><a aria-hidden="true" tabindex="-1"></a>unemployment <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.1</span>, <span class="fl">1.9</span>, <span class="fl">1.7</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">2.7</span>, <span class="fl">2.6</span>, <span class="fl">2.9</span>, <span class="fl">4.7</span>, <span class="fl">3.8</span>)</span>
<span id="cb13-6"><a aria-hidden="true" tabindex="-1"></a>productivity <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">113</span>, <span class="dv">123</span>, <span class="dv">127</span>, <span class="dv">138</span>, <span class="dv">130</span>, <span class="dv">146</span>, <span class="dv">151</span>, <span class="dv">152</span>, <span class="dv">141</span>, <span class="dv">159</span>)</span>
<span id="cb13-7"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1950</span>, <span class="dv">1959</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb13-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a grid of x and y values</span></span>
<span id="cb13-10"><a aria-hidden="true" tabindex="-1"></a>x_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(productivity), <span class="fu">max</span>(productivity), <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb13-11"><a aria-hidden="true" tabindex="-1"></a>y_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(year), <span class="fu">max</span>(year), <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb13-12"><a aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">productivity =</span> x_grid, <span class="at">year =</span> y_grid)</span>
<span id="cb13-13"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate z values for the regression plane</span></span>
<span id="cb13-15"><a aria-hidden="true" tabindex="-1"></a>z_values <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">1271.75</span> <span class="sc">-</span> <span class="fl">0.1033386</span> <span class="sc">*</span> grid<span class="sc">$</span>productivity <span class="sc">+</span> <span class="fl">0.6594171</span> <span class="sc">*</span> grid<span class="sc">$</span>year</span>
<span id="cb13-16"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot using plot_ly</span></span>
<span id="cb13-18"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot_ly</span>(<span class="at">x =</span> productivity, </span>
<span id="cb13-19"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> year, </span>
<span id="cb13-20"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">z =</span> unemployment, </span>
<span id="cb13-21"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">type =</span> <span class="st">"scatter3d"</span>, </span>
<span id="cb13-22"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">mode =</span> <span class="st">"markers"</span>,</span>
<span id="cb13-23"><a aria-hidden="true" tabindex="-1"></a>        <span class="at">marker =</span> <span class="fu">list</span>(<span class="at">size =</span> <span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb13-24"><a aria-hidden="true" tabindex="-1"></a>  <span class="fu">layout</span>(<span class="at">scene =</span> <span class="fu">list</span>(<span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Productivity"</span>),</span>
<span id="cb13-25"><a aria-hidden="true" tabindex="-1"></a>                      <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Year"</span>),</span>
<span id="cb13-26"><a aria-hidden="true" tabindex="-1"></a>                      <span class="at">zaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">"Unemployment"</span>)),</span>
<span id="cb13-27"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">width =</span> <span class="dv">1000</span>, </span>
<span id="cb13-28"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">height =</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb13-29"><a aria-hidden="true" tabindex="-1"></a>         <span class="fu">add_surface</span>(</span>
<span id="cb13-30"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">x =</span> x_grid, </span>
<span id="cb13-31"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">y =</span> y_grid, </span>
<span id="cb13-32"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">z =</span> <span class="fu">matrix</span>(z_values, <span class="at">nrow =</span> <span class="fu">length</span>(x_grid)),</span>
<span id="cb13-33"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">opacity =</span> <span class="fl">0.5</span>, </span>
<span id="cb13-34"><a aria-hidden="true" tabindex="-1"></a>         <span class="at">colorscale =</span> <span class="fu">list</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="st">'rgb(255,255,255)'</span>), <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">'rgb(255,0,0)'</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-bc546767f5666adf9db8" style="width:960px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-bc546767f5666adf9db8">{"x":{"visdat":{"91bb486f00ae":["function () ","plotlyVisDat"]},"cur_data":"91bb486f00ae","attrs":{"91bb486f00ae":{"x":[113,123,127,138,130,146,151,152,141,159],"y":[1950,1951,1952,1953,1954,1955,1956,1957,1958,1959],"z":[3.1000000000000001,1.8999999999999999,1.7,1.6000000000000001,3.2000000000000002,2.7000000000000002,2.6000000000000001,2.8999999999999999,4.7000000000000002,3.7999999999999998],"mode":"markers","marker":{"size":5,"color":"black"},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d"},"91bb486f00ae.1":{"x":[113,113.93877551020408,114.87755102040816,115.81632653061224,116.75510204081633,117.69387755102041,118.63265306122449,119.57142857142857,120.51020408163265,121.44897959183673,122.38775510204081,123.32653061224489,124.26530612244898,125.20408163265306,126.14285714285714,127.08163265306122,128.0204081632653,128.9591836734694,129.89795918367346,130.83673469387756,131.77551020408163,132.71428571428572,133.65306122448979,134.59183673469389,135.53061224489795,136.46938775510205,137.40816326530611,138.34693877551021,139.28571428571428,140.22448979591837,141.16326530612244,142.10204081632654,143.0408163265306,143.9795918367347,144.91836734693877,145.85714285714286,146.79591836734693,147.73469387755102,148.67346938775512,149.61224489795919,150.55102040816325,151.48979591836735,152.42857142857144,153.36734693877551,154.30612244897958,155.24489795918367,156.18367346938777,157.12244897959184,158.0612244897959,159],"y":[1950,1950.1836734693877,1950.3673469387754,1950.5510204081634,1950.7346938775511,1950.9183673469388,1951.1020408163265,1951.2857142857142,1951.4693877551019,1951.6530612244899,1951.8367346938776,1952.0204081632653,1952.204081632653,1952.3877551020407,1952.5714285714287,1952.7551020408164,1952.9387755102041,1953.1224489795918,1953.3061224489795,1953.4897959183672,1953.6734693877552,1953.8571428571429,1954.0408163265306,1954.2244897959183,1954.408163265306,1954.591836734694,1954.7755102040817,1954.9591836734694,1955.1428571428571,1955.3265306122448,1955.5102040816328,1955.6938775510205,1955.8775510204082,1956.0612244897959,1956.2448979591836,1956.4285714285713,1956.6122448979593,1956.795918367347,1956.9795918367347,1957.1632653061224,1957.3469387755101,1957.5306122448981,1957.7142857142858,1957.8979591836735,1958.0816326530612,1958.2653061224489,1958.4489795918366,1958.6326530612246,1958.8163265306123,1959],"z":[[2.4360831999999846,2.55720062653063,2.678318053061048,2.7994354795919207,2.9205529061223388,3.0416703326529841,3.1627877591836295,3.2839051857142749,3.4050226122446929,3.5261400387755657,3.6472574653062111,3.7683748918366291,3.8894923183672745,4.0106097448979199,4.1317271714285653,4.2528445979592107,4.373962024489856,4.4950794510202741,4.6161968775509195,4.7373143040815648,4.8584317306122102,4.9795491571428556,5.100666583673501,5.221784010203919,5.3429014367345644,5.4640188632654372,5.5851362897958552,5.7062537163265006,5.827371142857146,5.948488569387564,6.0696059959184367,6.1907234224490821,6.3118408489795002,6.4329582755101455,6.5540757020407909,6.6751931285714363,6.7963105551020817,6.9174279816327271,7.0385454081631451,7.1596628346937905,7.2807802612244359,7.4018976877550813,7.5230151142857267,7.6441325408163721,7.7652499673467901,7.8863673938774355,8.0074848204080809,8.1286022469387262,8.2497196734693716,8.370837100000017],[2.3390714530612513,2.4601888795918967,2.5813063061223147,2.7024237326531875,2.8235411591836055,2.9446585857142509,3.0657760122448963,3.1868934387755417,3.3080108653059597,3.4291282918368324,3.5502457183674778,3.6713631448978958,3.7924805714285412,3.9135979979591866,4.034715424489832,4.1558328510204774,4.2769502775511228,4.3980677040815408,4.5191851306121862,4.6403025571428316,4.761419983673477,4.8825374102041224,5.0036548367347677,5.1247722632651858,5.2458896897958311,5.3670071163267039,5.4881245428571219,5.6092419693877673,5.7303593959184127,5.8514768224488307,5.9725942489797035,6.0937116755103489,6.2148291020407669,6.3359465285714123,6.4570639551020577,6.5781813816327031,6.6992988081633484,6.8204162346939938,6.9415336612244118,7.0626510877550572,7.1837685142857026,7.304885940816348,7.4260033673469934,7.5471207938776388,7.6682382204080568,7.7893556469387022,7.9104730734693476,8.031590499999993,8.1527079265306384,8.2738253530612837],[2.242059706122518,2.3631771326531634,2.4842945591835814,2.6054119857144542,2.7265294122448722,2.8476468387755176,2.968764265306163,3.0898816918368084,3.2109991183672264,3.3321165448980992,3.4532339714287446,3.5743513979591626,3.695468824489808,3.8165862510204533,3.9377036775510987,4.0588211040817441,4.1799385306123895,4.3010559571428075,4.4221733836734529,4.5432908102040983,4.6644082367347437,4.7855256632653891,4.9066430897960345,5.0277605163264525,5.1488779428570979,5.2699953693879706,5.3911127959183887,5.512230222449034,5.6333476489796794,5.7544650755100974,5.8755825020409702,5.9966999285716156,6.1178173551020336,6.238934781632679,6.3600522081633244,6.4811696346939698,6.6022870612246152,6.7234044877552606,6.8445219142856786,6.965639340816324,7.0867567673469694,7.2078741938776147,7.3289916204082601,7.4501090469389055,7.5712264734693235,7.6923438999999689,7.8134613265306143,7.9345787530612597,8.0556961795919051,8.1768136061225505],[2.1450479591835574,2.2661653857142028,2.3872828122446208,2.5084002387754936,2.6295176653059116,2.750635091836557,2.8717525183672024,2.9928699448978477,3.1139873714282658,3.2351047979591385,3.3562222244897839,3.4773396510202019,3.5984570775508473,3.7195745040814927,3.8406919306121381,3.9618093571427835,4.0829267836734289,4.2040442102038469,4.3251616367344923,4.4462790632651377,4.5673964897957831,4.6885139163264284,4.8096313428570738,4.9307487693874918,5.0518661959181372,5.17298362244901,5.294101048979428,5.4152184755100734,5.5363359020407188,5.6574533285711368,5.7785707551020096,5.899688181632655,6.020805608163073,6.1419230346937184,6.2630404612243638,6.3841578877550091,6.5052753142856545,6.6263927408162999,6.7475101673467179,6.8686275938773633,6.9897450204080087,7.1108624469386541,7.2319798734692995,7.3530972999999449,7.4742147265303629,7.5953321530610083,7.7164495795916537,7.8375670061222991,7.9586844326529445,8.0798018591835898],[2.0480362122448241,2.1691536387754695,2.2902710653058875,2.4113884918367603,2.5325059183671783,2.6536233448978237,2.7747407714284691,2.8958581979591145,3.0169756244895325,3.1380930510204053,3.2592104775510506,3.3803279040814687,3.501445330612114,3.6225627571427594,3.7436801836734048,3.8647976102040502,3.9859150367346956,4.1070324632651136,4.228149889795759,4.3492673163264044,4.4703847428570498,4.5915021693876952,4.7126195959183406,4.8337370224487586,4.954854448979404,5.0759718755102767,5.1970893020406947,5.3182067285713401,5.4393241551019855,5.5604415816324035,5.6815590081632763,5.8026764346939217,5.9237938612243397,6.0449112877549851,6.1660287142856305,6.2871461408162759,6.4082635673469213,6.5293809938775667,6.6504984204079847,6.7716158469386301,6.8927332734692754,7.0138506999999208,7.1349681265305662,7.2560855530612116,7.3772029795916296,7.498320406122275,7.6194378326529204,7.7405552591835658,7.8616726857142112,7.9827901122448566],[1.9510244653060909,2.0721418918367362,2.1932593183671543,2.314376744898027,2.435494171428445,2.5566115979590904,2.6777290244897358,2.7988464510203812,2.9199638775507992,3.041081304081672,3.1621987306123174,3.2833161571427354,3.4044335836733808,3.5255510102040262,3.6466684367346716,3.7677858632653169,3.8889032897959623,4.0100207163263804,4.1311381428570257,4.2522555693876711,4.3733729959183165,4.4944904224489619,4.6156078489796073,4.7367252755100253,4.8578427020406707,4.9789601285715435,5.1000775551019615,5.2211949816326069,5.3423124081632523,5.4634298346936703,5.584547261224543,5.7056646877551884,5.8267821142856064,5.9478995408162518,6.0690169673468972,6.1901343938775426,6.311251820408188,6.4323692469388334,6.5534866734692514,6.6746040999998968,6.7957215265305422,6.9168389530611876,7.037956379591833,7.1590738061224783,7.2801912326528964,7.4013086591835417,7.5224260857141871,7.6435435122448325,7.7646609387754779,7.8857783653061233],[1.8540127183673576,1.975130144898003,2.096247571428421,2.2173649979592938,2.3384824244897118,2.4595998510203572,2.5807172775510026,2.7018347040816479,2.822952130612066,2.9440695571429387,3.0651869836735841,3.1863044102040021,3.3074218367346475,3.4285392632652929,3.5496566897959383,3.6707741163265837,3.7918915428572291,3.9130089693876471,4.0341263959182925,4.1552438224489379,4.2763612489795833,4.3974786755102286,4.518596102040874,4.639713528571292,4.7608309551019374,4.8819483816328102,5.0030658081632282,5.1241832346938736,5.245300661224519,5.366418087754937,5.4875355142858098,5.6086529408164552,5.7297703673468732,5.8508877938775186,5.972005220408164,6.0931226469388093,6.2142400734694547,6.3353575000001001,6.4564749265305181,6.5775923530611635,6.6987097795918089,6.8198272061224543,6.9409446326530997,7.0620620591837451,7.1831794857141631,7.3042969122448085,7.4254143387754539,7.5465317653060993,7.6676491918367446,7.78876661836739],[1.7570009714286243,1.8781183979592697,1.9992358244896877,2.1203532510205605,2.2414706775509785,2.3625881040816239,2.4837055306122693,2.6048229571429147,2.7259403836733327,2.8470578102042055,2.9681752367348508,3.0892926632652689,3.2104100897959142,3.3315275163265596,3.452644942857205,3.5737623693878504,3.6948797959184958,3.8159972224489138,3.9371146489795592,4.0582320755102046,4.17934950204085,4.3004669285714954,4.4215843551021408,4.5427017816325588,4.6638192081632042,4.7849366346940769,4.9060540612244949,5.0271714877551403,5.1482889142857857,5.2694063408162037,5.3905237673470765,5.5116411938777219,5.6327586204081399,5.7538760469387853,5.8749934734694307,5.9961109000000761,6.1172283265307215,6.2383457530613668,6.3594631795917849,6.4805806061224303,6.6016980326530756,6.722815459183721,6.8439328857143664,6.9650503122450118,7.0861677387754298,7.2072851653060752,7.3284025918367206,7.449520018367366,7.5706374448980114,7.6917548714286568],[1.6599892244896637,1.7811066510203091,1.9022240775507271,2.0233415040815999,2.1444589306120179,2.2655763571426633,2.3866937836733086,2.507811210203954,2.628928636734372,2.7500460632652448,2.8711634897958902,2.9922809163263082,3.1133983428569536,3.234515769387599,3.3556331959182444,3.4767506224488898,3.5978680489795352,3.7189854755099532,3.8401029020405986,3.961220328571244,4.0823377551018893,4.2034551816325347,4.3245726081631801,4.4456900346935981,4.5668074612242435,4.6879248877551163,4.8090423142855343,4.9301597408161797,5.0512771673468251,5.1723945938772431,5.2935120204081159,5.4146294469387612,5.5357468734691793,5.6568642999998247,5.77798172653047,5.8990991530611154,6.0202165795917608,6.1413340061224062,6.2624514326528242,6.3835688591834696,6.504686285714115,6.6258037122447604,6.7469211387754058,6.8680385653060512,6.9891559918364692,7.1102734183671146,7.23139084489776,7.3525082714284054,7.4736256979590507,7.5947431244896961],[1.5629774775509304,1.6840949040815758,1.8052123306119938,1.9263297571428666,2.0474471836732846,2.16856461020393,2.2896820367345754,2.4107994632652208,2.5319168897956388,2.6530343163265115,2.7741517428571569,2.8952691693875749,3.0163865959182203,3.1375040224488657,3.2586214489795111,3.3797388755101565,3.5008563020408019,3.6219737285712199,3.7430911551018653,3.8642085816325107,3.9853260081631561,4.1064434346938015,4.2275608612244469,4.3486782877548649,4.4697957142855103,4.590913140816383,4.712030567346801,4.8331479938774464,4.9542654204080918,5.0753828469385098,5.1965002734693826,5.317617700000028,5.438735126530446,5.5598525530610914,5.6809699795917368,5.8020874061223822,5.9232048326530276,6.0443222591836729,6.165439685714091,6.2865571122447363,6.4076745387753817,6.5287919653060271,6.6499093918366725,6.7710268183673179,6.8921442448977359,7.0132616714283813,7.1343790979590267,7.2554965244896721,7.3766139510203175,7.4977313775509629],[1.4659657306121971,1.5870831571428425,1.7082005836732606,1.8293180102041333,1.9504354367345513,2.0715528632651967,2.1926702897958421,2.3137877163264875,2.4349051428569055,2.5560225693877783,2.6771399959184237,2.7982574224488417,2.9193748489794871,3.0404922755101325,3.1616097020407778,3.2827271285714232,3.4038445551020686,3.5249619816324866,3.646079408163132,3.7671968346937774,3.8883142612244228,4.0094316877550682,4.1305491142857136,4.2516665408161316,4.372783967346777,4.4939013938776498,4.6150188204080678,4.7361362469387132,4.8572536734693585,4.9783710999997766,5.0994885265306493,5.2206059530612947,5.3417233795917127,5.4628408061223581,5.5839582326530035,5.7050756591836489,5.8261930857142943,5.9473105122449397,6.0684279387753577,6.1895453653060031,6.3106627918366485,6.4317802183672939,6.5528976448979392,6.6740150714285846,6.7951324979590026,6.916249924489648,7.0373673510202934,7.1584847775509388,7.2796022040815842,7.4007196306122296],[1.3689539836734639,1.4900714102041093,1.6111888367345273,1.7323062632654,1.8534236897958181,1.9745411163264635,2.0956585428571088,2.2167759693877542,2.3378933959181722,2.459010822449045,2.5801282489796904,2.7012456755101084,2.8223631020407538,2.9434805285713992,3.0645979551020446,3.18571538163269,3.3068328081633354,3.4279502346937534,3.5490676612243988,3.6701850877550442,3.7913025142856895,3.9124199408163349,4.0335373673469803,4.1546547938773983,4.2757722204080437,4.3968896469389165,4.5180070734693345,4.6391244999999799,4.7602419265306253,4.8813593530610433,5.0024767795919161,5.1235942061225614,5.2447116326529795,5.3658290591836248,5.4869464857142702,5.6080639122449156,5.729181338775561,5.8502987653062064,5.9714161918366244,6.0925336183672698,6.2136510448979152,6.3347684714285606,6.455885897959206,6.5770033244898514,6.6981207510202694,6.8192381775509148,6.9403556040815602,7.0614730306122055,7.1825904571428509,7.3037078836734963],[1.2719422367347306,1.393059663265376,1.514177089795794,1.6352945163266668,1.7564119428570848,1.8775293693877302,1.9986467959183756,2.119764222449021,2.240881648979439,2.3619990755103117,2.4831165020409571,2.6042339285713751,2.7253513551020205,2.8464687816326659,2.9675862081633113,3.0887036346939567,3.2098210612246021,3.3309384877550201,3.4520559142856655,3.5731733408163109,3.6942907673469563,3.8154081938776017,3.9365256204082471,4.0576430469386651,4.1787604734693105,4.2998779000001832,4.4209953265306012,4.5421127530612466,4.663230179591892,4.78434760612231,4.9054650326531828,5.0265824591838282,5.1476998857142462,5.2688173122448916,5.389934738775537,5.5110521653061824,5.6321695918368277,5.7532870183674731,5.8744044448978912,5.9955218714285365,6.1166392979591819,6.2377567244898273,6.3588741510204727,6.4799915775511181,6.6011090040815361,6.7222264306121815,6.8433438571428269,6.9644612836734723,7.0855787102041177,7.2066961367347631],[1.1749304897959973,1.2960479163266427,1.4171653428570608,1.5382827693879335,1.6594001959183515,1.7805176224489969,1.9016350489796423,2.0227524755102877,2.1438699020407057,2.2649873285715785,2.3861047551022239,2.5072221816326419,2.6283396081632873,2.7494570346939327,2.870574461224578,2.9916918877552234,3.1128093142858688,3.2339267408162868,3.3550441673469322,3.4761615938775776,3.597279020408223,3.7183964469388684,3.8395138734695138,3.9606312999999318,4.0817487265305772,4.2028661530614499,4.323983579591868,4.4451010061225134,4.5662184326531587,4.6873358591835768,4.8084532857144495,4.9295707122450949,5.0506881387755129,5.1718055653061583,5.2929229918368037,5.4140404183674491,5.5351578448980945,5.6562752714287399,5.7773926979591579,5.8985101244898033,6.0196275510204487,6.1407449775510941,6.2618624040817394,6.3829798306123848,6.5040972571428028,6.6252146836734482,6.7463321102040936,6.867449536734739,6.9885669632653844,7.1096843897960298],[1.0779187428570367,1.1990361693876821,1.3201535959181001,1.4412710224489729,1.5623884489793909,1.6835058755100363,1.8046233020406817,1.9257407285713271,2.0468581551017451,2.1679755816326178,2.2890930081632632,2.4102104346936812,2.5313278612243266,2.652445287754972,2.7735627142856174,2.8946801408162628,3.0157975673469082,3.1369149938773262,3.2580324204079716,3.379149846938617,3.5002672734692624,3.6213846999999078,3.7425021265305531,3.8636195530609712,3.9847369795916165,4.1058544061224893,4.2269718326529073,4.3480892591835527,4.4692066857141981,4.5903241122446161,4.7114415387754889,4.8325589653061343,4.9536763918365523,5.0747938183671977,5.1959112448978431,5.3170286714284885,5.4381460979591338,5.5592635244897792,5.6803809510201972,5.8014983775508426,5.922615804081488,6.0437332306121334,6.1648506571427788,6.2859680836734242,6.4070855102038422,6.5282029367344876,6.649320363265133,6.7704377897957784,6.8915552163264238,7.0126726428570691],[0.98090699591830344,1.1020244224489488,1.2231418489793668,1.3442592755102396,1.4653767020406576,1.586494128571303,1.7076115551019484,1.8287289816325938,1.9498464081630118,2.0709638346938846,2.19208126122453,2.313198687754948,2.4343161142855934,2.5554335408162387,2.6765509673468841,2.7976683938775295,2.9187858204081749,3.0399032469385929,3.1610206734692383,3.2821380999998837,3.4032555265305291,3.5243729530611745,3.6454903795918199,3.7666078061222379,3.8877252326528833,4.008842659183756,4.1299600857141741,4.2510775122448194,4.3721949387754648,4.4933123653058828,4.6144297918367556,4.735547218367401,4.856664644897819,4.9777820714284644,5.0988994979591098,5.2200169244897552,5.3411343510204006,5.462251777551046,5.583369204081464,5.7044866306121094,5.8256040571427548,5.9467214836734001,6.0678389102040455,6.1889563367346909,6.3100737632651089,6.4311911897957543,6.5523086163263997,6.6734260428570451,6.7945434693876905,6.9156608959183359],[0.88389524897957017,1.0050126755102156,1.1261301020406336,1.2472475285715063,1.3683649551019244,1.4894823816325697,1.6105998081632151,1.7317172346938605,1.8528346612242785,1.9739520877551513,2.0950695142857967,2.2161869408162147,2.3373043673468601,2.4584217938775055,2.5795392204081509,2.7006566469387963,2.8217740734694416,2.9428914999998597,3.0640089265305051,3.1851263530611504,3.3062437795917958,3.4273612061224412,3.5484786326530866,3.6695960591835046,3.79071348571415,3.9118309122450228,4.0329483387754408,4.1540657653060862,4.2751831918367316,4.3963006183671496,4.5174180448980223,4.6385354714286677,4.7596528979590857,4.8807703244897311,5.0018877510203765,5.1230051775510219,5.2441226040816673,5.3652400306123127,5.4863574571427307,5.6074748836733761,5.7285923102040215,5.8497097367346669,5.9708271632653123,6.0919445897959577,6.2130620163263757,6.3341794428570211,6.4552968693876664,6.5764142959183118,6.6975317224489572,6.8186491489796026],[0.7868835020408369,0.90800092857148229,1.0291183551019003,1.1502357816327731,1.2713532081631911,1.3924706346938365,1.5135880612244819,1.6347054877551273,1.7558229142855453,1.876940340816418,1.9980577673470634,2.1191751938774814,2.2402926204081268,2.3614100469387722,2.4825274734694176,2.603644900000063,2.7247623265307084,2.8458797530611264,2.9669971795917718,3.0881146061224172,3.2092320326530626,3.3303494591837079,3.4514668857143533,3.5725843122447714,3.6937017387754167,3.8148191653062895,3.9359365918367075,4.0570540183673529,4.1781714448979983,4.2992888714284163,4.4204062979592891,4.5415237244899345,4.6626411510203525,4.7837585775509979,4.9048760040816433,5.0259934306122886,5.147110857142934,5.2682282836735794,5.3893457102039974,5.5104631367346428,5.6315805632652882,5.7526979897959336,5.873815416326579,5.9949328428572244,6.1160502693876424,6.2371676959182878,6.3582851224489332,6.4794025489795786,6.600519975510224,6.7216374020408693],[0.68987175510210363,0.81098918163274902,0.93210660816316704,1.0532240346940398,1.1743414612244578,1.2954588877551032,1.4165763142857486,1.537693740816394,1.658811167346812,1.7799285938776848,1.9010460204083302,2.0221634469387482,2.1432808734693936,2.2643983000000389,2.3855157265306843,2.5066331530613297,2.6277505795919751,2.7488680061223931,2.8699854326530385,2.9911028591836839,3.1122202857143293,3.2333377122449747,3.3544551387756201,3.4755725653060381,3.5966899918366835,3.7178074183675562,3.8389248448979743,3.9600422714286196,4.081159697959265,4.202277124489683,4.3233945510205558,4.4445119775512012,4.5656294040816192,4.6867468306122646,4.80786425714291,4.9289816836735554,5.0500991102042008,5.1712165367348462,5.2923339632652642,5.4134513897959096,5.534568816326555,5.6556862428572003,5.7768036693878457,5.8979210959184911,6.0190385224489091,6.1401559489795545,6.2612733755101999,6.3823908020408453,6.5035082285714907,6.6246256551021361],[0.59286000816314299,0.71397743469378838,0.8350948612242064,0.95621228775507916,1.0773297142854972,1.1984471408161426,1.319564567346788,1.4406819938774333,1.5617994204078514,1.6829168469387241,1.8040342734693695,1.9251516999997875,2.0462691265304329,2.1673865530610783,2.2885039795917237,2.4096214061223691,2.5307388326530145,2.6518562591834325,2.7729736857140779,2.8940911122447233,3.0152085387753687,3.136325965306014,3.2574433918366594,3.3785608183670774,3.4996782448977228,3.6207956714285956,3.7419130979590136,3.863030524489659,3.9841479510203044,4.1052653775507224,4.2263828040815952,4.3475002306122406,4.4686176571426586,4.589735083673304,4.7108525102039494,4.8319699367345947,4.9530873632652401,5.0742047897958855,5.1953222163263035,5.3164396428569489,5.4375570693875943,5.5586744959182397,5.6797919224488851,5.8009093489795305,5.9220267755099485,6.0431442020405939,6.1642616285712393,6.2853790551018847,6.40649648163253,6.5276139081631754],[0.49584826122440973,0.61696568775505511,0.73808311428547313,0.85920054081634589,0.98031796734676391,1.1014353938774093,1.2225528204080547,1.3436702469387001,1.4647876734691181,1.5859050999999909,1.7070225265306362,1.8281399530610543,1.9492573795916996,2.070374806122345,2.1914922326529904,2.3126096591836358,2.4337270857142812,2.5548445122446992,2.6759619387753446,2.79707936530599,2.9181967918366354,3.0393142183672808,3.1604316448979262,3.2815490714283442,3.4026664979589896,3.5237839244898623,3.6449013510202803,3.7660187775509257,3.8871362040815711,4.0082536306119891,4.1293710571428619,4.2504884836735073,4.3716059102039253,4.4927233367345707,4.6138407632652161,4.7349581897958615,4.8560756163265069,4.9771930428571522,5.0983104693875703,5.2194278959182157,5.340545322448861,5.4616627489795064,5.5827801755101518,5.7038976020407972,5.8250150285712152,5.9461324551018606,6.067249881632506,6.1883673081631514,6.3094847346937968,6.4306021612244422],[0.39883651428567646,0.51995394081632185,0.64107136734673986,0.76218879387761262,0.88330622040803064,1.004423646938676,1.1255410734693214,1.2466584999999668,1.3677759265303848,1.4888933530612576,1.610010779591903,1.731128206122321,1.8522456326529664,1.9733630591836118,2.0944804857142572,2.2155979122449025,2.3367153387755479,2.4578327653059659,2.5789501918366113,2.7000676183672567,2.8211850448979021,2.9423024714285475,3.0634198979591929,3.1845373244896109,3.3056547510202563,3.4267721775511291,3.5478896040815471,3.6690070306121925,3.7901244571428379,3.9112418836732559,4.0323593102041286,4.153476736734774,4.274594163265192,4.3957115897958374,4.5168290163264828,4.6379464428571282,4.7590638693877736,4.880181295918419,5.001298722448837,5.1224161489794824,5.2435335755101278,5.3646510020407732,5.4857684285714186,5.6068858551020639,5.728003281632482,5.8491207081631273,5.9702381346937727,6.0913555612244181,6.2124729877550635,6.3335904142857089],[0.30182476734694319,0.42294219387758858,0.54405962040800659,0.66517704693887936,0.78629447346929737,0.90741189999994276,1.0285293265305882,1.1496467530612335,1.2707641795916516,1.3918816061225243,1.5129990326531697,1.6341164591835877,1.7552338857142331,1.8763513122448785,1.9974687387755239,2.1185861653061693,2.2397035918368147,2.3608210183672327,2.4819384448978781,2.6030558714285235,2.7241732979591688,2.8452907244898142,2.9664081510204596,3.0875255775508776,3.208643004081523,3.3297604306123958,3.4508778571428138,3.5719952836734592,3.6931127102041046,3.8142301367345226,3.9353475632653954,4.0564649897960408,4.1775824163264588,4.2986998428571042,4.4198172693877495,4.5409346959183949,4.6620521224490403,4.7831695489796857,4.9042869755101037,5.0254044020407491,5.1465218285713945,5.2676392551020399,5.3887566816326853,5.5098741081633307,5.6309915346937487,5.7521089612243941,5.8732263877550395,5.9943438142856849,6.1154612408163302,6.2365786673469756],[0.20481302040820992,0.32593044693885531,0.44704787346927333,0.56816530000014609,0.6892827265305641,0.81040015306120949,0.93151757959185488,1.0526350061225003,1.1737524326529183,1.294869859183791,1.4159872857144364,1.5371047122448545,1.6582221387754998,1.7793395653061452,1.9004569918367906,2.021574418367436,2.1426918448980814,2.2638092714284994,2.3849266979591448,2.5060441244897902,2.6271615510204356,2.748278977551081,2.8693964040817264,2.9905138306121444,3.1116312571427898,3.2327486836736625,3.3538661102040805,3.4749835367347259,3.5961009632653713,3.7172183897957893,3.8383358163266621,3.9594532428573075,4.0805706693877255,4.2016880959183709,4.3228055224490163,4.4439229489796617,4.5650403755103071,4.6861578020409524,4.8072752285713705,4.9283926551020159,5.0495100816326612,5.1706275081633066,5.291744934693952,5.4128623612245974,5.5339797877550154,5.6550972142856608,5.7762146408163062,5.8973320673469516,6.018449493877597,6.1395669204082424],[0.10780127346947666,0.22891870000012204,0.35003612653054006,0.47115355306141282,0.59227097959183084,0.71338840612247623,0.83450583265312162,0.955623259183767,1.076740685714185,1.1978581122450578,1.3189755387757032,1.4400929653061212,1.5612103918367666,1.682327818367412,1.8034452448980574,1.9245626714287027,2.0456800979593481,2.1667975244897661,2.2879149510204115,2.4090323775510569,2.5301498040817023,2.6512672306123477,2.7723846571429931,2.8935020836734111,3.0146195102040565,3.1357369367349293,3.2568543632653473,3.3779717897959927,3.4990892163266381,3.6202066428570561,3.7413240693879288,3.8624414959185742,3.9835589224489922,4.1046763489796376,4.225793775510283,4.3469112020409284,4.4680286285715738,4.5891460551022192,4.7102634816326372,4.8313809081632826,4.952498334693928,5.0736157612245734,5.1947331877552188,5.3158506142858641,5.4369680408162822,5.5580854673469275,5.6792028938775729,5.8003203204082183,5.9214377469388637,6.0425551734695091],[0.010789526530516014,0.1319069530611614,0.25302437959157942,0.37414180612245218,0.4952592326528702,0.61637665918351559,0.73749408571416097,0.85861151224480636,0.97972893877522438,1.1008463653060971,1.2219637918367425,1.3430812183671605,1.4641986448978059,1.5853160714284513,1.7064334979590967,1.8275509244897421,1.9486683510203875,2.0697857775508055,2.1909032040814509,2.3120206306120963,2.4331380571427417,2.5542554836733871,2.6753729102040325,2.7964903367344505,2.9176077632650959,3.0387251897959686,3.1598426163263866,3.280960042857032,3.4020774693876774,3.5231948959180954,3.6443123224489682,3.7654297489796136,3.8865471755100316,4.007664602040677,4.1287820285713224,4.2498994551019678,4.3710168816326131,4.4921343081632585,4.6132517346936766,4.7343691612243219,4.8554865877549673,4.9766040142856127,5.0977214408162581,5.2188388673469035,5.3399562938773215,5.4610737204079669,5.5821911469386123,5.7033085734692577,5.8244259999999031,5.9455434265305485],[-0.086222220408217254,0.034895206122428135,0.15601263265284615,0.27713005918371891,0.39824748571413693,0.51936491224478232,0.64048233877542771,0.7615997653060731,0.88271719183649111,1.0038346183673639,1.1249520448980093,1.2460694714284273,1.3671868979590727,1.4883043244897181,1.6094217510203634,1.7305391775510088,1.8516566040816542,1.9727740306120722,2.0938914571427176,2.215008883673363,2.3361263102040084,2.4572437367346538,2.5783611632652992,2.6994785897957172,2.8205960163263626,2.9417134428572353,3.0628308693876534,3.1839482959182988,3.3050657224489441,3.4261831489793622,3.5473005755102349,3.6684180020408803,3.7895354285712983,3.9106528551019437,4.0317702816325891,4.1528877081632345,4.2740051346938799,4.3951225612245253,4.5162399877549433,4.6373574142855887,4.7584748408162341,4.8795922673468795,5.0007096938775248,5.1218271204081702,5.2429445469385882,5.3640619734692336,5.485179399999879,5.6062968265305244,5.7274142530611698,5.8485316795918152],[-0.18323396734695052,-0.062116540816305132,0.059000885714112883,0.18011831224498565,0.30123573877540366,0.42235316530604905,0.54347059183669444,0.66458801836733983,0.78570544489775784,0.90682287142863061,1.027940297959276,1.149057724489694,1.2701751510203394,1.3912925775509848,1.5124100040816302,1.6335274306122756,1.754644857142921,1.875762283673339,1.9968797102039844,2.1179971367346297,2.2391145632652751,2.3602319897959205,2.4813494163265659,2.6024668428569839,2.7235842693876293,2.8447016959185021,2.9658191224489201,3.0869365489795655,3.2080539755102109,3.3291714020406289,3.4502888285715017,3.571406255102147,3.6925236816325651,3.8136411081632104,3.9347585346938558,4.0558759612245012,4.1769933877551466,4.298110814285792,4.41922824081621,4.5403456673468554,4.6614630938775008,4.7825805204081462,4.9036979469387916,5.024815373469437,5.145932799999855,5.2670502265305004,5.3881676530611458,5.5092850795917911,5.6304025061224365,5.7515199326530819],[-0.28024571428568379,-0.1591282877550384,-0.038010861224620385,0.083106565306252378,0.20422399183667039,0.32534141836731578,0.44645884489796117,0.56757627142860656,0.68869369795902458,0.80981112448989734,0.93092855102054273,1.0520459775509607,1.1731634040816061,1.2942808306122515,1.4153982571428969,1.5365156836735423,1.6576331102041877,1.7787505367346057,1.8998679632652511,2.0209853897958965,2.1421028163265419,2.2632202428571873,2.3843376693878326,2.5054550959182507,2.6265725224488961,2.7476899489797688,2.8688073755101868,2.9899248020408322,3.1110422285714776,3.2321596551018956,3.3532770816327684,3.4743945081634138,3.5955119346938318,3.7166293612244772,3.8377467877551226,3.958864214285768,4.0799816408164133,4.2010990673470587,4.3222164938774768,4.4433339204081221,4.5644513469387675,4.6855687734694129,4.8066862000000583,4.9278036265307037,5.0489210530611217,5.1700384795917671,5.2911559061224125,5.4122733326530579,5.5333907591837033,5.6545081857143487],[-0.37725746122441706,-0.25614003469377167,-0.13502260816335365,-0.01390518163248089,0.10721224489793713,0.22832967142858251,0.3494470979592279,0.47056452448987329,0.59168195102029131,0.71279937755116407,0.83391680408180946,0.95503423061222747,1.0761516571428729,1.1972690836735183,1.3183865102041636,1.439503936734809,1.5606213632654544,1.6817387897958724,1.8028562163265178,1.9239736428571632,2.0450910693878086,2.166208495918454,2.2873259224490994,2.4084433489795174,2.5295607755101628,2.6506782020410355,2.7717956285714536,2.892913055102099,3.0140304816327443,3.1351479081631624,3.2562653346940351,3.3773827612246805,3.4985001877550985,3.6196176142857439,3.7407350408163893,3.8618524673470347,3.9829698938776801,4.1040873204083255,4.2252047469387435,4.3463221734693889,4.4674396000000343,4.5885570265306797,4.709674453061325,4.8307918795919704,4.9519093061223884,5.0730267326530338,5.1941441591836792,5.3152615857143246,5.43637901224497,5.5574964387756154],[-0.4742692081633777,-0.35315178163273231,-0.23203435510231429,-0.11091692857144153,0.010200497958976484,0.13131792448962187,0.25243535102026726,0.37355277755091265,0.49467020408133067,0.61578763061220343,0.73690505714284882,0.85802248367326683,0.97913991020391222,1.1002573367345576,1.221374763265203,1.3424921897958484,1.4636096163264938,1.5847270428569118,1.7058444693875572,1.8269618959182026,1.948079322448848,2.0691967489794933,2.1903141755101387,2.3114316020405568,2.4325490285712021,2.5536664551020749,2.6747838816324929,2.7959013081631383,2.9170187346937837,3.0381361612242017,3.1592535877550745,3.2803710142857199,3.4014884408161379,3.5226058673467833,3.6437232938774287,3.764840720408074,3.8859581469387194,4.0070755734693648,4.1281929999997828,4.2493104265304282,4.3704278530610736,4.491545279591719,4.6126627061223644,4.7337801326530098,4.8548975591834278,4.9760149857140732,5.0971324122447186,5.218249838775364,5.3393672653060094,5.4604846918366547],[-0.57128095510211097,-0.45016352857146558,-0.32904610204104756,-0.2079286755101748,-0.086811248979756783,0.034306177550888606,0.15542360408153399,0.27654103061217938,0.3976584571425974,0.51877588367347016,0.63989331020411555,0.76101073673453357,0.88212816326517896,1.0032455897958243,1.1243630163264697,1.2454804428571151,1.3665978693877605,1.4877152959181785,1.6088327224488239,1.7299501489794693,1.8510675755101147,1.9721850020407601,2.0933024285714055,2.2144198551018235,2.3355372816324689,2.4566547081633416,2.5777721346937597,2.698889561224405,2.8200069877550504,2.9411244142854684,3.0622418408163412,3.1833592673469866,3.3044766938774046,3.42559412040805,3.5467115469386954,3.6678289734693408,3.7889463999999862,3.9100638265306316,4.0311812530610496,4.152298679591695,4.2734161061223404,4.3945335326529857,4.5156509591836311,4.6367683857142765,4.7578858122446945,4.8790032387753399,5.0001206653059853,5.1212380918366307,5.2423555183672761,5.3634729448979215],[-0.66829270204084423,-0.54717527551019884,-0.42605784897978083,-0.30494042244890807,-0.18382299591849005,-0.062705569387844662,0.058411857142800727,0.17952928367344612,0.30064671020386413,0.42176413673473689,0.54288156326538228,0.6639989897958003,0.78511641632644569,0.90623384285709108,1.0273512693877365,1.1484686959183819,1.2695861224490272,1.3907035489794453,1.5118209755100906,1.632938402040736,1.7540558285713814,1.8751732551020268,1.9962906816326722,2.1174081081630902,2.2385255346937356,2.3596429612246084,2.4807603877550264,2.6018778142856718,2.7229952408163172,2.8441126673467352,2.9652300938776079,3.0863475204082533,3.2074649469386713,3.3285823734693167,3.4496997999999621,3.5708172265306075,3.6919346530612529,3.8130520795918983,3.9341695061223163,4.0552869326529617,4.1764043591836071,4.2975217857142525,4.4186392122448979,4.5397566387755433,4.6608740653059613,4.7819914918366067,4.903108918367252,5.0242263448978974,5.1453437714285428,5.2664611979591882],[-0.7653044489795775,-0.64418702244893211,-0.5230695959185141,-0.40195216938764133,-0.28083474285722332,-0.15971731632657793,-0.03859988979593254,0.082517536734712849,0.20363496326513086,0.32475238979600363,0.44586981632664902,0.56698724285706703,0.68810466938771242,0.80922209591835781,0.9303395224490032,1.0514569489796486,1.172574375510294,1.293691802040712,1.4148092285713574,1.5359266551020028,1.6570440816326482,1.7781615081632935,1.8992789346939389,2.020396361224357,2.1415137877550023,2.2626312142858751,2.3837486408162931,2.5048660673469385,2.6259834938775839,2.7471009204080019,2.8682183469388747,2.9893357734695201,3.1104531999999381,3.2315706265305835,3.3526880530612289,3.4738054795918742,3.5949229061225196,3.716040332653165,3.837157759183583,3.9582751857142284,4.0793926122448738,4.2005100387755192,4.3216274653061646,4.44274489183681,4.563862318367228,4.6849797448978734,4.8060971714285188,4.9272145979591642,5.0483320244898096,5.1694494510204549],[-0.86231619591831077,-0.74119876938766538,-0.62008134285724736,-0.4989639163263746,-0.37784648979595659,-0.2567290632653112,-0.13561163673466581,-0.014494210204020419,0.1066232163263976,0.22774064285727036,0.34885806938791575,0.46997549591833376,0.59109292244897915,0.71221034897962454,0.83332777551026993,0.95444520204091532,1.0755626285715607,1.1966800551019787,1.3177974816326241,1.4389149081632695,1.5600323346939149,1.6811497612245603,1.8022671877552057,1.9233846142856237,2.0445020408162691,2.1656194673471418,2.2867368938775599,2.4078543204082052,2.5289717469388506,2.6500891734692686,2.7712066000001414,2.8923240265307868,3.0134414530612048,3.1345588795918502,3.2556763061224956,3.376793732653141,3.4979111591837864,3.6190285857144318,3.7401460122448498,3.8612634387754952,3.9823808653061405,4.1034982918367859,4.2246157183674313,4.3457331448980767,4.4668505714284947,4.5879679979591401,4.7090854244897855,4.8302028510204309,4.9513202775510763,5.0724377040817217],[-0.95932794285727141,-0.83821051632662602,-0.71709308979620801,-0.59597566326533524,-0.47485823673491723,-0.35374081020427184,-0.23262338367362645,-0.11150595714298106,0.009611469387436955,0.13072889591830972,0.25184632244895511,0.37296374897937312,0.49408117551001851,0.6151986020406639,0.73631602857130929,0.85743345510195468,0.97855088163260007,1.0996683081630181,1.2207857346936635,1.3419031612243089,1.4630205877549542,1.5841380142855996,1.705255440816245,1.826372867346663,1.9474902938773084,2.0686077204081812,2.1897251469385992,2.3108425734692446,2.43195999999989,2.553077426530308,2.6741948530611808,2.7953122795918262,2.9164297061222442,3.0375471326528896,3.1586645591835349,3.2797819857141803,3.4008994122448257,3.5220168387754711,3.6431342653058891,3.7642516918365345,3.8853691183671799,4.0064865448978253,4.1276039714284707,4.2487213979591161,4.3698388244895341,4.4909562510201795,4.6120736775508249,4.7331911040814703,4.8543085306121156,4.975425957142761],[-1.0563396897960047,-0.93522226326535929,-0.81410483673494127,-0.69298741020406851,-0.57186998367365049,-0.45075255714300511,-0.32963513061235972,-0.20851770408171433,-0.087400277551296313,0.03371714897957645,0.15483457551022184,0.27595200204063985,0.39706942857128524,0.51818685510193063,0.63930428163257602,0.76042170816322141,0.8815391346938668,1.0026565612242848,1.1237739877549302,1.2448914142855756,1.366008840816221,1.4871262673468664,1.6082436938775118,1.7293611204079298,1.8504785469385752,1.9715959734694479,2.0927133999998659,2.2138308265305113,2.3349482530611567,2.4560656795915747,2.5771831061224475,2.6983005326530929,2.8194179591835109,2.9405353857141563,3.0616528122448017,3.1827702387754471,3.3038876653060925,3.4250050918367378,3.5461225183671559,3.6672399448978013,3.7883573714284466,3.909474797959092,4.0305922244897374,4.1517096510203828,4.2728270775508008,4.3939445040814462,4.5150619306120916,4.636179357142737,4.7572967836733824,4.8784142102040278],[-1.1533514367347379,-1.0322340102040926,-0.91111658367367454,-0.78999915714280178,-0.66888173061238376,-0.54776430408173837,-0.42664687755109298,-0.3055294510204476,-0.18441202449002958,-0.063294597959156818,0.057822828571488571,0.17894025510190659,0.30005768163255198,0.42117510816319736,0.54229253469384275,0.66340996122448814,0.78452738775513353,0.90564481428555155,1.0267622408161969,1.1478796673468423,1.2689970938774877,1.3901145204081331,1.5112319469387785,1.6323493734691965,1.7534667999998419,1.8745842265307147,1.9957016530611327,2.1168190795917781,2.2379365061224235,2.3590539326528415,2.4801713591837142,2.6012887857143596,2.7224062122447776,2.843523638775423,2.9646410653060684,3.0857584918367138,3.2068759183673592,3.3279933448980046,3.4491107714284226,3.570228197959068,3.6913456244897134,3.8124630510203588,3.9335804775510042,4.0546979040816495,4.1758153306120676,4.2969327571427129,4.4180501836733583,4.5391676102040037,4.6602850367346491,4.7814024632652945],[-1.2503631836734712,-1.1292457571428258,-1.0081283306124078,-0.88701090408153505,-0.76589347755111703,-0.64477605102047164,-0.52365862448982625,-0.40254119795918086,-0.28142377142876285,-0.16030634489789009,-0.039188918367244696,0.081928508163173319,0.20304593469381871,0.3241633612244641,0.44528078775510949,0.56639821428575488,0.68751564081640026,0.80863306734681828,0.92975049387746367,1.0508679204081091,1.1719853469387544,1.2931027734693998,1.4142202000000452,1.5353376265304632,1.6564550530611086,1.7775724795919814,1.8986899061223994,2.0198073326530448,2.1409247591836902,2.2620421857141082,2.383159612244981,2.5042770387756264,2.6253944653060444,2.7465118918366898,2.8676293183673351,2.9887467448979805,3.1098641714286259,3.2309815979592713,3.3520990244896893,3.4732164510203347,3.5943338775509801,3.7154513040816255,3.8365687306122709,3.9576861571429163,4.0788035836733343,4.1999210102039797,4.3210384367346251,4.4421558632652705,4.5632732897959158,4.6843907163265612],[-1.3473749306122045,-1.2262575040815591,-1.1051400775511411,-0.98402265102026831,-0.8629052244898503,-0.74178779795920491,-0.62067037142855952,-0.49955294489791413,-0.37843551836749612,-0.25731809183662335,-0.13620066530597796,-0.015083238775559948,0.10603418775508544,0.22715161428573083,0.34826904081637622,0.46938646734702161,0.590503893877667,0.71162132040808501,0.8327387469387304,0.95385617346937579,1.0749736000000212,1.1960910265306666,1.317208453061312,1.43832587959173,1.5594433061223754,1.6805607326532481,1.8016781591836661,1.9227955857143115,2.0439130122449569,2.1650304387753749,2.2861478653062477,2.4072652918368931,2.5283827183673111,2.6495001448979565,2.7706175714286019,2.8917349979592473,3.0128524244898927,3.133969851020538,3.2550872775509561,3.3762047040816014,3.4973221306122468,3.6184395571428922,3.7395569836735376,3.860674410204183,3.981791836734601,4.1029092632652464,4.2240266897958918,4.3451441163265372,4.4662615428571826,4.587378969387828],[-1.4443866775509377,-1.3232692510202924,-1.2021518244898743,-1.0810343979590016,-0.95991697142858357,-0.83879954489793818,-0.71768211836729279,-0.5965646918366474,-0.47544726530622938,-0.35432983877535662,-0.23321241224471123,-0.11209498571429322,0.009022440816352173,0.13013986734699756,0.25125729387764295,0.37237472040828834,0.49349214693893373,0.61460957346935174,0.73572699999999713,0.85684442653064252,0.97796185306128791,1.0990792795919333,1.2201967061225787,1.3413141326529967,1.4624315591836421,1.5835489857145149,1.7046664122449329,1.8257838387755783,1.9469012653062236,2.0680186918366417,2.1891361183675144,2.3102535448981598,2.4313709714285778,2.5524883979592232,2.6736058244898686,2.794723251020514,2.9158406775511594,3.0369581040818048,3.1580755306122228,3.2791929571428682,3.4003103836735136,3.521427810204159,3.6425452367348043,3.7636626632654497,3.8847800897958678,4.0058975163265131,4.1270149428571585,4.2481323693878039,4.3692497959184493,4.4903672224490947],[-1.5413984244898984,-1.420280997959253,-1.299163571428835,-1.1780461448979622,-1.0569287183675442,-0.93581129183689882,-0.81469386530625343,-0.69357643877560804,-0.57245901224519002,-0.45134158571431726,-0.33022415918367187,-0.20910673265325386,-0.087989306122608468,0.033128120408036921,0.15424554693868231,0.2753629734693277,0.39648039999997309,0.5175978265303911,0.63871525306103649,0.75983267959168188,0.88095010612232727,1.0020675326529727,1.123184959183618,1.2443023857140361,1.3654198122446815,1.4865372387755542,1.6076546653059722,1.7287720918366176,1.849889518367263,1.971006944897681,2.0921243714285538,2.2132417979591992,2.3343592244896172,2.4554766510202626,2.576594077550908,2.6977115040815534,2.8188289306121987,2.9399463571428441,3.0610637836732622,3.1821812102039075,3.3032986367345529,3.4244160632651983,3.5455334897958437,3.6666509163264891,3.7877683428569071,3.9088857693875525,4.0300031959181979,4.1511206224488433,4.2722380489794887,4.3933554755101341],[-1.6384101714286317,-1.5172927448979863,-1.3961753183675683,-1.2750578918366955,-1.1539404653062775,-1.0328230387756321,-0.9117056122449867,-0.79058818571434131,-0.66947075918392329,-0.54835333265305053,-0.42723590612240514,-0.30611847959198712,-0.18500105306134174,-0.063883626530696347,0.057233799999949042,0.17835122653059443,0.29946865306123982,0.42058607959165784,0.54170350612230322,0.66282093265294861,0.783938359183594,0.90505578571423939,1.0261732122448848,1.1472906387753028,1.2684080653059482,1.3895254918368209,1.510642918367239,1.6317603448978844,1.7528777714285297,1.8739951979589478,1.9951126244898205,2.1162300510204659,2.2373474775508839,2.3584649040815293,2.4795823306121747,2.6006997571428201,2.7218171836734655,2.8429346102041109,2.9640520367345289,3.0851694632651743,3.2062868897958197,3.3274043163264651,3.4485217428571104,3.5696391693877558,3.6907565959181738,3.8118740224488192,3.9329914489794646,4.05410887551011,4.1752263020407554,4.2963437285714008],[-1.7354219183673649,-1.6143044918367195,-1.4931870653063015,-1.3720696387754288,-1.2509522122450107,-1.1298347857143654,-1.00871735918372,-0.88759993265307457,-0.76648250612265656,-0.6453650795917838,-0.52424765306113841,-0.40313022653072039,-0.282012800000075,-0.16089537346942961,-0.039777946938784225,0.081339479591861163,0.20245690612250655,0.32357433265292457,0.44469175918356996,0.56580918571421535,0.68692661224486073,0.80804403877550612,0.92916146530615151,1.0502788918365695,1.1713963183672149,1.2925137448980877,1.4136311714285057,1.5347485979591511,1.6558660244897965,1.7769834510202145,1.8981008775510873,2.0192183040817326,2.1403357306121507,2.261453157142796,2.3825705836734414,2.5036880102040868,2.6248054367347322,2.7459228632653776,2.8670402897957956,2.988157716326441,3.1092751428570864,3.2303925693877318,3.3515099959183772,3.4726274224490226,3.5937448489794406,3.714862275510086,3.8359797020407314,3.9570971285713767,4.0782145551020221,4.1993319816326675],[-1.8324336653060982,-1.7113162387754528,-1.5901988122450348,-1.469081385714162,-1.347963959183744,-1.2268465326530986,-1.1057291061224532,-0.98461167959180784,-0.86349425306138983,-0.74237682653051706,-0.62125939999987168,-0.50014197346945366,-0.37902454693880827,-0.25790712040816288,-0.13678969387751749,-0.015672267346872104,0.10544515918377328,0.2265625857141913,0.34768001224483669,0.46879743877548208,0.58991486530612747,0.71103229183677286,0.83214971836741825,0.95326714489783626,1.0743845714284816,1.1955019979593544,1.3166194244897724,1.4377368510204178,1.5588542775510632,1.6799717040814812,1.801089130612354,1.9222065571429994,2.0433239836734174,2.1644414102040628,2.2855588367347082,2.4066762632653536,2.5277936897959989,2.6489111163266443,2.7700285428570623,2.8911459693877077,3.0122633959183531,3.1333808224489985,3.2544982489796439,3.3756156755102893,3.4967331020407073,3.6178505285713527,3.7389679551019981,3.8600853816326435,3.9812028081632889,4.1023202346939343],[-1.9294454122448315,-1.8083279857141861,-1.6872105591837681,-1.5660931326528953,-1.4449757061224773,-1.3238582795918319,-1.2027408530611865,-1.0816234265305411,-0.96050600000012309,-0.83938857346925033,-0.71827114693860494,-0.59715372040818693,-0.47603629387754154,-0.35491886734689615,-0.23380144081625076,-0.11268401428560537,0.0084334122450400173,0.12955083877545803,0.25066826530610342,0.37178569183674881,0.4929031183673942,0.61402054489803959,0.73513797142868498,0.85625539795910299,0.97737282448974838,1.0984902510206211,1.2196076775510392,1.3407251040816845,1.4618425306123299,1.582959957142748,1.7040773836736207,1.8251948102042661,1.9463122367346841,2.0674296632653295,2.1885470897959749,2.3096645163266203,2.4307819428572657,2.5518993693879111,2.6730167959183291,2.7941342224489745,2.9152516489796199,3.0363690755102652,3.1574865020409106,3.278603928571556,3.399721355101974,3.5208387816326194,3.6419562081632648,3.7630736346939102,3.8841910612245556,4.005308487755201],[-2.0264571591837921,-1.9053397326531467,-1.7842223061227287,-1.6631048795918559,-1.5419874530614379,-1.4208700265307925,-1.2997526000001471,-1.1786351734695018,-1.0575177469390837,-0.93640032040821097,-0.81528289387756558,-0.69416546734714757,-0.57304804081650218,-0.45193061428585679,-0.3308131877552114,-0.20969576122456601,-0.088578334693920624,0.032539091836497391,0.15365651836714278,0.27477394489778817,0.39589137142843356,0.51700879795907895,0.63812622448972434,0.75924365102014235,0.88036107755078774,1.0014785040816605,1.1225959306120785,1.2437133571427239,1.3648307836733693,1.4859482102037873,1.6070656367346601,1.7281830632653055,1.8493004897957235,1.9704179163263689,2.0915353428570143,2.2126527693876596,2.333770195918305,2.4548876224489504,2.5760050489793684,2.6971224755100138,2.8182399020406592,2.9393573285713046,3.06047475510195,3.1815921816325954,3.3027096081630134,3.4238270346936588,3.5449444612243042,3.6660618877549496,3.787179314285595,3.9082967408162403],[-2.1234689061225254,-2.00235147959188,-1.881234053061462,-1.7601166265305892,-1.6389992000001712,-1.5178817734695258,-1.3967643469388804,-1.275646920408235,-1.154529493877817,-1.0334120673469442,-0.91229464081629885,-0.79117721428588084,-0.67005978775523545,-0.54894236122459006,-0.42782493469394467,-0.30670750816329928,-0.18559008163265389,-0.064472655102235876,0.056644771428409513,0.1777621979590549,0.29887962448970029,0.41999705102034568,0.54111447755099107,0.66223190408140908,0.78334933061205447,0.90446675714292724,1.0255841836733453,1.1467016102039906,1.267819036734636,1.388936463265054,1.5100538897959268,1.6311713163265722,1.7522887428569902,1.8734061693876356,1.994523595918281,2.1156410224489264,2.2367584489795718,2.3578758755102172,2.4789933020406352,2.6001107285712806,2.7212281551019259,2.8423455816325713,2.9634630081632167,3.0845804346938621,3.2056978612242801,3.3268152877549255,3.4479327142855709,3.5690501408162163,3.6901675673468617,3.8112849938775071],[-2.2204806530612586,-2.0993632265306132,-1.9782458000001952,-1.8571283734693225,-1.7360109469389045,-1.6148935204082591,-1.4937760938776137,-1.3726586673469683,-1.2515412408165503,-1.1304238142856775,-1.0093063877550321,-0.8881889612246141,-0.76707153469396872,-0.64595410816332333,-0.52483668163267794,-0.40371925510203255,-0.28260182857138716,-0.16148440204096914,-0.040366975510323755,0.080750451020321634,0.20186787755096702,0.32298530408161241,0.4441027306122578,0.56522015714267582,0.68633758367332121,0.80745501020419397,0.92857243673461198,1.0496898632652574,1.1708072897959028,1.2919247163263208,1.4130421428571935,1.5341595693878389,1.6552769959182569,1.7763944224489023,1.8975118489795477,2.0186292755101931,2.1397467020408385,2.2608641285714839,2.3819815551019019,2.5030989816325473,2.6242164081631927,2.7453338346938381,2.8664512612244835,2.9875686877551288,3.1086861142855469,3.2298035408161923,3.3509209673468376,3.472038393877483,3.5931558204081284,3.7142732469387738],[-2.3174923999999919,-2.1963749734693465,-2.0752575469389285,-1.9541401204080557,-1.8330226938776377,-1.7119052673469923,-1.5907878408163469,-1.4696704142857016,-1.3485529877552835,-1.2274355612244108,-1.1063181346937654,-0.98520070816334737,-0.86408328163270198,-0.74296585510205659,-0.6218484285714112,-0.50073100204076582,-0.37961357551012043,-0.25849614897970241,-0.13737872244905702,-0.016261295918411633,0.10485613061223376,0.22597355714287914,0.34709098367352453,0.46820841020394255,0.58932583673458794,0.7104432632654607,0.83156068979587872,0.9526781163265241,1.0737955428571695,1.1949129693875875,1.3160303959184603,1.4371478224491057,1.5582652489795237,1.6793826755101691,1.8005001020408145,1.9216175285714598,2.0427349551021052,2.1638523816327506,2.2849698081631686,2.406087234693814,2.5272046612244594,2.6483220877551048,2.7694395142857502,2.8905569408163956,3.0116743673468136,3.132791793877459,3.2539092204081044,3.3750266469387498,3.4961440734693952,3.6172615000000405]],"mode":"markers","marker":{"size":5,"color":"black"},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"surface","opacity":0.5,"colorscale":[["0","rgb(255,255,255)"],["1","rgb(255,0,0)"]],"inherit":true}},"layout":{"width":1000,"height":500,"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Productivity"},"yaxis":{"title":"Year"},"zaxis":{"title":"Unemployment"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[113,123,127,138,130,146,151,152,141,159],"y":[1950,1951,1952,1953,1954,1955,1956,1957,1958,1959],"z":[3.1000000000000001,1.8999999999999999,1.7,1.6000000000000001,3.2000000000000002,2.7000000000000002,2.6000000000000001,2.8999999999999999,4.7000000000000002,3.7999999999999998],"mode":"markers","marker":{"color":"black","size":5,"line":{"color":"rgba(31,119,180,1)"}},"type":"scatter3d","error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgb(255,255,255)"],["1","rgb(255,0,0)"]],"showscale":true,"x":[113,113.93877551020408,114.87755102040816,115.81632653061224,116.75510204081633,117.69387755102041,118.63265306122449,119.57142857142857,120.51020408163265,121.44897959183673,122.38775510204081,123.32653061224489,124.26530612244898,125.20408163265306,126.14285714285714,127.08163265306122,128.0204081632653,128.9591836734694,129.89795918367346,130.83673469387756,131.77551020408163,132.71428571428572,133.65306122448979,134.59183673469389,135.53061224489795,136.46938775510205,137.40816326530611,138.34693877551021,139.28571428571428,140.22448979591837,141.16326530612244,142.10204081632654,143.0408163265306,143.9795918367347,144.91836734693877,145.85714285714286,146.79591836734693,147.73469387755102,148.67346938775512,149.61224489795919,150.55102040816325,151.48979591836735,152.42857142857144,153.36734693877551,154.30612244897958,155.24489795918367,156.18367346938777,157.12244897959184,158.0612244897959,159],"y":[1950,1950.1836734693877,1950.3673469387754,1950.5510204081634,1950.7346938775511,1950.9183673469388,1951.1020408163265,1951.2857142857142,1951.4693877551019,1951.6530612244899,1951.8367346938776,1952.0204081632653,1952.204081632653,1952.3877551020407,1952.5714285714287,1952.7551020408164,1952.9387755102041,1953.1224489795918,1953.3061224489795,1953.4897959183672,1953.6734693877552,1953.8571428571429,1954.0408163265306,1954.2244897959183,1954.408163265306,1954.591836734694,1954.7755102040817,1954.9591836734694,1955.1428571428571,1955.3265306122448,1955.5102040816328,1955.6938775510205,1955.8775510204082,1956.0612244897959,1956.2448979591836,1956.4285714285713,1956.6122448979593,1956.795918367347,1956.9795918367347,1957.1632653061224,1957.3469387755101,1957.5306122448981,1957.7142857142858,1957.8979591836735,1958.0816326530612,1958.2653061224489,1958.4489795918366,1958.6326530612246,1958.8163265306123,1959],"z":[[2.4360831999999846,2.55720062653063,2.678318053061048,2.7994354795919207,2.9205529061223388,3.0416703326529841,3.1627877591836295,3.2839051857142749,3.4050226122446929,3.5261400387755657,3.6472574653062111,3.7683748918366291,3.8894923183672745,4.0106097448979199,4.1317271714285653,4.2528445979592107,4.373962024489856,4.4950794510202741,4.6161968775509195,4.7373143040815648,4.8584317306122102,4.9795491571428556,5.100666583673501,5.221784010203919,5.3429014367345644,5.4640188632654372,5.5851362897958552,5.7062537163265006,5.827371142857146,5.948488569387564,6.0696059959184367,6.1907234224490821,6.3118408489795002,6.4329582755101455,6.5540757020407909,6.6751931285714363,6.7963105551020817,6.9174279816327271,7.0385454081631451,7.1596628346937905,7.2807802612244359,7.4018976877550813,7.5230151142857267,7.6441325408163721,7.7652499673467901,7.8863673938774355,8.0074848204080809,8.1286022469387262,8.2497196734693716,8.370837100000017],[2.3390714530612513,2.4601888795918967,2.5813063061223147,2.7024237326531875,2.8235411591836055,2.9446585857142509,3.0657760122448963,3.1868934387755417,3.3080108653059597,3.4291282918368324,3.5502457183674778,3.6713631448978958,3.7924805714285412,3.9135979979591866,4.034715424489832,4.1558328510204774,4.2769502775511228,4.3980677040815408,4.5191851306121862,4.6403025571428316,4.761419983673477,4.8825374102041224,5.0036548367347677,5.1247722632651858,5.2458896897958311,5.3670071163267039,5.4881245428571219,5.6092419693877673,5.7303593959184127,5.8514768224488307,5.9725942489797035,6.0937116755103489,6.2148291020407669,6.3359465285714123,6.4570639551020577,6.5781813816327031,6.6992988081633484,6.8204162346939938,6.9415336612244118,7.0626510877550572,7.1837685142857026,7.304885940816348,7.4260033673469934,7.5471207938776388,7.6682382204080568,7.7893556469387022,7.9104730734693476,8.031590499999993,8.1527079265306384,8.2738253530612837],[2.242059706122518,2.3631771326531634,2.4842945591835814,2.6054119857144542,2.7265294122448722,2.8476468387755176,2.968764265306163,3.0898816918368084,3.2109991183672264,3.3321165448980992,3.4532339714287446,3.5743513979591626,3.695468824489808,3.8165862510204533,3.9377036775510987,4.0588211040817441,4.1799385306123895,4.3010559571428075,4.4221733836734529,4.5432908102040983,4.6644082367347437,4.7855256632653891,4.9066430897960345,5.0277605163264525,5.1488779428570979,5.2699953693879706,5.3911127959183887,5.512230222449034,5.6333476489796794,5.7544650755100974,5.8755825020409702,5.9966999285716156,6.1178173551020336,6.238934781632679,6.3600522081633244,6.4811696346939698,6.6022870612246152,6.7234044877552606,6.8445219142856786,6.965639340816324,7.0867567673469694,7.2078741938776147,7.3289916204082601,7.4501090469389055,7.5712264734693235,7.6923438999999689,7.8134613265306143,7.9345787530612597,8.0556961795919051,8.1768136061225505],[2.1450479591835574,2.2661653857142028,2.3872828122446208,2.5084002387754936,2.6295176653059116,2.750635091836557,2.8717525183672024,2.9928699448978477,3.1139873714282658,3.2351047979591385,3.3562222244897839,3.4773396510202019,3.5984570775508473,3.7195745040814927,3.8406919306121381,3.9618093571427835,4.0829267836734289,4.2040442102038469,4.3251616367344923,4.4462790632651377,4.5673964897957831,4.6885139163264284,4.8096313428570738,4.9307487693874918,5.0518661959181372,5.17298362244901,5.294101048979428,5.4152184755100734,5.5363359020407188,5.6574533285711368,5.7785707551020096,5.899688181632655,6.020805608163073,6.1419230346937184,6.2630404612243638,6.3841578877550091,6.5052753142856545,6.6263927408162999,6.7475101673467179,6.8686275938773633,6.9897450204080087,7.1108624469386541,7.2319798734692995,7.3530972999999449,7.4742147265303629,7.5953321530610083,7.7164495795916537,7.8375670061222991,7.9586844326529445,8.0798018591835898],[2.0480362122448241,2.1691536387754695,2.2902710653058875,2.4113884918367603,2.5325059183671783,2.6536233448978237,2.7747407714284691,2.8958581979591145,3.0169756244895325,3.1380930510204053,3.2592104775510506,3.3803279040814687,3.501445330612114,3.6225627571427594,3.7436801836734048,3.8647976102040502,3.9859150367346956,4.1070324632651136,4.228149889795759,4.3492673163264044,4.4703847428570498,4.5915021693876952,4.7126195959183406,4.8337370224487586,4.954854448979404,5.0759718755102767,5.1970893020406947,5.3182067285713401,5.4393241551019855,5.5604415816324035,5.6815590081632763,5.8026764346939217,5.9237938612243397,6.0449112877549851,6.1660287142856305,6.2871461408162759,6.4082635673469213,6.5293809938775667,6.6504984204079847,6.7716158469386301,6.8927332734692754,7.0138506999999208,7.1349681265305662,7.2560855530612116,7.3772029795916296,7.498320406122275,7.6194378326529204,7.7405552591835658,7.8616726857142112,7.9827901122448566],[1.9510244653060909,2.0721418918367362,2.1932593183671543,2.314376744898027,2.435494171428445,2.5566115979590904,2.6777290244897358,2.7988464510203812,2.9199638775507992,3.041081304081672,3.1621987306123174,3.2833161571427354,3.4044335836733808,3.5255510102040262,3.6466684367346716,3.7677858632653169,3.8889032897959623,4.0100207163263804,4.1311381428570257,4.2522555693876711,4.3733729959183165,4.4944904224489619,4.6156078489796073,4.7367252755100253,4.8578427020406707,4.9789601285715435,5.1000775551019615,5.2211949816326069,5.3423124081632523,5.4634298346936703,5.584547261224543,5.7056646877551884,5.8267821142856064,5.9478995408162518,6.0690169673468972,6.1901343938775426,6.311251820408188,6.4323692469388334,6.5534866734692514,6.6746040999998968,6.7957215265305422,6.9168389530611876,7.037956379591833,7.1590738061224783,7.2801912326528964,7.4013086591835417,7.5224260857141871,7.6435435122448325,7.7646609387754779,7.8857783653061233],[1.8540127183673576,1.975130144898003,2.096247571428421,2.2173649979592938,2.3384824244897118,2.4595998510203572,2.5807172775510026,2.7018347040816479,2.822952130612066,2.9440695571429387,3.0651869836735841,3.1863044102040021,3.3074218367346475,3.4285392632652929,3.5496566897959383,3.6707741163265837,3.7918915428572291,3.9130089693876471,4.0341263959182925,4.1552438224489379,4.2763612489795833,4.3974786755102286,4.518596102040874,4.639713528571292,4.7608309551019374,4.8819483816328102,5.0030658081632282,5.1241832346938736,5.245300661224519,5.366418087754937,5.4875355142858098,5.6086529408164552,5.7297703673468732,5.8508877938775186,5.972005220408164,6.0931226469388093,6.2142400734694547,6.3353575000001001,6.4564749265305181,6.5775923530611635,6.6987097795918089,6.8198272061224543,6.9409446326530997,7.0620620591837451,7.1831794857141631,7.3042969122448085,7.4254143387754539,7.5465317653060993,7.6676491918367446,7.78876661836739],[1.7570009714286243,1.8781183979592697,1.9992358244896877,2.1203532510205605,2.2414706775509785,2.3625881040816239,2.4837055306122693,2.6048229571429147,2.7259403836733327,2.8470578102042055,2.9681752367348508,3.0892926632652689,3.2104100897959142,3.3315275163265596,3.452644942857205,3.5737623693878504,3.6948797959184958,3.8159972224489138,3.9371146489795592,4.0582320755102046,4.17934950204085,4.3004669285714954,4.4215843551021408,4.5427017816325588,4.6638192081632042,4.7849366346940769,4.9060540612244949,5.0271714877551403,5.1482889142857857,5.2694063408162037,5.3905237673470765,5.5116411938777219,5.6327586204081399,5.7538760469387853,5.8749934734694307,5.9961109000000761,6.1172283265307215,6.2383457530613668,6.3594631795917849,6.4805806061224303,6.6016980326530756,6.722815459183721,6.8439328857143664,6.9650503122450118,7.0861677387754298,7.2072851653060752,7.3284025918367206,7.449520018367366,7.5706374448980114,7.6917548714286568],[1.6599892244896637,1.7811066510203091,1.9022240775507271,2.0233415040815999,2.1444589306120179,2.2655763571426633,2.3866937836733086,2.507811210203954,2.628928636734372,2.7500460632652448,2.8711634897958902,2.9922809163263082,3.1133983428569536,3.234515769387599,3.3556331959182444,3.4767506224488898,3.5978680489795352,3.7189854755099532,3.8401029020405986,3.961220328571244,4.0823377551018893,4.2034551816325347,4.3245726081631801,4.4456900346935981,4.5668074612242435,4.6879248877551163,4.8090423142855343,4.9301597408161797,5.0512771673468251,5.1723945938772431,5.2935120204081159,5.4146294469387612,5.5357468734691793,5.6568642999998247,5.77798172653047,5.8990991530611154,6.0202165795917608,6.1413340061224062,6.2624514326528242,6.3835688591834696,6.504686285714115,6.6258037122447604,6.7469211387754058,6.8680385653060512,6.9891559918364692,7.1102734183671146,7.23139084489776,7.3525082714284054,7.4736256979590507,7.5947431244896961],[1.5629774775509304,1.6840949040815758,1.8052123306119938,1.9263297571428666,2.0474471836732846,2.16856461020393,2.2896820367345754,2.4107994632652208,2.5319168897956388,2.6530343163265115,2.7741517428571569,2.8952691693875749,3.0163865959182203,3.1375040224488657,3.2586214489795111,3.3797388755101565,3.5008563020408019,3.6219737285712199,3.7430911551018653,3.8642085816325107,3.9853260081631561,4.1064434346938015,4.2275608612244469,4.3486782877548649,4.4697957142855103,4.590913140816383,4.712030567346801,4.8331479938774464,4.9542654204080918,5.0753828469385098,5.1965002734693826,5.317617700000028,5.438735126530446,5.5598525530610914,5.6809699795917368,5.8020874061223822,5.9232048326530276,6.0443222591836729,6.165439685714091,6.2865571122447363,6.4076745387753817,6.5287919653060271,6.6499093918366725,6.7710268183673179,6.8921442448977359,7.0132616714283813,7.1343790979590267,7.2554965244896721,7.3766139510203175,7.4977313775509629],[1.4659657306121971,1.5870831571428425,1.7082005836732606,1.8293180102041333,1.9504354367345513,2.0715528632651967,2.1926702897958421,2.3137877163264875,2.4349051428569055,2.5560225693877783,2.6771399959184237,2.7982574224488417,2.9193748489794871,3.0404922755101325,3.1616097020407778,3.2827271285714232,3.4038445551020686,3.5249619816324866,3.646079408163132,3.7671968346937774,3.8883142612244228,4.0094316877550682,4.1305491142857136,4.2516665408161316,4.372783967346777,4.4939013938776498,4.6150188204080678,4.7361362469387132,4.8572536734693585,4.9783710999997766,5.0994885265306493,5.2206059530612947,5.3417233795917127,5.4628408061223581,5.5839582326530035,5.7050756591836489,5.8261930857142943,5.9473105122449397,6.0684279387753577,6.1895453653060031,6.3106627918366485,6.4317802183672939,6.5528976448979392,6.6740150714285846,6.7951324979590026,6.916249924489648,7.0373673510202934,7.1584847775509388,7.2796022040815842,7.4007196306122296],[1.3689539836734639,1.4900714102041093,1.6111888367345273,1.7323062632654,1.8534236897958181,1.9745411163264635,2.0956585428571088,2.2167759693877542,2.3378933959181722,2.459010822449045,2.5801282489796904,2.7012456755101084,2.8223631020407538,2.9434805285713992,3.0645979551020446,3.18571538163269,3.3068328081633354,3.4279502346937534,3.5490676612243988,3.6701850877550442,3.7913025142856895,3.9124199408163349,4.0335373673469803,4.1546547938773983,4.2757722204080437,4.3968896469389165,4.5180070734693345,4.6391244999999799,4.7602419265306253,4.8813593530610433,5.0024767795919161,5.1235942061225614,5.2447116326529795,5.3658290591836248,5.4869464857142702,5.6080639122449156,5.729181338775561,5.8502987653062064,5.9714161918366244,6.0925336183672698,6.2136510448979152,6.3347684714285606,6.455885897959206,6.5770033244898514,6.6981207510202694,6.8192381775509148,6.9403556040815602,7.0614730306122055,7.1825904571428509,7.3037078836734963],[1.2719422367347306,1.393059663265376,1.514177089795794,1.6352945163266668,1.7564119428570848,1.8775293693877302,1.9986467959183756,2.119764222449021,2.240881648979439,2.3619990755103117,2.4831165020409571,2.6042339285713751,2.7253513551020205,2.8464687816326659,2.9675862081633113,3.0887036346939567,3.2098210612246021,3.3309384877550201,3.4520559142856655,3.5731733408163109,3.6942907673469563,3.8154081938776017,3.9365256204082471,4.0576430469386651,4.1787604734693105,4.2998779000001832,4.4209953265306012,4.5421127530612466,4.663230179591892,4.78434760612231,4.9054650326531828,5.0265824591838282,5.1476998857142462,5.2688173122448916,5.389934738775537,5.5110521653061824,5.6321695918368277,5.7532870183674731,5.8744044448978912,5.9955218714285365,6.1166392979591819,6.2377567244898273,6.3588741510204727,6.4799915775511181,6.6011090040815361,6.7222264306121815,6.8433438571428269,6.9644612836734723,7.0855787102041177,7.2066961367347631],[1.1749304897959973,1.2960479163266427,1.4171653428570608,1.5382827693879335,1.6594001959183515,1.7805176224489969,1.9016350489796423,2.0227524755102877,2.1438699020407057,2.2649873285715785,2.3861047551022239,2.5072221816326419,2.6283396081632873,2.7494570346939327,2.870574461224578,2.9916918877552234,3.1128093142858688,3.2339267408162868,3.3550441673469322,3.4761615938775776,3.597279020408223,3.7183964469388684,3.8395138734695138,3.9606312999999318,4.0817487265305772,4.2028661530614499,4.323983579591868,4.4451010061225134,4.5662184326531587,4.6873358591835768,4.8084532857144495,4.9295707122450949,5.0506881387755129,5.1718055653061583,5.2929229918368037,5.4140404183674491,5.5351578448980945,5.6562752714287399,5.7773926979591579,5.8985101244898033,6.0196275510204487,6.1407449775510941,6.2618624040817394,6.3829798306123848,6.5040972571428028,6.6252146836734482,6.7463321102040936,6.867449536734739,6.9885669632653844,7.1096843897960298],[1.0779187428570367,1.1990361693876821,1.3201535959181001,1.4412710224489729,1.5623884489793909,1.6835058755100363,1.8046233020406817,1.9257407285713271,2.0468581551017451,2.1679755816326178,2.2890930081632632,2.4102104346936812,2.5313278612243266,2.652445287754972,2.7735627142856174,2.8946801408162628,3.0157975673469082,3.1369149938773262,3.2580324204079716,3.379149846938617,3.5002672734692624,3.6213846999999078,3.7425021265305531,3.8636195530609712,3.9847369795916165,4.1058544061224893,4.2269718326529073,4.3480892591835527,4.4692066857141981,4.5903241122446161,4.7114415387754889,4.8325589653061343,4.9536763918365523,5.0747938183671977,5.1959112448978431,5.3170286714284885,5.4381460979591338,5.5592635244897792,5.6803809510201972,5.8014983775508426,5.922615804081488,6.0437332306121334,6.1648506571427788,6.2859680836734242,6.4070855102038422,6.5282029367344876,6.649320363265133,6.7704377897957784,6.8915552163264238,7.0126726428570691],[0.98090699591830344,1.1020244224489488,1.2231418489793668,1.3442592755102396,1.4653767020406576,1.586494128571303,1.7076115551019484,1.8287289816325938,1.9498464081630118,2.0709638346938846,2.19208126122453,2.313198687754948,2.4343161142855934,2.5554335408162387,2.6765509673468841,2.7976683938775295,2.9187858204081749,3.0399032469385929,3.1610206734692383,3.2821380999998837,3.4032555265305291,3.5243729530611745,3.6454903795918199,3.7666078061222379,3.8877252326528833,4.008842659183756,4.1299600857141741,4.2510775122448194,4.3721949387754648,4.4933123653058828,4.6144297918367556,4.735547218367401,4.856664644897819,4.9777820714284644,5.0988994979591098,5.2200169244897552,5.3411343510204006,5.462251777551046,5.583369204081464,5.7044866306121094,5.8256040571427548,5.9467214836734001,6.0678389102040455,6.1889563367346909,6.3100737632651089,6.4311911897957543,6.5523086163263997,6.6734260428570451,6.7945434693876905,6.9156608959183359],[0.88389524897957017,1.0050126755102156,1.1261301020406336,1.2472475285715063,1.3683649551019244,1.4894823816325697,1.6105998081632151,1.7317172346938605,1.8528346612242785,1.9739520877551513,2.0950695142857967,2.2161869408162147,2.3373043673468601,2.4584217938775055,2.5795392204081509,2.7006566469387963,2.8217740734694416,2.9428914999998597,3.0640089265305051,3.1851263530611504,3.3062437795917958,3.4273612061224412,3.5484786326530866,3.6695960591835046,3.79071348571415,3.9118309122450228,4.0329483387754408,4.1540657653060862,4.2751831918367316,4.3963006183671496,4.5174180448980223,4.6385354714286677,4.7596528979590857,4.8807703244897311,5.0018877510203765,5.1230051775510219,5.2441226040816673,5.3652400306123127,5.4863574571427307,5.6074748836733761,5.7285923102040215,5.8497097367346669,5.9708271632653123,6.0919445897959577,6.2130620163263757,6.3341794428570211,6.4552968693876664,6.5764142959183118,6.6975317224489572,6.8186491489796026],[0.7868835020408369,0.90800092857148229,1.0291183551019003,1.1502357816327731,1.2713532081631911,1.3924706346938365,1.5135880612244819,1.6347054877551273,1.7558229142855453,1.876940340816418,1.9980577673470634,2.1191751938774814,2.2402926204081268,2.3614100469387722,2.4825274734694176,2.603644900000063,2.7247623265307084,2.8458797530611264,2.9669971795917718,3.0881146061224172,3.2092320326530626,3.3303494591837079,3.4514668857143533,3.5725843122447714,3.6937017387754167,3.8148191653062895,3.9359365918367075,4.0570540183673529,4.1781714448979983,4.2992888714284163,4.4204062979592891,4.5415237244899345,4.6626411510203525,4.7837585775509979,4.9048760040816433,5.0259934306122886,5.147110857142934,5.2682282836735794,5.3893457102039974,5.5104631367346428,5.6315805632652882,5.7526979897959336,5.873815416326579,5.9949328428572244,6.1160502693876424,6.2371676959182878,6.3582851224489332,6.4794025489795786,6.600519975510224,6.7216374020408693],[0.68987175510210363,0.81098918163274902,0.93210660816316704,1.0532240346940398,1.1743414612244578,1.2954588877551032,1.4165763142857486,1.537693740816394,1.658811167346812,1.7799285938776848,1.9010460204083302,2.0221634469387482,2.1432808734693936,2.2643983000000389,2.3855157265306843,2.5066331530613297,2.6277505795919751,2.7488680061223931,2.8699854326530385,2.9911028591836839,3.1122202857143293,3.2333377122449747,3.3544551387756201,3.4755725653060381,3.5966899918366835,3.7178074183675562,3.8389248448979743,3.9600422714286196,4.081159697959265,4.202277124489683,4.3233945510205558,4.4445119775512012,4.5656294040816192,4.6867468306122646,4.80786425714291,4.9289816836735554,5.0500991102042008,5.1712165367348462,5.2923339632652642,5.4134513897959096,5.534568816326555,5.6556862428572003,5.7768036693878457,5.8979210959184911,6.0190385224489091,6.1401559489795545,6.2612733755101999,6.3823908020408453,6.5035082285714907,6.6246256551021361],[0.59286000816314299,0.71397743469378838,0.8350948612242064,0.95621228775507916,1.0773297142854972,1.1984471408161426,1.319564567346788,1.4406819938774333,1.5617994204078514,1.6829168469387241,1.8040342734693695,1.9251516999997875,2.0462691265304329,2.1673865530610783,2.2885039795917237,2.4096214061223691,2.5307388326530145,2.6518562591834325,2.7729736857140779,2.8940911122447233,3.0152085387753687,3.136325965306014,3.2574433918366594,3.3785608183670774,3.4996782448977228,3.6207956714285956,3.7419130979590136,3.863030524489659,3.9841479510203044,4.1052653775507224,4.2263828040815952,4.3475002306122406,4.4686176571426586,4.589735083673304,4.7108525102039494,4.8319699367345947,4.9530873632652401,5.0742047897958855,5.1953222163263035,5.3164396428569489,5.4375570693875943,5.5586744959182397,5.6797919224488851,5.8009093489795305,5.9220267755099485,6.0431442020405939,6.1642616285712393,6.2853790551018847,6.40649648163253,6.5276139081631754],[0.49584826122440973,0.61696568775505511,0.73808311428547313,0.85920054081634589,0.98031796734676391,1.1014353938774093,1.2225528204080547,1.3436702469387001,1.4647876734691181,1.5859050999999909,1.7070225265306362,1.8281399530610543,1.9492573795916996,2.070374806122345,2.1914922326529904,2.3126096591836358,2.4337270857142812,2.5548445122446992,2.6759619387753446,2.79707936530599,2.9181967918366354,3.0393142183672808,3.1604316448979262,3.2815490714283442,3.4026664979589896,3.5237839244898623,3.6449013510202803,3.7660187775509257,3.8871362040815711,4.0082536306119891,4.1293710571428619,4.2504884836735073,4.3716059102039253,4.4927233367345707,4.6138407632652161,4.7349581897958615,4.8560756163265069,4.9771930428571522,5.0983104693875703,5.2194278959182157,5.340545322448861,5.4616627489795064,5.5827801755101518,5.7038976020407972,5.8250150285712152,5.9461324551018606,6.067249881632506,6.1883673081631514,6.3094847346937968,6.4306021612244422],[0.39883651428567646,0.51995394081632185,0.64107136734673986,0.76218879387761262,0.88330622040803064,1.004423646938676,1.1255410734693214,1.2466584999999668,1.3677759265303848,1.4888933530612576,1.610010779591903,1.731128206122321,1.8522456326529664,1.9733630591836118,2.0944804857142572,2.2155979122449025,2.3367153387755479,2.4578327653059659,2.5789501918366113,2.7000676183672567,2.8211850448979021,2.9423024714285475,3.0634198979591929,3.1845373244896109,3.3056547510202563,3.4267721775511291,3.5478896040815471,3.6690070306121925,3.7901244571428379,3.9112418836732559,4.0323593102041286,4.153476736734774,4.274594163265192,4.3957115897958374,4.5168290163264828,4.6379464428571282,4.7590638693877736,4.880181295918419,5.001298722448837,5.1224161489794824,5.2435335755101278,5.3646510020407732,5.4857684285714186,5.6068858551020639,5.728003281632482,5.8491207081631273,5.9702381346937727,6.0913555612244181,6.2124729877550635,6.3335904142857089],[0.30182476734694319,0.42294219387758858,0.54405962040800659,0.66517704693887936,0.78629447346929737,0.90741189999994276,1.0285293265305882,1.1496467530612335,1.2707641795916516,1.3918816061225243,1.5129990326531697,1.6341164591835877,1.7552338857142331,1.8763513122448785,1.9974687387755239,2.1185861653061693,2.2397035918368147,2.3608210183672327,2.4819384448978781,2.6030558714285235,2.7241732979591688,2.8452907244898142,2.9664081510204596,3.0875255775508776,3.208643004081523,3.3297604306123958,3.4508778571428138,3.5719952836734592,3.6931127102041046,3.8142301367345226,3.9353475632653954,4.0564649897960408,4.1775824163264588,4.2986998428571042,4.4198172693877495,4.5409346959183949,4.6620521224490403,4.7831695489796857,4.9042869755101037,5.0254044020407491,5.1465218285713945,5.2676392551020399,5.3887566816326853,5.5098741081633307,5.6309915346937487,5.7521089612243941,5.8732263877550395,5.9943438142856849,6.1154612408163302,6.2365786673469756],[0.20481302040820992,0.32593044693885531,0.44704787346927333,0.56816530000014609,0.6892827265305641,0.81040015306120949,0.93151757959185488,1.0526350061225003,1.1737524326529183,1.294869859183791,1.4159872857144364,1.5371047122448545,1.6582221387754998,1.7793395653061452,1.9004569918367906,2.021574418367436,2.1426918448980814,2.2638092714284994,2.3849266979591448,2.5060441244897902,2.6271615510204356,2.748278977551081,2.8693964040817264,2.9905138306121444,3.1116312571427898,3.2327486836736625,3.3538661102040805,3.4749835367347259,3.5961009632653713,3.7172183897957893,3.8383358163266621,3.9594532428573075,4.0805706693877255,4.2016880959183709,4.3228055224490163,4.4439229489796617,4.5650403755103071,4.6861578020409524,4.8072752285713705,4.9283926551020159,5.0495100816326612,5.1706275081633066,5.291744934693952,5.4128623612245974,5.5339797877550154,5.6550972142856608,5.7762146408163062,5.8973320673469516,6.018449493877597,6.1395669204082424],[0.10780127346947666,0.22891870000012204,0.35003612653054006,0.47115355306141282,0.59227097959183084,0.71338840612247623,0.83450583265312162,0.955623259183767,1.076740685714185,1.1978581122450578,1.3189755387757032,1.4400929653061212,1.5612103918367666,1.682327818367412,1.8034452448980574,1.9245626714287027,2.0456800979593481,2.1667975244897661,2.2879149510204115,2.4090323775510569,2.5301498040817023,2.6512672306123477,2.7723846571429931,2.8935020836734111,3.0146195102040565,3.1357369367349293,3.2568543632653473,3.3779717897959927,3.4990892163266381,3.6202066428570561,3.7413240693879288,3.8624414959185742,3.9835589224489922,4.1046763489796376,4.225793775510283,4.3469112020409284,4.4680286285715738,4.5891460551022192,4.7102634816326372,4.8313809081632826,4.952498334693928,5.0736157612245734,5.1947331877552188,5.3158506142858641,5.4369680408162822,5.5580854673469275,5.6792028938775729,5.8003203204082183,5.9214377469388637,6.0425551734695091],[0.010789526530516014,0.1319069530611614,0.25302437959157942,0.37414180612245218,0.4952592326528702,0.61637665918351559,0.73749408571416097,0.85861151224480636,0.97972893877522438,1.1008463653060971,1.2219637918367425,1.3430812183671605,1.4641986448978059,1.5853160714284513,1.7064334979590967,1.8275509244897421,1.9486683510203875,2.0697857775508055,2.1909032040814509,2.3120206306120963,2.4331380571427417,2.5542554836733871,2.6753729102040325,2.7964903367344505,2.9176077632650959,3.0387251897959686,3.1598426163263866,3.280960042857032,3.4020774693876774,3.5231948959180954,3.6443123224489682,3.7654297489796136,3.8865471755100316,4.007664602040677,4.1287820285713224,4.2498994551019678,4.3710168816326131,4.4921343081632585,4.6132517346936766,4.7343691612243219,4.8554865877549673,4.9766040142856127,5.0977214408162581,5.2188388673469035,5.3399562938773215,5.4610737204079669,5.5821911469386123,5.7033085734692577,5.8244259999999031,5.9455434265305485],[-0.086222220408217254,0.034895206122428135,0.15601263265284615,0.27713005918371891,0.39824748571413693,0.51936491224478232,0.64048233877542771,0.7615997653060731,0.88271719183649111,1.0038346183673639,1.1249520448980093,1.2460694714284273,1.3671868979590727,1.4883043244897181,1.6094217510203634,1.7305391775510088,1.8516566040816542,1.9727740306120722,2.0938914571427176,2.215008883673363,2.3361263102040084,2.4572437367346538,2.5783611632652992,2.6994785897957172,2.8205960163263626,2.9417134428572353,3.0628308693876534,3.1839482959182988,3.3050657224489441,3.4261831489793622,3.5473005755102349,3.6684180020408803,3.7895354285712983,3.9106528551019437,4.0317702816325891,4.1528877081632345,4.2740051346938799,4.3951225612245253,4.5162399877549433,4.6373574142855887,4.7584748408162341,4.8795922673468795,5.0007096938775248,5.1218271204081702,5.2429445469385882,5.3640619734692336,5.485179399999879,5.6062968265305244,5.7274142530611698,5.8485316795918152],[-0.18323396734695052,-0.062116540816305132,0.059000885714112883,0.18011831224498565,0.30123573877540366,0.42235316530604905,0.54347059183669444,0.66458801836733983,0.78570544489775784,0.90682287142863061,1.027940297959276,1.149057724489694,1.2701751510203394,1.3912925775509848,1.5124100040816302,1.6335274306122756,1.754644857142921,1.875762283673339,1.9968797102039844,2.1179971367346297,2.2391145632652751,2.3602319897959205,2.4813494163265659,2.6024668428569839,2.7235842693876293,2.8447016959185021,2.9658191224489201,3.0869365489795655,3.2080539755102109,3.3291714020406289,3.4502888285715017,3.571406255102147,3.6925236816325651,3.8136411081632104,3.9347585346938558,4.0558759612245012,4.1769933877551466,4.298110814285792,4.41922824081621,4.5403456673468554,4.6614630938775008,4.7825805204081462,4.9036979469387916,5.024815373469437,5.145932799999855,5.2670502265305004,5.3881676530611458,5.5092850795917911,5.6304025061224365,5.7515199326530819],[-0.28024571428568379,-0.1591282877550384,-0.038010861224620385,0.083106565306252378,0.20422399183667039,0.32534141836731578,0.44645884489796117,0.56757627142860656,0.68869369795902458,0.80981112448989734,0.93092855102054273,1.0520459775509607,1.1731634040816061,1.2942808306122515,1.4153982571428969,1.5365156836735423,1.6576331102041877,1.7787505367346057,1.8998679632652511,2.0209853897958965,2.1421028163265419,2.2632202428571873,2.3843376693878326,2.5054550959182507,2.6265725224488961,2.7476899489797688,2.8688073755101868,2.9899248020408322,3.1110422285714776,3.2321596551018956,3.3532770816327684,3.4743945081634138,3.5955119346938318,3.7166293612244772,3.8377467877551226,3.958864214285768,4.0799816408164133,4.2010990673470587,4.3222164938774768,4.4433339204081221,4.5644513469387675,4.6855687734694129,4.8066862000000583,4.9278036265307037,5.0489210530611217,5.1700384795917671,5.2911559061224125,5.4122733326530579,5.5333907591837033,5.6545081857143487],[-0.37725746122441706,-0.25614003469377167,-0.13502260816335365,-0.01390518163248089,0.10721224489793713,0.22832967142858251,0.3494470979592279,0.47056452448987329,0.59168195102029131,0.71279937755116407,0.83391680408180946,0.95503423061222747,1.0761516571428729,1.1972690836735183,1.3183865102041636,1.439503936734809,1.5606213632654544,1.6817387897958724,1.8028562163265178,1.9239736428571632,2.0450910693878086,2.166208495918454,2.2873259224490994,2.4084433489795174,2.5295607755101628,2.6506782020410355,2.7717956285714536,2.892913055102099,3.0140304816327443,3.1351479081631624,3.2562653346940351,3.3773827612246805,3.4985001877550985,3.6196176142857439,3.7407350408163893,3.8618524673470347,3.9829698938776801,4.1040873204083255,4.2252047469387435,4.3463221734693889,4.4674396000000343,4.5885570265306797,4.709674453061325,4.8307918795919704,4.9519093061223884,5.0730267326530338,5.1941441591836792,5.3152615857143246,5.43637901224497,5.5574964387756154],[-0.4742692081633777,-0.35315178163273231,-0.23203435510231429,-0.11091692857144153,0.010200497958976484,0.13131792448962187,0.25243535102026726,0.37355277755091265,0.49467020408133067,0.61578763061220343,0.73690505714284882,0.85802248367326683,0.97913991020391222,1.1002573367345576,1.221374763265203,1.3424921897958484,1.4636096163264938,1.5847270428569118,1.7058444693875572,1.8269618959182026,1.948079322448848,2.0691967489794933,2.1903141755101387,2.3114316020405568,2.4325490285712021,2.5536664551020749,2.6747838816324929,2.7959013081631383,2.9170187346937837,3.0381361612242017,3.1592535877550745,3.2803710142857199,3.4014884408161379,3.5226058673467833,3.6437232938774287,3.764840720408074,3.8859581469387194,4.0070755734693648,4.1281929999997828,4.2493104265304282,4.3704278530610736,4.491545279591719,4.6126627061223644,4.7337801326530098,4.8548975591834278,4.9760149857140732,5.0971324122447186,5.218249838775364,5.3393672653060094,5.4604846918366547],[-0.57128095510211097,-0.45016352857146558,-0.32904610204104756,-0.2079286755101748,-0.086811248979756783,0.034306177550888606,0.15542360408153399,0.27654103061217938,0.3976584571425974,0.51877588367347016,0.63989331020411555,0.76101073673453357,0.88212816326517896,1.0032455897958243,1.1243630163264697,1.2454804428571151,1.3665978693877605,1.4877152959181785,1.6088327224488239,1.7299501489794693,1.8510675755101147,1.9721850020407601,2.0933024285714055,2.2144198551018235,2.3355372816324689,2.4566547081633416,2.5777721346937597,2.698889561224405,2.8200069877550504,2.9411244142854684,3.0622418408163412,3.1833592673469866,3.3044766938774046,3.42559412040805,3.5467115469386954,3.6678289734693408,3.7889463999999862,3.9100638265306316,4.0311812530610496,4.152298679591695,4.2734161061223404,4.3945335326529857,4.5156509591836311,4.6367683857142765,4.7578858122446945,4.8790032387753399,5.0001206653059853,5.1212380918366307,5.2423555183672761,5.3634729448979215],[-0.66829270204084423,-0.54717527551019884,-0.42605784897978083,-0.30494042244890807,-0.18382299591849005,-0.062705569387844662,0.058411857142800727,0.17952928367344612,0.30064671020386413,0.42176413673473689,0.54288156326538228,0.6639989897958003,0.78511641632644569,0.90623384285709108,1.0273512693877365,1.1484686959183819,1.2695861224490272,1.3907035489794453,1.5118209755100906,1.632938402040736,1.7540558285713814,1.8751732551020268,1.9962906816326722,2.1174081081630902,2.2385255346937356,2.3596429612246084,2.4807603877550264,2.6018778142856718,2.7229952408163172,2.8441126673467352,2.9652300938776079,3.0863475204082533,3.2074649469386713,3.3285823734693167,3.4496997999999621,3.5708172265306075,3.6919346530612529,3.8130520795918983,3.9341695061223163,4.0552869326529617,4.1764043591836071,4.2975217857142525,4.4186392122448979,4.5397566387755433,4.6608740653059613,4.7819914918366067,4.903108918367252,5.0242263448978974,5.1453437714285428,5.2664611979591882],[-0.7653044489795775,-0.64418702244893211,-0.5230695959185141,-0.40195216938764133,-0.28083474285722332,-0.15971731632657793,-0.03859988979593254,0.082517536734712849,0.20363496326513086,0.32475238979600363,0.44586981632664902,0.56698724285706703,0.68810466938771242,0.80922209591835781,0.9303395224490032,1.0514569489796486,1.172574375510294,1.293691802040712,1.4148092285713574,1.5359266551020028,1.6570440816326482,1.7781615081632935,1.8992789346939389,2.020396361224357,2.1415137877550023,2.2626312142858751,2.3837486408162931,2.5048660673469385,2.6259834938775839,2.7471009204080019,2.8682183469388747,2.9893357734695201,3.1104531999999381,3.2315706265305835,3.3526880530612289,3.4738054795918742,3.5949229061225196,3.716040332653165,3.837157759183583,3.9582751857142284,4.0793926122448738,4.2005100387755192,4.3216274653061646,4.44274489183681,4.563862318367228,4.6849797448978734,4.8060971714285188,4.9272145979591642,5.0483320244898096,5.1694494510204549],[-0.86231619591831077,-0.74119876938766538,-0.62008134285724736,-0.4989639163263746,-0.37784648979595659,-0.2567290632653112,-0.13561163673466581,-0.014494210204020419,0.1066232163263976,0.22774064285727036,0.34885806938791575,0.46997549591833376,0.59109292244897915,0.71221034897962454,0.83332777551026993,0.95444520204091532,1.0755626285715607,1.1966800551019787,1.3177974816326241,1.4389149081632695,1.5600323346939149,1.6811497612245603,1.8022671877552057,1.9233846142856237,2.0445020408162691,2.1656194673471418,2.2867368938775599,2.4078543204082052,2.5289717469388506,2.6500891734692686,2.7712066000001414,2.8923240265307868,3.0134414530612048,3.1345588795918502,3.2556763061224956,3.376793732653141,3.4979111591837864,3.6190285857144318,3.7401460122448498,3.8612634387754952,3.9823808653061405,4.1034982918367859,4.2246157183674313,4.3457331448980767,4.4668505714284947,4.5879679979591401,4.7090854244897855,4.8302028510204309,4.9513202775510763,5.0724377040817217],[-0.95932794285727141,-0.83821051632662602,-0.71709308979620801,-0.59597566326533524,-0.47485823673491723,-0.35374081020427184,-0.23262338367362645,-0.11150595714298106,0.009611469387436955,0.13072889591830972,0.25184632244895511,0.37296374897937312,0.49408117551001851,0.6151986020406639,0.73631602857130929,0.85743345510195468,0.97855088163260007,1.0996683081630181,1.2207857346936635,1.3419031612243089,1.4630205877549542,1.5841380142855996,1.705255440816245,1.826372867346663,1.9474902938773084,2.0686077204081812,2.1897251469385992,2.3108425734692446,2.43195999999989,2.553077426530308,2.6741948530611808,2.7953122795918262,2.9164297061222442,3.0375471326528896,3.1586645591835349,3.2797819857141803,3.4008994122448257,3.5220168387754711,3.6431342653058891,3.7642516918365345,3.8853691183671799,4.0064865448978253,4.1276039714284707,4.2487213979591161,4.3698388244895341,4.4909562510201795,4.6120736775508249,4.7331911040814703,4.8543085306121156,4.975425957142761],[-1.0563396897960047,-0.93522226326535929,-0.81410483673494127,-0.69298741020406851,-0.57186998367365049,-0.45075255714300511,-0.32963513061235972,-0.20851770408171433,-0.087400277551296313,0.03371714897957645,0.15483457551022184,0.27595200204063985,0.39706942857128524,0.51818685510193063,0.63930428163257602,0.76042170816322141,0.8815391346938668,1.0026565612242848,1.1237739877549302,1.2448914142855756,1.366008840816221,1.4871262673468664,1.6082436938775118,1.7293611204079298,1.8504785469385752,1.9715959734694479,2.0927133999998659,2.2138308265305113,2.3349482530611567,2.4560656795915747,2.5771831061224475,2.6983005326530929,2.8194179591835109,2.9405353857141563,3.0616528122448017,3.1827702387754471,3.3038876653060925,3.4250050918367378,3.5461225183671559,3.6672399448978013,3.7883573714284466,3.909474797959092,4.0305922244897374,4.1517096510203828,4.2728270775508008,4.3939445040814462,4.5150619306120916,4.636179357142737,4.7572967836733824,4.8784142102040278],[-1.1533514367347379,-1.0322340102040926,-0.91111658367367454,-0.78999915714280178,-0.66888173061238376,-0.54776430408173837,-0.42664687755109298,-0.3055294510204476,-0.18441202449002958,-0.063294597959156818,0.057822828571488571,0.17894025510190659,0.30005768163255198,0.42117510816319736,0.54229253469384275,0.66340996122448814,0.78452738775513353,0.90564481428555155,1.0267622408161969,1.1478796673468423,1.2689970938774877,1.3901145204081331,1.5112319469387785,1.6323493734691965,1.7534667999998419,1.8745842265307147,1.9957016530611327,2.1168190795917781,2.2379365061224235,2.3590539326528415,2.4801713591837142,2.6012887857143596,2.7224062122447776,2.843523638775423,2.9646410653060684,3.0857584918367138,3.2068759183673592,3.3279933448980046,3.4491107714284226,3.570228197959068,3.6913456244897134,3.8124630510203588,3.9335804775510042,4.0546979040816495,4.1758153306120676,4.2969327571427129,4.4180501836733583,4.5391676102040037,4.6602850367346491,4.7814024632652945],[-1.2503631836734712,-1.1292457571428258,-1.0081283306124078,-0.88701090408153505,-0.76589347755111703,-0.64477605102047164,-0.52365862448982625,-0.40254119795918086,-0.28142377142876285,-0.16030634489789009,-0.039188918367244696,0.081928508163173319,0.20304593469381871,0.3241633612244641,0.44528078775510949,0.56639821428575488,0.68751564081640026,0.80863306734681828,0.92975049387746367,1.0508679204081091,1.1719853469387544,1.2931027734693998,1.4142202000000452,1.5353376265304632,1.6564550530611086,1.7775724795919814,1.8986899061223994,2.0198073326530448,2.1409247591836902,2.2620421857141082,2.383159612244981,2.5042770387756264,2.6253944653060444,2.7465118918366898,2.8676293183673351,2.9887467448979805,3.1098641714286259,3.2309815979592713,3.3520990244896893,3.4732164510203347,3.5943338775509801,3.7154513040816255,3.8365687306122709,3.9576861571429163,4.0788035836733343,4.1999210102039797,4.3210384367346251,4.4421558632652705,4.5632732897959158,4.6843907163265612],[-1.3473749306122045,-1.2262575040815591,-1.1051400775511411,-0.98402265102026831,-0.8629052244898503,-0.74178779795920491,-0.62067037142855952,-0.49955294489791413,-0.37843551836749612,-0.25731809183662335,-0.13620066530597796,-0.015083238775559948,0.10603418775508544,0.22715161428573083,0.34826904081637622,0.46938646734702161,0.590503893877667,0.71162132040808501,0.8327387469387304,0.95385617346937579,1.0749736000000212,1.1960910265306666,1.317208453061312,1.43832587959173,1.5594433061223754,1.6805607326532481,1.8016781591836661,1.9227955857143115,2.0439130122449569,2.1650304387753749,2.2861478653062477,2.4072652918368931,2.5283827183673111,2.6495001448979565,2.7706175714286019,2.8917349979592473,3.0128524244898927,3.133969851020538,3.2550872775509561,3.3762047040816014,3.4973221306122468,3.6184395571428922,3.7395569836735376,3.860674410204183,3.981791836734601,4.1029092632652464,4.2240266897958918,4.3451441163265372,4.4662615428571826,4.587378969387828],[-1.4443866775509377,-1.3232692510202924,-1.2021518244898743,-1.0810343979590016,-0.95991697142858357,-0.83879954489793818,-0.71768211836729279,-0.5965646918366474,-0.47544726530622938,-0.35432983877535662,-0.23321241224471123,-0.11209498571429322,0.009022440816352173,0.13013986734699756,0.25125729387764295,0.37237472040828834,0.49349214693893373,0.61460957346935174,0.73572699999999713,0.85684442653064252,0.97796185306128791,1.0990792795919333,1.2201967061225787,1.3413141326529967,1.4624315591836421,1.5835489857145149,1.7046664122449329,1.8257838387755783,1.9469012653062236,2.0680186918366417,2.1891361183675144,2.3102535448981598,2.4313709714285778,2.5524883979592232,2.6736058244898686,2.794723251020514,2.9158406775511594,3.0369581040818048,3.1580755306122228,3.2791929571428682,3.4003103836735136,3.521427810204159,3.6425452367348043,3.7636626632654497,3.8847800897958678,4.0058975163265131,4.1270149428571585,4.2481323693878039,4.3692497959184493,4.4903672224490947],[-1.5413984244898984,-1.420280997959253,-1.299163571428835,-1.1780461448979622,-1.0569287183675442,-0.93581129183689882,-0.81469386530625343,-0.69357643877560804,-0.57245901224519002,-0.45134158571431726,-0.33022415918367187,-0.20910673265325386,-0.087989306122608468,0.033128120408036921,0.15424554693868231,0.2753629734693277,0.39648039999997309,0.5175978265303911,0.63871525306103649,0.75983267959168188,0.88095010612232727,1.0020675326529727,1.123184959183618,1.2443023857140361,1.3654198122446815,1.4865372387755542,1.6076546653059722,1.7287720918366176,1.849889518367263,1.971006944897681,2.0921243714285538,2.2132417979591992,2.3343592244896172,2.4554766510202626,2.576594077550908,2.6977115040815534,2.8188289306121987,2.9399463571428441,3.0610637836732622,3.1821812102039075,3.3032986367345529,3.4244160632651983,3.5455334897958437,3.6666509163264891,3.7877683428569071,3.9088857693875525,4.0300031959181979,4.1511206224488433,4.2722380489794887,4.3933554755101341],[-1.6384101714286317,-1.5172927448979863,-1.3961753183675683,-1.2750578918366955,-1.1539404653062775,-1.0328230387756321,-0.9117056122449867,-0.79058818571434131,-0.66947075918392329,-0.54835333265305053,-0.42723590612240514,-0.30611847959198712,-0.18500105306134174,-0.063883626530696347,0.057233799999949042,0.17835122653059443,0.29946865306123982,0.42058607959165784,0.54170350612230322,0.66282093265294861,0.783938359183594,0.90505578571423939,1.0261732122448848,1.1472906387753028,1.2684080653059482,1.3895254918368209,1.510642918367239,1.6317603448978844,1.7528777714285297,1.8739951979589478,1.9951126244898205,2.1162300510204659,2.2373474775508839,2.3584649040815293,2.4795823306121747,2.6006997571428201,2.7218171836734655,2.8429346102041109,2.9640520367345289,3.0851694632651743,3.2062868897958197,3.3274043163264651,3.4485217428571104,3.5696391693877558,3.6907565959181738,3.8118740224488192,3.9329914489794646,4.05410887551011,4.1752263020407554,4.2963437285714008],[-1.7354219183673649,-1.6143044918367195,-1.4931870653063015,-1.3720696387754288,-1.2509522122450107,-1.1298347857143654,-1.00871735918372,-0.88759993265307457,-0.76648250612265656,-0.6453650795917838,-0.52424765306113841,-0.40313022653072039,-0.282012800000075,-0.16089537346942961,-0.039777946938784225,0.081339479591861163,0.20245690612250655,0.32357433265292457,0.44469175918356996,0.56580918571421535,0.68692661224486073,0.80804403877550612,0.92916146530615151,1.0502788918365695,1.1713963183672149,1.2925137448980877,1.4136311714285057,1.5347485979591511,1.6558660244897965,1.7769834510202145,1.8981008775510873,2.0192183040817326,2.1403357306121507,2.261453157142796,2.3825705836734414,2.5036880102040868,2.6248054367347322,2.7459228632653776,2.8670402897957956,2.988157716326441,3.1092751428570864,3.2303925693877318,3.3515099959183772,3.4726274224490226,3.5937448489794406,3.714862275510086,3.8359797020407314,3.9570971285713767,4.0782145551020221,4.1993319816326675],[-1.8324336653060982,-1.7113162387754528,-1.5901988122450348,-1.469081385714162,-1.347963959183744,-1.2268465326530986,-1.1057291061224532,-0.98461167959180784,-0.86349425306138983,-0.74237682653051706,-0.62125939999987168,-0.50014197346945366,-0.37902454693880827,-0.25790712040816288,-0.13678969387751749,-0.015672267346872104,0.10544515918377328,0.2265625857141913,0.34768001224483669,0.46879743877548208,0.58991486530612747,0.71103229183677286,0.83214971836741825,0.95326714489783626,1.0743845714284816,1.1955019979593544,1.3166194244897724,1.4377368510204178,1.5588542775510632,1.6799717040814812,1.801089130612354,1.9222065571429994,2.0433239836734174,2.1644414102040628,2.2855588367347082,2.4066762632653536,2.5277936897959989,2.6489111163266443,2.7700285428570623,2.8911459693877077,3.0122633959183531,3.1333808224489985,3.2544982489796439,3.3756156755102893,3.4967331020407073,3.6178505285713527,3.7389679551019981,3.8600853816326435,3.9812028081632889,4.1023202346939343],[-1.9294454122448315,-1.8083279857141861,-1.6872105591837681,-1.5660931326528953,-1.4449757061224773,-1.3238582795918319,-1.2027408530611865,-1.0816234265305411,-0.96050600000012309,-0.83938857346925033,-0.71827114693860494,-0.59715372040818693,-0.47603629387754154,-0.35491886734689615,-0.23380144081625076,-0.11268401428560537,0.0084334122450400173,0.12955083877545803,0.25066826530610342,0.37178569183674881,0.4929031183673942,0.61402054489803959,0.73513797142868498,0.85625539795910299,0.97737282448974838,1.0984902510206211,1.2196076775510392,1.3407251040816845,1.4618425306123299,1.582959957142748,1.7040773836736207,1.8251948102042661,1.9463122367346841,2.0674296632653295,2.1885470897959749,2.3096645163266203,2.4307819428572657,2.5518993693879111,2.6730167959183291,2.7941342224489745,2.9152516489796199,3.0363690755102652,3.1574865020409106,3.278603928571556,3.399721355101974,3.5208387816326194,3.6419562081632648,3.7630736346939102,3.8841910612245556,4.005308487755201],[-2.0264571591837921,-1.9053397326531467,-1.7842223061227287,-1.6631048795918559,-1.5419874530614379,-1.4208700265307925,-1.2997526000001471,-1.1786351734695018,-1.0575177469390837,-0.93640032040821097,-0.81528289387756558,-0.69416546734714757,-0.57304804081650218,-0.45193061428585679,-0.3308131877552114,-0.20969576122456601,-0.088578334693920624,0.032539091836497391,0.15365651836714278,0.27477394489778817,0.39589137142843356,0.51700879795907895,0.63812622448972434,0.75924365102014235,0.88036107755078774,1.0014785040816605,1.1225959306120785,1.2437133571427239,1.3648307836733693,1.4859482102037873,1.6070656367346601,1.7281830632653055,1.8493004897957235,1.9704179163263689,2.0915353428570143,2.2126527693876596,2.333770195918305,2.4548876224489504,2.5760050489793684,2.6971224755100138,2.8182399020406592,2.9393573285713046,3.06047475510195,3.1815921816325954,3.3027096081630134,3.4238270346936588,3.5449444612243042,3.6660618877549496,3.787179314285595,3.9082967408162403],[-2.1234689061225254,-2.00235147959188,-1.881234053061462,-1.7601166265305892,-1.6389992000001712,-1.5178817734695258,-1.3967643469388804,-1.275646920408235,-1.154529493877817,-1.0334120673469442,-0.91229464081629885,-0.79117721428588084,-0.67005978775523545,-0.54894236122459006,-0.42782493469394467,-0.30670750816329928,-0.18559008163265389,-0.064472655102235876,0.056644771428409513,0.1777621979590549,0.29887962448970029,0.41999705102034568,0.54111447755099107,0.66223190408140908,0.78334933061205447,0.90446675714292724,1.0255841836733453,1.1467016102039906,1.267819036734636,1.388936463265054,1.5100538897959268,1.6311713163265722,1.7522887428569902,1.8734061693876356,1.994523595918281,2.1156410224489264,2.2367584489795718,2.3578758755102172,2.4789933020406352,2.6001107285712806,2.7212281551019259,2.8423455816325713,2.9634630081632167,3.0845804346938621,3.2056978612242801,3.3268152877549255,3.4479327142855709,3.5690501408162163,3.6901675673468617,3.8112849938775071],[-2.2204806530612586,-2.0993632265306132,-1.9782458000001952,-1.8571283734693225,-1.7360109469389045,-1.6148935204082591,-1.4937760938776137,-1.3726586673469683,-1.2515412408165503,-1.1304238142856775,-1.0093063877550321,-0.8881889612246141,-0.76707153469396872,-0.64595410816332333,-0.52483668163267794,-0.40371925510203255,-0.28260182857138716,-0.16148440204096914,-0.040366975510323755,0.080750451020321634,0.20186787755096702,0.32298530408161241,0.4441027306122578,0.56522015714267582,0.68633758367332121,0.80745501020419397,0.92857243673461198,1.0496898632652574,1.1708072897959028,1.2919247163263208,1.4130421428571935,1.5341595693878389,1.6552769959182569,1.7763944224489023,1.8975118489795477,2.0186292755101931,2.1397467020408385,2.2608641285714839,2.3819815551019019,2.5030989816325473,2.6242164081631927,2.7453338346938381,2.8664512612244835,2.9875686877551288,3.1086861142855469,3.2298035408161923,3.3509209673468376,3.472038393877483,3.5931558204081284,3.7142732469387738],[-2.3174923999999919,-2.1963749734693465,-2.0752575469389285,-1.9541401204080557,-1.8330226938776377,-1.7119052673469923,-1.5907878408163469,-1.4696704142857016,-1.3485529877552835,-1.2274355612244108,-1.1063181346937654,-0.98520070816334737,-0.86408328163270198,-0.74296585510205659,-0.6218484285714112,-0.50073100204076582,-0.37961357551012043,-0.25849614897970241,-0.13737872244905702,-0.016261295918411633,0.10485613061223376,0.22597355714287914,0.34709098367352453,0.46820841020394255,0.58932583673458794,0.7104432632654607,0.83156068979587872,0.9526781163265241,1.0737955428571695,1.1949129693875875,1.3160303959184603,1.4371478224491057,1.5582652489795237,1.6793826755101691,1.8005001020408145,1.9216175285714598,2.0427349551021052,2.1638523816327506,2.2849698081631686,2.406087234693814,2.5272046612244594,2.6483220877551048,2.7694395142857502,2.8905569408163956,3.0116743673468136,3.132791793877459,3.2539092204081044,3.3750266469387498,3.4961440734693952,3.6172615000000405]],"mode":"markers","marker":{"size":5,"color":"black"},"type":"surface","opacity":0.5,"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
<section id="computing-the-r2-coefficient" class="slide level2 smaller">
<h2>Computing the <span class="math inline">R^2</span> coefficient</h2>
<ul>
<li><p>How well does the multiple linear model fit our data?</p></li>
<li><p>To answer this question we compute the coefficient of determination</p></li>
</ul>
<p><span class="math display">
R^2 = 1 - \frac{\mathop{\mathrm{RSS}}}{\mathop{\mathrm{TSS}}}
</span></p>
</section>
<section id="computing-mathopmathrmtss" class="slide level2 smaller">
<h2>Computing <span class="math inline">\mathop{\mathrm{TSS}}</span></h2>
<ul>
<li>We have that</li>
</ul>
<p><span class="math display">
\mathop{\mathrm{TSS}}:= \sum_{i=1}^n (y_i - \overline{y})^2
</span></p>
<ul>
<li>We compute <span class="math inline">\overline{y}</span> with the R command</li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mean of y</span></span>
<span id="cb14-2"><a aria-hidden="true" tabindex="-1"></a>y.bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>We compute <span class="math inline">\mathop{\mathrm{TSS}}</span> with the R command</li>
</ul>
<div class="sourceCode" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute TSS</span></span>
<span id="cb15-2"><a aria-hidden="true" tabindex="-1"></a>TSS <span class="ot">&lt;-</span> <span class="fu">sum</span>( ( y <span class="sc">-</span> y.bar) <span class="sc">^</span> <span class="dv">2</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="computing-predictions" class="slide level2 smaller">
<h2>Computing predictions</h2>
<ul>
<li>We have that</li>
</ul>
<p><span class="math display">
\mathop{\mathrm{RSS}}:= \sum_{i=1}^n (y_i - \hat y_i)^2
</span></p>
<ul>
<li>We need to compute the predictions</li>
</ul>
<p><span class="math display">
\hat y_i :=  \hat \beta_1 + \hat \beta_2 x_{i2} + \hat \beta_3 x_{i3}
</span></p>
</section>
<section id="computing-predictions-1" class="slide level2 smaller">
<h2>Computing predictions</h2>
<ul>
<li><span class="math inline">\hat y</span>, the design matrix <span class="math inline">Z</span>, and <span class="math inline">\hat \beta</span> are</li>
</ul>
<p><span class="math display">
\hat y =
\left(\begin{array}{c}
    \hat y_1 \\
    \ldots \\
    \hat y_i  \\
    \ldots  \\
    \hat y_n \\
\end{array}\right) \,, \qquad
Z =
\left(\begin{array}{cccc}
    1 &amp; x_{11} &amp; x_{12} \\
    \ldots &amp; \ldots &amp; \ldots \\
    1 &amp; x_{i1} &amp; x_{i2} \\
    \ldots &amp; \ldots &amp; \ldots \\
    1 &amp; x_{n1} &amp; x_{n2} \\
\end{array}\right) \,, \qquad
\hat \beta =
\left(\begin{array}{c}
    \hat \beta_1 \\
    \hat \beta_2  \\
    \hat \beta_3 \\
\end{array}\right)
</span></p>
<ul>
<li>Therefore, we can compute <span class="math display">
\hat y_i =  \hat \beta_1 + \hat \beta_2 x_{i2} + \hat \beta_3 x_{i3}
</span> with the product <span class="math display">
\hat y = Z \hat \beta
</span></li>
</ul>
</section>
<section id="computing-mathopmathrmrss" class="slide level2 smaller">
<h2>Computing <span class="math inline">\mathop{\mathrm{RSS}}</span></h2>
<ul>
<li><p>Recall that <span class="math inline">\hat \beta</span> is stored in <code>beta</code></p></li>
<li><p>Compute predictions <span class="math inline">\hat y = Z \hat{\beta}</span></p></li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute predictions y.hat</span></span>
<span id="cb16-2"><a aria-hidden="true" tabindex="-1"></a>y.hat <span class="ot">&lt;-</span> Z <span class="sc">%*%</span> beta</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><p>Recall that <span class="math display">
\mathop{\mathrm{RSS}}= \sum_{i=1}^n (y_i - \hat{y}_i)^2
</span></p></li>
<li><p>This is computed in R with</p></li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute RSS</span></span>
<span id="cb17-2"><a aria-hidden="true" tabindex="-1"></a>RSS <span class="ot">&lt;-</span> <span class="fu">sum</span>( (y <span class="sc">-</span> y.hat) <span class="sc">^</span> <span class="dv">2</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="computing-r2" class="slide level2 smaller">
<h2>Computing <span class="math inline">R^2</span></h2>
<ul>
<li>The coefficient <span class="math inline">R^2</span> is computed with</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute coefficient of determination R^2</span></span>
<span id="cb18-2"><a aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> RSS <span class="sc">/</span> TSS</span>
<span id="cb18-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print R^2</span></span>
<span id="cb18-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">The coefficient of determination R^2 is"</span>, R2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>The full code can be downloaded here <a href="codes/R2_multiple_regression.R">R2_multiple_regression.R</a></li>
</ul>
</section>
<section id="output-conclusions" class="slide level2 smaller">
<h2>Output &amp; Conclusions</h2>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
The estimator is -1271.75 -0.1033386 0.6594171</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
The coefficient of determination R^2 is 0.8655401</code></pre>
</div>
</div>
<p><br></p>
<p>The coefficient of determination <span class="math display">
R^2 = 0.8655401
</span> is quite close to <span class="math inline">1</span>, showing that:</p>
<ul>
<li>The model fits data quite well</li>
<li><em>Productivity Index</em> and <em>Year</em> affect <em>Unemployment</em></li>
<li><em>Unemployment</em> is almost completely explained by <em>Productivity Index</em> and <em>Year</em><br>
(Because <span class="math inline">R^2</span> is almost <span class="math inline">1</span>)</li>
</ul>
</section></section>
<section>
<section id="part-6-two-sample-t-test-as-general-regression" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 6: <br>Two sample t-test<br> as general regression</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="two-sample-t-test-as-general-regression" class="slide level2 smaller">
<h2>Two-sample t-test as general regression</h2>
<ul>
<li><p>Two-sample t-test is special case of general linear regression</p></li>
<li><p>This example is important for two reasons</p>
<ul>
<li>Shows that multiple linear regression encapsulates simple models like the two-sample t-test</li>
<li>Shows that general linear regression leads to intuitive solutions in simple examples</li>
</ul></li>
</ul>
</section>
<section id="two-sample-t-test-setting" class="slide level2 smaller">
<h2>Two-sample t-test setting</h2>
<ul>
<li><p>We have 2 populations <span class="math inline">A</span> and <span class="math inline">B</span> distributed like <span class="math inline">N(\mu_A, \sigma_A^2)</span> and <span class="math inline">N(\mu_B, \sigma_B^2)</span></p></li>
<li><p>We have two samples</p>
<ul>
<li>Sample of size <span class="math inline">n_A</span> from population <span class="math inline">A</span> <span class="math display">
a = (a_1, \ldots, a_{n_A})
</span></li>
<li>Sample of size <span class="math inline">n_B</span> from population <span class="math inline">B</span> <span class="math display">
b = (b_1, \ldots, b_{n_B})
</span></li>
</ul></li>
<li><p>Two-sample t-test compares means <span class="math inline">\mu_A</span> and <span class="math inline">\mu_B</span> by computing t-statistic <span class="math display">
t = \frac{ \overline{a} - \overline{b} }{\mathop{\mathrm{e.s.e.}}}
</span></p></li>
</ul>
</section>
<section id="setting-up-the-regression-analysis" class="slide level2 smaller">
<h2>Setting up the regression analysis</h2>
<ul>
<li><p>We want a regression model that can describe the sample means <span class="math inline">\overline{a}</span> and <span class="math inline">\overline{b}</span></p></li>
<li><p>It is sufficient to consider a general linear model with <span class="math inline">p = 2</span>, that is,</p></li>
</ul>
<p><span class="math display">
{\rm I\kern-.3em E}[Y | Z_1 = z_1 , Z_2 = z_2 ] = \beta_1 z_1 + \beta_2 z_2
</span></p>
<ul>
<li>Define the data vector <span class="math inline">y</span> by concatenating <span class="math inline">a</span> and <span class="math inline">b</span></li>
</ul>
<p><span class="math display">
y =
\left(\begin{array}{c}
     y_1   \\
     \ldots \\
     y_{n_A} \\
     y_{n_A + 1}\\
     \ldots \\
     y_{n_A + n_B}
\end{array}\right)
=
\left(\begin{array}{c}
     a_1   \\
     \ldots \\
     a_{n_A} \\
     b_{1}\\
     \ldots \\
     b_{n_B}
\end{array}\right)
</span></p>
</section>
<section id="setting-up-the-regression-analysis-1" class="slide level2 smaller">
<h2>Setting up the regression analysis</h2>
<ul>
<li>The variable <span class="math inline">Z_1</span> is modelled as</li>
</ul>
<p><span class="math display">
Z_1 = 1_{A}(i) :=
\begin{cases}
1 &amp; \text{ if i-th observation is from population A} \\
0 &amp; \text{ otherwise}
\end{cases}
</span></p>
<ul>
<li>Therefore, we have</li>
</ul>
<p><span class="math display">\begin{align*}
z_1 &amp; = (\underbrace{1_A(i) , \ldots, 1_A(i)}_{n_A + n_B} ) \\[15pts]
    &amp; = (\underbrace{1 , \ldots, 1}_{n_A},
         \underbrace{0 , \ldots, 0}_{n_B} )
\end{align*}</span></p>
</section>
<section id="setting-up-the-regression-analysis-2" class="slide level2 smaller">
<h2>Setting up the regression analysis</h2>
<ul>
<li>Similarly, the variable <span class="math inline">Z_2</span> is modelled as</li>
</ul>
<p><span class="math display">
Z_2 = 1_{B}(i) :=
\begin{cases}
1 &amp; \text{ if i-th observation is from population B} \\
0 &amp; \text{ otherwise}
\end{cases}
</span></p>
<ul>
<li>Therefore we have</li>
</ul>
<p><span class="math display">\begin{align*}
z_2 &amp; = (\underbrace{1_B(i), \ldots, 1_B (i)}_{n_A + n_B} ) \\[15pts]
    &amp; = (\underbrace{0 , \ldots, 0}_{n_A},
         \underbrace{1 , \ldots, 1}_{n_B} )
\end{align*}</span></p>
</section>
<section id="setting-up-the-regression-analysis-3" class="slide level2 smaller">
<h2>Setting up the regression analysis</h2>
<ul>
<li>The general regression model is</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 \, 1_{A}(i) + \beta_2 \, 1_{B}(i) + \varepsilon_i
</span></p>
<ul>
<li><p>Variables <span class="math inline">1_A</span> and <span class="math inline">1_B</span> are called <strong>dummy variables</strong> (more on this later)</p></li>
<li><p>The design matrix is therefore</p></li>
</ul>
<p><span class="math display">
Z = (1_A | 1_B) =
\left(\begin{array}{cc}
     1_A(i) &amp; 1_B (i)  \\
     \ldots &amp; \ldots\\
     1_A(i) &amp; 1_B (i) \\
\end{array}\right)  
=
\left(\begin{array}{cc}
     1 &amp; 0  \\
     \ldots &amp; \ldots\\
     1  &amp; 0\\
     0 &amp; 1 \\
     \ldots &amp; \ldots\\
     0 &amp; 1
\end{array}\right)
</span></p>
</section>
<section id="calculating-zt-y" class="slide level2 smaller">
<h2>Calculating <span class="math inline">Z^T y</span></h2>
<ul>
<li>We want to compute the regression estimator</li>
</ul>
<p><span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p>
<ul>
<li><span class="math inline">Z</span> has dimension <span class="math inline">(n_A + n_B) \times 2</span></li>
<li><span class="math inline">Z^T</span> has dimension <span class="math inline">2 \times (n_A + n_B)</span></li>
<li><span class="math inline">y</span> has dimension <span class="math inline">(n_A + n_B) \times 1</span></li>
<li><span class="math inline">Z^T y</span> therefore has dimension</li>
</ul>
<p><span class="math display">
[ 2 \times (n_A + n_B)] \times [ (n_A + n_B) \times 1 ]
= 2 \times 1
</span></p>
</section>
<section id="calculating-zt-y-1" class="slide level2 smaller">
<h2>Calculating <span class="math inline">Z^T y</span></h2>
<p><span class="math display">\begin{align*}
Z^T y &amp; =
\left(\begin{array}{cc}
     1 &amp; 0  \\
     \ldots &amp; \ldots\\
     1 &amp; 0\\
     0 &amp; 1\\
     \ldots &amp; \ldots\\
     0 &amp; 1
\end{array}\right)^T
\left(\begin{array}{c}
     y_1  \\
     \ldots\\
     y_{n_A}\\
     y_{n_A+1}\\
     \ldots\\
     y_{n_A+n_B}
\end{array}\right)
=
\left(\begin{array}{cccccc}
     1 &amp; \ldots &amp; 1 &amp; 0 &amp; \ldots &amp; 0  \\
     0 &amp; \ldots &amp; 0 &amp; 1 &amp; \ldots &amp; 1  \\
\end{array}\right)
\left(\begin{array}{c}
     y_1  \\
     \ldots\\
     y_{n_A}\\
     y_{n_A+1}\\
     \ldots\\
     y_{n_A+n_B}
\end{array}\right) \\[35pt]
&amp; =
\left(\begin{array}{c}
     y_1 \cdot 1 + \ldots + y_{n_A} \cdot 1 +
     y_{n_A + 1} \cdot 0 + \ldots + y_{n_A + n_B} \cdot 0 \\
     y_1 \cdot 0 + \ldots + y_{n_A} \cdot 0 +
     y_{n_A + 1} \cdot 1 + \ldots + y_{n_A + n_B} \cdot 1
\end{array}\right) \\[20pt]
&amp; =
\left(\begin{array}{c}
     y_1 + \ldots + y_{n_A} \\
     y_{n_A + 1} + \ldots + y_{n_A + n_B}
\end{array}\right)
=
\left(\begin{array}{c}
     a_1 + \ldots + a_{n_A} \\
     b_{1} + \ldots + b_{n_B}
\end{array}\right)
=
\left(\begin{array}{c}
     n_A \ \overline{a} \\
      n_B \ \overline{b}
\end{array}\right)
\end{align*}</span></p>
</section>
<section id="calculating-zt-z-2" class="slide level2 smaller">
<h2>Calculating <span class="math inline">Z^T Z</span></h2>
<ul>
<li><span class="math inline">Z</span> has dimension <span class="math inline">(n_A + n_B) \times 2</span></li>
<li><span class="math inline">Z^T</span> has dimension <span class="math inline">2 \times (n_A + n_B)</span></li>
<li><span class="math inline">Z^T Z</span> therefore has dimension</li>
</ul>
<p><span class="math display">
[ 2 \times (n_A + n_B)] \times [ (n_A + n_B) \times 2 ]
= 2 \times 2
</span></p>
</section>
<section id="calculating-zt-z-3" class="slide level2 smaller">
<h2>Calculating <span class="math inline">Z^T Z</span></h2>
<p><span class="math display">\begin{align*}
Z^T Z &amp; =
\left(\begin{array}{cc}
     1 &amp; 0  \\
     \ldots &amp; \ldots\\
     1 &amp; 0\\
     0 &amp; 1\\
     \ldots &amp; \ldots\\
     0 &amp; 1
\end{array}\right)^T
\left(\begin{array}{cc}
     1 &amp; 0  \\
     \ldots &amp; \ldots\\
     1 &amp; 0\\
     0 &amp; 1\\
     \ldots &amp; \ldots\\
     0 &amp; 1
\end{array}\right) \\[35pt]
&amp; =
\left(\begin{array}{cccccc}
     1 &amp; \ldots &amp; 1 &amp; 0 &amp; \ldots &amp; 0  \\
     0 &amp; \ldots &amp; 0 &amp; 1 &amp; \ldots &amp; 1  \\
\end{array}\right)
\left(\begin{array}{cc}
     1 &amp; 0  \\
     \ldots &amp; \ldots\\
     1 &amp; 0\\
     0 &amp; 1\\
     \ldots &amp; \ldots\\
     0 &amp; 1
\end{array}\right)
= \left(\begin{array}{cc}
   n_A  &amp; 0  \\
    0 &amp; n_B
\end{array}\right)
\end{align*}</span></p>
</section>
<section id="calculating-hat-beta" class="slide level2 smaller">
<h2>Calculating <span class="math inline">\hat \beta</span></h2>
<ul>
<li>As <span class="math inline">Z^T Z</span> is diagonal, the inverse is</li>
</ul>
<p><span class="math display">
(Z^T Z)^{-1} =
\left(\begin{array}{cc}
   n_A  &amp; 0  \\
    0  &amp; n_B
\end{array}\right)^{-1}
=\left(\begin{array}{cc}
    \frac{1}{n_A} &amp; 0 \\
    0 &amp; \frac{1}{n_B}
\end{array}\right)
</span></p>
<ul>
<li>The MLE is therefore</li>
</ul>
<p><span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^Ty =
\left(\begin{array}{cc}
    \frac{1}{n_A} &amp; 0 \\
    0 &amp; \frac{1}{n_B}
\end{array}\right)
\left(\begin{array}{c}
     n_A \ \overline{a}  \\
      n_B \ \overline{b}
\end{array}\right)
=
\left(\begin{array}{c}
     \overline{a}  \\
     \overline{b}
\end{array}\right)
</span></p>
</section>
<section id="conclusions" class="slide level2 smaller">
<h2>Conclusions</h2>
<ul>
<li>The MLE is</li>
</ul>
<p><span class="math display">
\hat \beta =
\left(\begin{array}{c}
     \overline{a}  \\
     \overline{b}
\end{array}\right)
</span></p>
<ul>
<li>The regression function is hence</li>
</ul>
<p><span class="math display">\begin{align*}
{\rm I\kern-.3em E}[Y | 1_A = z_1 , 1_B = z_2] &amp; = \hat\beta_1 \ z_1 + \hat\beta_2 \ z_2 \\[20pt]
&amp; = \overline{a} \ z_1 + \overline{b} \ z_2
\end{align*}</span></p>
</section>
<section id="conclusions-1" class="slide level2 smaller">
<h2>Conclusions</h2>
<ul>
<li>This is a very intuitive result:
<ul>
<li>The expected value for <span class="math inline">Y</span> when data is observed from population <span class="math inline">A</span> is <span class="math display">
{\rm I\kern-.3em E}[Y | 1_A = 1 , 1_B = 0] = \overline{a}
</span></li>
<li>The expected value for <span class="math inline">Y</span> when data is observed from population <span class="math inline">B</span> is <span class="math display">
{\rm I\kern-.3em E}[Y | 1_A = 0 , 1_B = 1] = \overline{b}
</span></li>
</ul></li>
<li>Therefore, under this simple model
<ul>
<li>The best estimate for population A is the sample mean <span class="math inline">\overline{a}</span></li>
<li>The best estimate for population B is the sample mean <span class="math inline">\overline{b}</span></li>
</ul></li>
</ul>

<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p><a href="../index.html">Homepage</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="../license.html">License</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.silviofanzon.com/contact">Contact</a></p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>