<!DOCTYPE html>
<html lang="en"><head>
<link href="../favicon.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-contrib/foldbox/foldbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Dr.&nbsp;Silvio Fanzon">
  <title>Statistical Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <style>
  .Problem {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Important {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Axiom {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Proof {
    --color1: #f1f1f2;
    --color2: #c0c0c1;
  }
  .TODO {
    --color1: #e7b1b4;
    --color2: #8c3236;
  }
  .DONE {
    --color1: #cce7b1;
    --color2: #86b754;
  }
  .Definition {
    --color1: #c6e6ed;
    --color2: #1995ad;
  }
  .Corollary {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Warning {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Notation {
    --color1: #c6e6ed;
    --color2: #1995ad;
  }
  .Conjecture {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Remark {
    --color1: #bce5de;
    --color2: #21aa93;
  }
  .Example {
    --color1: #bce5de;
    --color2: #21aa93;
  }
  .Lemma {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Proposition {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Idea {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Question {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  .Theorem {
    --color1: #f4cce0;
    --color2: #db4d92;
  }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Statistical Models</h1>
  <p class="subtitle">Lecture 10</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<a href="https://www.silviofanzon.com">Dr.&nbsp;Silvio Fanzon</a> 
</div>
<div class="quarto-title-author-email">
<a href="mailto:S.Fanzon@hull.ac.uk">S.Fanzon@hull.ac.uk</a>
</div>
        <p class="quarto-title-affiliation">
            University of Hull
          </p>
    </div>
</div>

</section>
<section>
<section id="lecture-10-model-selection-regression-assumptions" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Lecture 10: <br> Model Selection &amp; <br> Regression Assumptions</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="outline-of-lecture-10" class="slide level2 smaller">
<h2>Outline of Lecture 10</h2>
<ol type="1">
<li><p>Model Selection</p></li>
<li><p>Examples of Model Selection</p></li>
<li><p>Regression Assumptions</p></li>
<li><p>Heteroscedasticity</p></li>
<li><p>Autocorrelation</p></li>
</ol>
</section></section>
<section>
<section id="part-1-model-selection" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 1: <br> Model Selection <br></h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="testing-regression-parameters" class="slide level2 smaller">
<h2>Testing regression parameters</h2>
<p><strong>Summary:</strong> In Lecture 10 we have studied t-test and F-test for regression parameters:</p>
<ol type="1">
<li><strong>t-test:</strong> Consider the <em>general linear regression model</em></li>
</ol>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \ldots + \beta_{ip} z_{ip} + \varepsilon_i \,, \qquad
\varepsilon_i \, \text{ iid } \, N(0, \sigma^2)
</span></p>
<ul>
<li>We have that</li>
</ul>
<p><span class="math display">
Z_j \,\, \text{ affects } \,\, Y \qquad \iff \qquad
\beta_j \neq 0
</span></p>
<ul>
<li>To see if <span class="math inline">Z_j</span> affects <span class="math inline">Y</span>, we introduced <strong>t-test</strong> for the hypothesis</li>
</ul>
<p><span class="math display">\begin{align*}
H_0 \colon  &amp; \beta_j = 0 \\
H_1 \colon &amp; \beta_j \neq 0
\end{align*}</span></p>
</section>
<section id="testing-regression-parameters-1" class="slide level2 smaller">
<h2>Testing regression parameters</h2>
<ol start="2" type="1">
<li><strong>F-test:</strong> We considered two <strong>nested</strong> multiple regression models <span class="math display">\begin{align*}
\textbf{Model 1:} &amp; \qquad Y_ i= \beta_1 + \varepsilon_i \\[10pt]
\textbf{Model 2:} &amp; \qquad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_p x_{ip} + \varepsilon_i
\end{align*}</span></li>
</ol>
<ul>
<li>We tested the <strong>Overall Significance</strong> of the parameters <span class="math inline">\beta_2 , \ldots, \beta_p</span>
<ul>
<li>This means choosing which model makes better predictions</li>
</ul></li>
<li>The comparison is achieved with <strong>F-test</strong> for the hypothesis</li>
</ul>
<p><span class="math display">\begin{align*}
H_0 &amp; \colon \, \beta_2 = \beta_3 = \ldots = \beta_p = 0 \\
H_1 &amp; \colon \text{ At least one of the } \beta_i \text{ is non-zero}
\end{align*}</span></p>
</section>
<section id="more-general-nested-models" class="slide level2 smaller">
<h2>More general nested models</h2>
<p>Consider the more general <strong>nested</strong> multiple regression models</p>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<ul>
<li><p>Model 1 has k parameters</p></li>
<li><p>Model 2 has p parameters, with <span class="math inline">p &gt; k</span></p></li>
<li><p>The two models coincide if and only if all the extra parameters are zero</p></li>
</ul>
<p><span class="math display">
\beta_{k + 1} = \beta_{k + 2} = \ldots = \beta_p = 0
</span></p>
</section>
<section id="model-selection" class="slide level2 smaller">
<h2>Model Selection</h2>
<p>Consider the more general <strong>nested</strong> multiple regression models</p>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<p><strong>Question:</strong> How do we decide which model is better?</p>
<p><strong>Answer:</strong> Test hypothesis for <em>Model Selection</em></p>
<p><span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{k+1}, \ldots, \beta_p \text{ is non-zero}
\end{align*}</span></p>
<ul>
<li><span class="math inline">H_0</span> is in favor of Model 1 <span class="math inline">\qquad \quad H_1</span> is in favor of Model 2</li>
</ul>
</section>
<section id="comparing-the-two-models" class="slide level2 smaller">
<h2>Comparing the two Models</h2>
<p>Consider the more general <strong>nested</strong> multiple regression models</p>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<p><strong>Goal:</strong> Formulate a statistic to decide between the 2 Models</p>
<ul>
<li><p>First, calculate ML Estimators <span class="math inline">\hat{\beta}^1</span> and <span class="math inline">\hat{\beta}^2</span> for Models 1 and 2, respectively</p></li>
<li><p>With the MLEs, define the predictions for the two models</p></li>
</ul>
<p><span class="math display">\begin{align*}
\hat y_i^1 &amp; := \hat{\beta}_1^{1} + \hat{\beta}_2^1 x_{i2}+ \ldots + \hat{\beta}_{k}^1 x_{ik} \\[10pt]
\hat y_i^2 &amp; :=  \hat{\beta}_1^2 + \hat{\beta}_2^2 x_{i2}+ \ldots + \hat{\beta}_{k}^2 x_{ik} + \hat{\beta}_{k + 1}^2 x_{i(k + 1)} +
    \ldots + \hat{\beta}_{p}^2 x_{ip}
\end{align*}</span></p>
</section>
<section id="comparing-the-two-models-1" class="slide level2 smaller">
<h2>Comparing the two Models</h2>
<p>Consider the more general <strong>nested</strong> multiple regression models</p>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<ul>
<li><p>Recall: The <span class="math inline">\mathop{\mathrm{RSS}}</span> measures variation between data and prediction</p></li>
<li><p>Compute the <span class="math inline">\mathop{\mathrm{RSS}}</span> for both models</p></li>
</ul>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad \mathop{\mathrm{RSS}}_1 := \mathop{\mathrm{RSS}}(k) = \sum_{i=1}^n (y_i - \hat y_i^1)^2 \\[10pt]
    \textbf{Model 2:} &amp; \quad \mathop{\mathrm{RSS}}_2 := \mathop{\mathrm{RSS}}(p) = \sum_{i=1}^n (y_i - \hat y_i^2)^2
\end{align*}</span></p>
</section>
<section id="extra-sum-of-squares" class="slide level2 smaller">
<h2>Extra sum of squares</h2>
<div id="Definition*-2.1" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The <strong>extra sum of squares</strong> is the difference<p></p>
<p><span class="math display">
\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 := \mathop{\mathrm{RSS}}(k) - \mathop{\mathrm{RSS}}(p)
</span></p>
</div></details>
</div>
<p><strong>Recall:</strong> <span class="math inline">\mathop{\mathrm{RSS}}</span> cannot increase if we increase the number of parameteres <span class="math display">
k &lt; p \quad \implies \quad \mathop{\mathrm{RSS}}(k) \geq \mathop{\mathrm{RSS}}(p)
</span> (this is because <span class="math inline">\mathop{\mathrm{RSS}}</span> is defined via minimization, as already remarked in Lecture 10)</p>
<p><strong>Remark:</strong> In particular, we deduce that the <em>Extra Sum of Squares</em> is non-negative <span class="math display">
\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 \geq 0
</span></p>
</section>
<section id="deciding-between-the-two-models" class="slide level2 smaller">
<h2>Deciding between the two models</h2>
<div style="font-size: 0.95em">
<p>The hypothesis for deciding between the two model is <span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{k+1}, \ldots, \beta_p \text{ is non-zero}
\end{align*}</span></p>
<ul>
<li><p>Suppose the null hypothesis <span class="math inline">H_0</span> holds</p></li>
<li><p>In this case, the two Models are the same</p></li>
<li><p>Therefore, predictions will be similar</p></li>
<li><p>Hence, the <span class="math inline">\mathop{\mathrm{RSS}}</span> for the 2 models are similar</p></li>
</ul>
<p><span class="math display">
\mathop{\mathrm{RSS}}_1 \, \approx \, \mathop{\mathrm{RSS}}_2
</span></p>
</div>
</section>
<section id="deciding-between-the-two-models-1" class="slide level2 smaller">
<h2>Deciding between the two models</h2>
<div style="font-size: 0.95em">
<p>The hypothesis for deciding between the two model is <span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{k+1}, \ldots, \beta_p \text{ is non-zero}
\end{align*}</span></p>
<ul>
<li><p>Suppose instead that the alternative hypothesis <span class="math inline">H_1</span> holds</p></li>
<li><p>As already noted, in general it holds that <span class="math display">
\mathop{\mathrm{RSS}}_1 \geq \mathop{\mathrm{RSS}}_2
</span></p></li>
<li><p>From <span class="math inline">H_1</span>, we know that some of the extra parameters <span class="math inline">\beta_{k+1} , \ldots, \beta_p</span> are non-zero</p></li>
<li><p>Thus, Model 2 will give better predictions <span class="math inline">\implies \mathop{\mathrm{RSS}}_2</span> is <strong>much smaller</strong> <span class="math display">
\mathop{\mathrm{RSS}}_1 \gg \mathop{\mathrm{RSS}}_2
</span></p></li>
</ul>
</div>
</section>
<section id="conclusion-2-cases" class="slide level2 smaller">
<h2>Conclusion: 2 cases</h2>
<div style="font-size: 0.95em">
<ol type="1">
<li>Choose Model 1:</li>
</ol>
<p><span class="math display">\begin{align*}
H_0 \,\, \text{ holds } &amp; \, \iff \,  \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[15pt]
&amp; \, \iff \, \mathop{\mathrm{RSS}}_1 \approx \mathop{\mathrm{RSS}}_2 \, \iff \, \frac{\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2}{\mathop{\mathrm{RSS}}_2} \approx 0
\end{align*}</span></p>
<ol start="2" type="1">
<li>Choose Model 2:</li>
</ol>
<p><span class="math display">\begin{align*}
H_1 \,\, \text{ holds } &amp; \, \iff \, \exists \,\, i \in \{ k+1, \ldots, p\} \, \text{ s.t.  } \, \beta_i \neq 0 \\[15pt]
&amp; \, \iff \, \mathop{\mathrm{RSS}}_1 \gg \mathop{\mathrm{RSS}}_2 \, \iff \, \frac{\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2}{\mathop{\mathrm{RSS}}_2} \gg 0
\end{align*}</span></p>
</div>
</section>
<section id="construction-of-f-statistic" class="slide level2 smaller">
<h2>Construction of F-statistic</h2>
<div style="font-size: 0.95em">
<ul>
<li>Thus, the quantity below can be used as statistic to decide between the 2 models</li>
</ul>
<p><span class="math display">
\frac{\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2}{\mathop{\mathrm{RSS}}_2}
</span></p>
<ul>
<li><p>However, in order to obtain a known distribution, we need to rescale</p></li>
<li><p>To this end, note that the degrees of freedom are:</p>
<ul>
<li>Model 1: <span class="math display">
  k \text{ parameters } \quad \implies \quad \mathop{\mathrm{df}}_1 =  n - k
  </span></li>
<li>Model 2: <span class="math display">
  p \text{ parameters } \quad \implies \quad \mathop{\mathrm{df}}_2 = n - p
  </span></li>
</ul></li>
</ul>
</div>
</section>
<section id="f-statistic-for-model-selection" class="slide level2 smaller">
<h2>F-statistic for Model Selection</h2>
<div id="Definition*-2.2" class="Definition">
<p></p><details class="Definition fbx-simplebox fbx-default" open=""><summary><strong>Definition</strong></summary><div>The F-statistic for Model Selection is<p></p>
<p><span class="math display">\begin{align*}
F &amp; = \frac{ \mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_2  }  \\[20pt]
&amp; = \frac{ \mathop{\mathrm{RSS}}(k) - \mathop{\mathrm{RSS}}(p) }{ p - k  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}(p) }{ n - p  }  
\end{align*}</span></p>
</div></details>
</div>
<p><strong>Theorem:</strong> The F-statistic for Model Selection has F-distribution</p>
<p><span class="math display">
F \, \sim  \, F_{\mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2 , \, \mathop{\mathrm{df}}_2} = F_{p - k, \, n - p}
</span></p>
</section>
<section id="rewriting-the-f-statistic" class="slide level2 smaller">
<h2>Rewriting the F-statistic</h2>
<p>Denote by <span class="math inline">R^2_1</span> and <span class="math inline">R^2_2</span> the coefficients of determination of the 2 models</p>
<div id="Proposition*-2.3" class="Proposition">
<p></p><details class="Proposition fbx-simplebox fbx-default" open=""><summary><strong>Proposition</strong></summary><div>The F-statistic for Model Selection can be rewritten as<p></p>
<p><span class="math display">\begin{align*}
F &amp; = \frac{ \mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_2 }   \\[20pt]
  &amp; = \frac{ R^2_2 - R^2_1 }{1 - R^2_2}  \, \cdot \,  \frac{n-p}{p-k}
\end{align*}</span></p>
</div></details>
</div>
</section>
<section id="proof-of-proposition" class="slide level2 smaller">
<h2>Proof of Proposition</h2>
<ul>
<li>Recall the definition of coefficient of determination for the two models</li>
</ul>
<p><span class="math display">
R_1^2 := R^2 (k) := 1 - \frac{ \mathop{\mathrm{RSS}}(k) }{ \mathop{\mathrm{TSS}}}
\, , \qquad \quad
R_2^2 := R^2 (p) := 1 - \frac{ \mathop{\mathrm{RSS}}(p) }{ \mathop{\mathrm{TSS}}}
</span></p>
<ul>
<li><p><strong>Note:</strong> <span class="math inline">\mathop{\mathrm{TSS}}</span> does not depend on numeber of parameters</p></li>
<li><p>From the above, we get</p></li>
</ul>
<p><span class="math display">
\mathop{\mathrm{RSS}}(k) = (1 - R_1^2) \mathop{\mathrm{TSS}}
\, , \qquad \quad
\mathop{\mathrm{RSS}}(p) = (1 - R_2^2) \mathop{\mathrm{TSS}}
</span></p>
<ul>
<li>In particular, we obtain</li>
</ul>
<p><span class="math display">\begin{align*}
\mathop{\mathrm{RSS}}(k) - \mathop{\mathrm{RSS}}(p) = ( R^2_2 - R^2_1 )  \mathop{\mathrm{TSS}}
\end{align*}</span></p>
</section>
<section id="section" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Therefore, the F-statistic can be rewritten as</li>
</ul>
<p><span class="math display">\begin{align*}
F &amp; = \frac{ \mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_2 }   \\[20pt]
  &amp; = \frac{ \mathop{\mathrm{RSS}}(k) - \mathop{\mathrm{RSS}}(p) }{\mathop{\mathrm{RSS}}(p)}  \, \cdot \,  \frac{n-p}{p-k} \\[20pt]
  &amp; = \frac{ (R^2_2 - R^2_1) \mathop{\mathrm{TSS}}}{ (1 - R^2_2) \mathop{\mathrm{TSS}}} \, \cdot \,  \frac{n-p}{p-k} \\[20pt]
  &amp; = \frac{ R^2_2 - R^2_1 }{1 - R^2_2}  \, \cdot \,  \frac{n-p}{p-k}
\end{align*}</span></p>
<ul>
<li>The proof is concluded</li>
</ul>
</section>
<section id="test-for-model-selection" class="slide level2 smaller">
<h2>Test for Model Selection</h2>
<ul>
<li><strong>Recall:</strong> We want to decide between the 2 models</li>
</ul>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<ul>
<li>To make a decision, we have formulated the hypothesis</li>
</ul>
<p><span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{k+1}, \ldots, \beta_p \text{ is non-zero}
\end{align*}</span></p>
<ul>
<li><span class="math inline">H_0</span> is in favor of Model 1 <span class="math inline">\qquad \quad H_1</span> is in favor of Model 2</li>
</ul>
</section>
<section id="section-1" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<p>We use the F-statistic to decide between the two models <span class="math display">
F = \frac{ \mathop{\mathrm{RSS}}(k) - \mathop{\mathrm{RSS}}(p) }{ p - k  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}(p) }{ n - p  }
</span></p>
<ol type="1">
<li><p>Choose Model 1: <span class="math display">\begin{align*}
H_0 \,\, \text{ holds }  &amp; \, \iff \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0  \\[10pt]
  &amp; \, \iff \, \mathop{\mathrm{RSS}}(k) \approx \mathop{\mathrm{RSS}}(p) \, \iff \, F \approx 0
\end{align*}</span></p></li>
<li><p>Choose Model 2: <span class="math display">\begin{align*}
H_1 \,\, \text{ holds } &amp; \, \iff \,\exists \,\, i \in \{ k+1, \ldots, p\} \, \text{ s.t.  } \, \beta_i \neq 0  \\[10pt]
  &amp;  \, \iff \, \mathop{\mathrm{RSS}}(k) \gg \mathop{\mathrm{RSS}}(p) \, \iff \, F \gg 0
\end{align*}</span></p></li>
</ol>
<ul>
<li><strong>Therefore, the test is one-sided: <span class="math inline">\,\,</span> Reject <span class="math inline">H_0 \iff F \gg 0</span></strong></li>
</ul>
</div>
</section>
<section id="the-f-test-for-model-selection" class="slide level2 smaller">
<h2>The F-test for Model Selection</h2>
<p><strong>Assumption:</strong> Given data points <span class="math inline">(x_{i2},\ldots , x_{ip},  y_i)</span>, consider the nested models</p>
<p><span class="math display">\begin{align*}
    \textbf{Model 1:} &amp; \quad Y_ i =\beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \varepsilon_i \\[10pt]
    \textbf{Model 2:} &amp; \quad Y_ i= \beta_1 + \beta_2 x_{i2}+ \ldots + \beta_{k} x_{ik} + \beta_{k + 1} x_{i(k + 1)} +
    \ldots + \beta_{p} x_{ip} + \varepsilon_i
\end{align*}</span></p>
<p><strong>Hypothesis:</strong> To decide which model gives better predictions</p>
<p><span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{k+1} = \beta_{k+2} = \ldots  = \beta_p = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{k+1}, \ldots, \beta_p \text{ is non-zero}
\end{align*}</span></p>
<ul>
<li><span class="math inline">H_0</span> is in favor of Model 1 <span class="math inline">\qquad \quad H_1</span> is in favor of Model 2</li>
</ul>
</section>
<section id="procedure-3-steps" class="slide level2 smaller">
<h2>Procedure: 3 Steps</h2>
<ol type="1">
<li><strong>Calculation</strong>: Compute MLEs <span class="math inline">\hat{\beta}^1, \hat{\beta}^2</span> and predictions <span class="math inline">\hat{y}_i^2, \hat{y}_i^2</span> for the 2 models <span class="math display">
\hat{\beta}^i = (Z_i^TZ_i)^{-1} Z_i^T y \,, \qquad \hat{y}^i = Z_i \hat{\beta}^i \,, \qquad Z_i = \text{design matrix for Model } i
</span> Compute the <span class="math inline">\mathop{\mathrm{TSS}}</span>. Compute <span class="math inline">\mathop{\mathrm{RSS}}</span> and <span class="math inline">R^2</span> coefficient for both models <span class="math display">
\mathop{\mathrm{TSS}}= \sum_{i=1}^n (y_i - \overline{y})^2\,, \qquad
\mathop{\mathrm{RSS}}_j = \sum_{i=1}^n (y_i - \hat{y}_i^j)^2 \,, \qquad
R^2_j = 1 - \frac{\mathop{\mathrm{RSS}}_j}{\mathop{\mathrm{TSS}}}
</span> Finally, compute the F-statistic for <em>Model Selection</em> <span class="math display">
F = \frac{R^2_2 - R_1^2}{1 - R^2_2} \, \cdot \, \frac{n - p}{p - k} \ \sim \ F_{p-k, n - p}
</span></li>
</ol>
</section>
<section id="section-2" class="slide level2 smaller">
<h2></h2>
<ol start="2" type="1">
<li><strong>Statistical Tables or R</strong>: Find either
<ul>
<li>Critical value <span class="math inline">F^*</span> in <a href="files/Statistics_Tables.pdf">Table 3</a></li>
<li>p-value in R</li>
</ul></li>
</ol>
<p><br></p>
<ol start="3" type="1">
<li><strong>Interpretation</strong>: Reject <span class="math inline">H_0</span> when either <span class="math display">
p &lt; 0.05 \qquad \text{ or } \qquad F \in \,\,\text{Rejection Region}
</span></li>
</ol>
<table class="caption-top">
<colgroup>
<col style="width: 35%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Alternative</th>
<th>Rejection Region</th>
<th><span class="math inline">F^*</span></th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\exists \,\, i \in \{ k+1, \ldots, p\}</span> s.t. <span class="math inline">\beta_i \neq 0</span></td>
<td><span class="math inline">F &gt; F^*</span></td>
<td><span class="math inline">F_{p-k,n-p}(0.05)</span></td>
<td><span class="math inline">P(F_{p-k,n-p} &gt; F)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="the-f-test-for-model-selection-in-r" class="slide level2 smaller">
<h2>The F-test for Model Selection in R</h2>
<ol type="1">
<li>Fit the two models with <code>lm</code></li>
<li>Compare the models with the command <span class="math inline">\, \texttt{anova} \qquad\quad</span> (more on this later)</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a aria-hidden="true" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> ... <span class="sc">+</span> xk)</span>
<span id="cb1-2"><a aria-hidden="true" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> ... <span class="sc">+</span> xk <span class="sc">+</span> <span class="fu">x</span>(k<span class="sc">+</span><span class="dv">1</span>) <span class="sc">+</span> ... <span class="sc">+</span> xp)</span>
<span id="cb1-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.1</span>, model<span class="fl">.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Alternative:</strong></p>
<ul>
<li>Find <span class="math inline">R^2_1</span> and <span class="math inline">R^2_2</span> in each Summary</li>
<li>Compute F-statistic and p-value by hand, using formulas</li>
</ul>
<p><span class="math display">
F = \frac{R^2_2 - R_1^2}{1 - R^2_2} \, \cdot \, \frac{n - p}{p - k} \,, \qquad p = P(F_{p-k,n-p} &gt; F)
</span></p>
</section>
<section id="f-test-for-overall-significance-revisited" class="slide level2 smaller">
<h2>F-test for Overall Significance revisited</h2>
<ul>
<li><p>The F-test for Overall Significance allows to select between models <span class="math display">\begin{align*}
  \textbf{Model 1:} &amp; \qquad Y_ i= \beta_1 + \varepsilon_i \\[10pt]
  \textbf{Model 2:} &amp; \qquad Y_ i= \beta_1 + \beta_2 x_{2, i}+ \ldots + \beta_p x_{p, i} + \varepsilon_i
\end{align*}</span></p></li>
<li><p>Model 1 has <span class="math inline">k = 1</span> parameters</p></li>
<li><p>F-statistic for <em>Model Selection</em> coincides with F-statistic for <em>Overall Significance</em></p></li>
</ul>
<p><span class="math display">
F = \frac{ \mathop{\mathrm{RSS}}(1) - \mathop{\mathrm{RSS}}(p) }{ p - 1  } \bigg/
      \frac{ \mathop{\mathrm{RSS}}(p) }{ n - p  }
</span></p>
<p><strong>Model Selection and Overall Significance tests coincide in this case</strong></p>
</section></section>
<section>
<section id="part-2-examples-of-model-selection" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 2: <br>Examples of <br> Model Selection</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="examples-of-model-selection" class="slide level2 smaller">
<h2>Examples of Model Selection</h2>
<p>We illustrate F-test for Model Selection with 3 examples:</p>
<ul>
<li>Joint significance in Multiple linear Regression</li>
<li>Polynomial regression (Two Examples)</li>
</ul>
</section>
<section id="example-1-multiple-linear-regression" class="slide level2 smaller">
<h2>Example 1: Multiple linear regression</h2>
<h3 id="consider-again-the-longley-dataset">Consider again the Longley dataset</h3>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>     GNP.deflator     GNP Unemployed Armed.Forces Population Year Employed
1947         83.0 234.289      235.6        159.0    107.608 1947   60.323
1948         88.5 259.426      232.5        145.6    108.632 1948   61.122
1949         88.2 258.054      368.2        161.6    109.773 1949   60.171</code></pre>
</div>
</div>
<div style="font-size: 0.30em">
<p><br></p>
</div>
<p><strong>Goal:</strong> Explain the number of <em>Employed</em> people <span class="math inline">Y</span> in the US in terms of</p>
<ul>
<li><span class="math inline">X_2</span> <em>GNP deflator</em> to adjust GNP for inflation</li>
<li><span class="math inline">X_3</span> <em>GNP</em> Gross National Product</li>
<li><span class="math inline">X_4</span> number of <em>Unemployed</em></li>
<li><span class="math inline">X_5</span> number of people in the <em>Armed Forces</em></li>
<li><span class="math inline">X_6</span> <em>non-institutionalised Population</em> <span class="math inline">\geq</span> age 14 (not in care of insitutions)</li>
<li><span class="math inline">X_7</span> <em>Years</em> from 1947 to 1962</li>
</ul>
</section>
<section id="section-3" class="slide level2 smaller">
<h2></h2>
<p><strong>Previous Analysis:</strong> Using t-test for parameters significance, we showed that</p>
<ul>
<li><span class="math inline">X_2, X_3</span> and <span class="math inline">X_6</span> do not affect <span class="math inline">Y</span></li>
<li><span class="math inline">X_4</span> and <span class="math inline">X_5</span> negatively affect <span class="math inline">Y</span></li>
<li><span class="math inline">X_7</span> positively affects <span class="math inline">Y</span></li>
</ul>
<p><strong>Question:</strong> Since <span class="math inline">X_2, X_3, X_6</span> do not affect <span class="math inline">Y</span>, can we exclude them from the model?</p>
<p><strong>Answer:</strong> Use the F-test for Model Selection on the 2 nested models</p>
<ul>
<li><p><strong>Model 1:</strong> The Reduced Model without <span class="math inline">X_2, X_3, X_6</span> <span class="math display">
Y = \beta_1 +  \beta_4 X_4 +  \beta_5 X_5 +
     \beta_7 X_7 + \varepsilon
</span></p></li>
<li><p><strong>Model 2:</strong> The Full Model <span class="math display">
Y = \beta_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4 +
     \beta_5 X_5 +  \beta_6 X_6 +  \beta_7 X_7 + \varepsilon
</span></p></li>
</ul>
</section>
<section id="r-commands-for-reading-in-the-data" class="slide level2 smaller">
<h2>R commands for reading in the data</h2>
<ul>
<li><p>We read the data in the same way we did last time</p></li>
<li><p>Longley dataset available here <a href="datasets/longley.txt">longley.txt</a></p></li>
<li><p>Download the file and place it in current working directory</p></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Read data file</span></span>
<span id="cb3-2"><a aria-hidden="true" tabindex="-1"></a>longley <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">file =</span> <span class="st">"longley.txt"</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Store columns in vectors</span></span>
<span id="cb3-5"><a aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> longley[ , <span class="dv">1</span>]        <span class="co"># GNP Deflator</span></span>
<span id="cb3-6"><a aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> longley[ , <span class="dv">2</span>]        <span class="co"># GNP</span></span>
<span id="cb3-7"><a aria-hidden="true" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> longley[ , <span class="dv">3</span>]        <span class="co"># Unemployed</span></span>
<span id="cb3-8"><a aria-hidden="true" tabindex="-1"></a>x5 <span class="ot">&lt;-</span> longley[ , <span class="dv">4</span>]        <span class="co"># Armed Forces</span></span>
<span id="cb3-9"><a aria-hidden="true" tabindex="-1"></a>x6 <span class="ot">&lt;-</span> longley[ , <span class="dv">5</span>]        <span class="co"># Population</span></span>
<span id="cb3-10"><a aria-hidden="true" tabindex="-1"></a>x7 <span class="ot">&lt;-</span> longley[ , <span class="dv">6</span>]        <span class="co"># Year</span></span>
<span id="cb3-11"><a aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> longley[ , <span class="dv">7</span>]         <span class="co"># Employed</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="r-commands-for-f-test-of-model-selection" class="slide level2 smaller">
<h2>R commands for F-test of Model Selection</h2>
<ol type="1">
<li>Fit the two multiple regression models</li>
</ol>
<p><span class="math display">\begin{align*}
\textbf{Model 1:} &amp; \quad Y = \beta_1 + \beta_4 X_4 + \beta_5 X_5 +
       \beta_7 X_7 + \varepsilon\\[10pt]
\textbf{Model 2:} &amp; \quad Y = \beta_1 + \beta_2 X_2 + \beta_3 X_3 + \beta_4 X_4 +
       \beta_5 X_5 +  \beta_6 X_6 +  \beta_7 X_7 + \varepsilon
\end{align*}</span></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Model 1 and Model 2</span></span>
<span id="cb4-2"><a aria-hidden="true" tabindex="-1"></a>model<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x4 <span class="sc">+</span> x5 <span class="sc">+</span> x7)</span>
<span id="cb4-3"><a aria-hidden="true" tabindex="-1"></a>model<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x2 <span class="sc">+</span> x3 <span class="sc">+</span> x4 <span class="sc">+</span> x5 <span class="sc">+</span> x6 <span class="sc">+</span> x7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="2" type="1">
<li>F-test for Model Selection is done using the command <span class="math inline">\, \texttt{anova}</span></li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># F-test for Model Selection</span></span>
<span id="cb5-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(model<span class="fl">.1</span>, model<span class="fl">.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Full code can be downloaded here <a href="codes/longley_selection.R">longley_selection.R</a></li>
</ul>
</section>
<section id="section-4" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><p>First two lines say that the following 2 models are being compared <span class="math display">\begin{align*}
  \textbf{Model 1:} &amp; \quad Y = \beta_1 + \beta_4 x_{4} + \beta_5 x_{5} + \beta_7 x_{7}  + \varepsilon\\[10pt]
  \textbf{Model 2:} &amp;\quad Y =\beta_1 + \beta_2 x_{2}+ \beta_3 x_{3} + \beta_4 x_{4} + \beta_5 x_{5} + \beta_{6} x_{6} + \beta_7 x_{7}  + \varepsilon
\end{align*}</span></p></li>
<li><p>The null hypothesis favors Model 1; The alternative favors Model 2 <span class="math display">\begin{align*}
H_0 \colon &amp; \, \beta_{2} = \beta_{3} = \beta_6 = 0 \\[5pt]
H_1 \colon &amp; \, \text{ At least one among } \beta_{2}, \beta_{3}, \beta_6  \text{ is non-zero}
\end{align*}</span></p></li>
</ul>
</div>
</section>
<section id="section-5" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><span class="math inline">\texttt{Res.Df} \,</span> are the degrees of freedom of each model
<ul>
<li>The sample size of longley is 16</li>
<li>Model 1 has <span class="math inline">k=4</span> parameters</li>
<li>Model 2 has <span class="math inline">p=7</span> parameters</li>
<li><span class="math inline">\mathop{\mathrm{df}}_1 = n - k = 16 - 4 = 12   \quad \qquad \mathop{\mathrm{df}}_2 = n - p = 16 - 7 = 9</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="section-6" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><span class="math inline">\texttt{Df} \,</span> is difference in degrees of freedom
<ul>
<li><span class="math inline">\mathop{\mathrm{df}}_1 = 12</span></li>
<li><span class="math inline">\mathop{\mathrm{df}}_2 = 9</span></li>
<li>Therefore the difference is <span class="math display">
  \mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2 = 12 - 9 = 3
  </span></li>
</ul></li>
</ul>
</div>
</section>
<section id="section-7" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><span class="math inline">\texttt{RSS} \,</span> is the residual sum of squares for each model
<ul>
<li><span class="math inline">\mathop{\mathrm{RSS}}_1 = 1.32336</span></li>
<li><span class="math inline">\mathop{\mathrm{RSS}}_2 = 0.83642</span></li>
</ul></li>
<li><span class="math inline">\texttt{Sum of Sq} \,</span> is the <em>Extra Sum of Squares</em>
<ul>
<li><span class="math inline">\mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 = 0.48694</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="section-8" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><span class="math inline">\texttt{F} \,</span> is the F-statistic for Model Selection</li>
</ul>
<p><span class="math display">\begin{align*}
F &amp; = \frac{ \mathop{\mathrm{RSS}}_1 - \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2 } \bigg/
      \frac{ \mathop{\mathrm{RSS}}_2 }{ \mathop{\mathrm{df}}_2 } \\
  &amp; = \frac{ 1.32336 - 0.83642 }{ 12 - 9 } \bigg/
      \frac{ 0.83642 }{ 9 } =  1.7465
\end{align*}</span></p>
</div>
</section>
<section id="section-9" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<ul>
<li><span class="math inline">\texttt{Pr(&gt;F)}</span> is the p-value for the F-test for Model Selection
<ul>
<li><span class="math inline">F \, \sim \, F_{\mathop{\mathrm{df}}_1 - \mathop{\mathrm{df}}_2 , \, \mathop{\mathrm{df}}_2 } = F_{3, 9}</span></li>
<li>Therefore the p-value is <span class="math display">
  p = P(F_{3,9} &gt; F) = 0.227
  </span></li>
</ul></li>
</ul>
</div>
</section>
<section id="section-10" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ x4 + x5 + x7
Model 2: y ~ x2 + x3 + x4 + x5 + x6 + x7
  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)
1     12 1.32336                           
2      9 0.83642  3   0.48694 1.7465  0.227</code></pre>
</div>
</div>
<p><br></p>
<p><strong>Conclusion:</strong> The p-value is <span class="math inline">p = 0.227 &gt; 0.05</span></p>
<ul>
<li><p>This means we cannot reject <span class="math inline">H_0</span>, which said that <span class="math inline">\beta_{2} = \beta_{3} = \beta_6 = 0</span></p></li>
<li><p>Therefore the Reduced Model 1 has to be preferred <span class="math display">
Y = \beta_1 + \beta_4 x_{4} + \beta_5 x_{5} + \beta_7 x_{7}  + \varepsilon
</span></p></li>
<li><p>This gives statistical evidence that <span class="math inline">X_2, X_3,X_6</span> can be excluded from the model</p></li>
<li><p><em>GNP Deflator</em>, <em>GNP</em> and <em>Population</em> do not affect the <em>Number of Employed</em></p></li>
</ul>
</div>
</section>
<section id="example-2-motion-of-falling-bodies" class="slide level2 smaller">
<h2>Example 2: Motion of falling bodies</h2>
<p>Engraving (1546): people believed projectiles follow circular trajectories (<a href="https://www.alamy.com/engraving-depicting-the-path-of-a-projectile-shown-as-a-circular-arc-rather-than-a-parabolic-arc-as-was-later-proved-to-be-the-case-by-galileo-galileo-galilei-1564-1642-an-italian-polymath-dated-16th-century-image186386912.html">source</a>)</p>

<img data-src="images/engraving.jpg" style="width:73.0%" class="r-stretch"></section>
<section id="section-11" class="slide level2 smaller">
<h2></h2>
<ul>
<li>1609: Galileo proved mathematically that projectile trajectories are parabolic
<ul>
<li>His finding was based on empirical data</li>
<li>A ball (covered in ink) was released on an inclined plane from <em>Initial Height</em></li>
<li>Ink mark on the floor represented the <em>Horizontal Distance</em> traveled</li>
<li>Unit of measure is <em>punti</em> <span class="math inline">\qquad\quad 1 \text{ punto} = 169/180 \, \text{mm}</span></li>
</ul></li>
</ul>

<img data-src="images/galileo_0.png" style="width:73.0%" class="r-stretch"></section>
<section id="section-12" class="slide level2 smaller">
<h2></h2>
<ul>
<li>We have access to Galileos original data <span class="citation" data-cites="drake_galileo">[<a href="#/references" role="doc-biblioref" onclick="">1</a>]</span></li>
<li>Does a parabolic (quadratic) trajectory really explain the data?</li>
<li>Lets fit a polynomial regression model and find out!</li>
</ul>

<img data-src="images/galileo.png" style="width:73.0%" class="r-stretch"></section>
<section id="plotting-the-data" class="slide level2 smaller">
<h2>Plotting the data</h2>
<p><br></p>
<table class="caption-top">
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Initial Height</strong></td>
<td style="text-align: left;">100</td>
<td style="text-align: left;">200</td>
<td style="text-align: left;">300</td>
<td style="text-align: left;">450</td>
<td style="text-align: left;">600</td>
<td style="text-align: left;">800</td>
<td style="text-align: left;">1000</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Horizontal Distance</strong></td>
<td style="text-align: left;">253</td>
<td style="text-align: left;">337</td>
<td style="text-align: left;">395</td>
<td style="text-align: left;">451</td>
<td style="text-align: left;">495</td>
<td style="text-align: left;">534</td>
<td style="text-align: left;">573</td>
</tr>
</tbody>
</table>
<p><br></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Enter the data</span></span>
<span id="cb13-2"><a aria-hidden="true" tabindex="-1"></a>height <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">450</span>, <span class="dv">600</span>, <span class="dv">800</span>, <span class="dv">1000</span>)</span>
<span id="cb13-3"><a aria-hidden="true" tabindex="-1"></a>distance <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">253</span>, <span class="dv">337</span>, <span class="dv">395</span>, <span class="dv">451</span>, <span class="dv">495</span>, <span class="dv">534</span>, <span class="dv">573</span>)</span>
<span id="cb13-4"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb13-6"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height, distance, <span class="at">pch =</span> <span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="data-visualization" class="slide level2 smaller">
<h2>Data visualization</h2>
<div class="column" style="width:45%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-9-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:53%;">
<div style="font-size: 0.93em">
<ul>
<li><p>The plot shows that a parabola might fit better than a straight line</p></li>
<li><p>We can first fit the usual simple linear regression model <span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \varepsilon
</span></p></li>
<li><p>Then, we can try a degree 2 polynomial (linear) regression model <span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3 \, {\rm height }^2 + \varepsilon
</span></p></li>
<li><p>We can compare the 2 models with the F-test for <em>Model Selection</em></p></li>
</ul>
</div>
</div></section>
<section id="fit-simple-linear-model" class="slide level2 smaller">
<h2>Fit simple linear model</h2>
<p><span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \varepsilon
</span></p>
<p><br></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb14-2"><a aria-hidden="true" tabindex="-1"></a>linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height)</span>
<span id="cb14-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print summary</span></span>
<span id="cb14-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-13" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 269.71246   24.31239  11.094 0.000104 ***
height        0.33334    0.04203   7.931 0.000513 ***
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 33.68 on 5 degrees of freedom
Multiple R-squared:  0.9264,    Adjusted R-squared:  0.9116 
F-statistic: 62.91 on 1 and 5 DF,  p-value: 0.0005132
</code></pre>
<p><br></p>
<ul>
<li>Individual t-tests show that coefficients for both <strong>Intercept</strong> and <strong>height</strong> are non-zero
<ul>
<li><span class="math inline">\beta_1 \neq 0</span> because corresponding p-value is <span class="math inline">p = 0.000104 &lt; 0.05</span></li>
<li><span class="math inline">\beta_2 \neq 0</span> because corresponding p-value is <span class="math inline">p = 0.000513 &lt; 0.05</span></li>
</ul></li>
<li>F-test for overall significance coincides with t-test for paramter <span class="math inline">\beta_2</span>
<ul>
<li>Recall: This is always true for simple regression</li>
<li>Hence, F-test is redundant in this case</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-14" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 269.71246   24.31239  11.094 0.000104 ***
height        0.33334    0.04203   7.931 0.000513 ***
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 33.68 on 5 degrees of freedom
Multiple R-squared:  0.9264,    Adjusted R-squared:  0.9116 
F-statistic: 62.91 on 1 and 5 DF,  p-value: 0.0005132
</code></pre>
<p><br></p>
<ul>
<li>The coefficient of determination is <span class="math inline">R^2 = 0.9264</span>
<ul>
<li>This is quite high (close to <span class="math inline">1</span>)</li>
</ul></li>
<li><strong>Conclusion:</strong> Every indicator shows that the linear model fits quite well</li>
</ul>
</div>
</section>
<section id="fit-quadratic-model" class="slide level2 smaller">
<h2>Fit quadratic model</h2>
<p><span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3  
\, {\rm height }^2 + \varepsilon
</span></p>
<p><br></p>
<p><strong>Note:</strong> To specify powers, we need to type <span class="math inline">\,\, \texttt{I}</span></p>
<p><br></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit quadratic model</span></span>
<span id="cb17-2"><a aria-hidden="true" tabindex="-1"></a>quadratic <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height <span class="sc">+</span> <span class="fu">I</span>( height<span class="sc">^</span><span class="dv">2</span> ))</span>
<span id="cb17-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print summary</span></span>
<span id="cb17-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(quadratic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-15" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.999e+02  1.676e+01  11.928 0.000283 ***
height       7.083e-01  7.482e-02   9.467 0.000695 ***
I(height^2) -3.437e-04  6.678e-05  -5.147 0.006760 ** 
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 13.64 on 4 degrees of freedom
Multiple R-squared:  0.9903,    Adjusted R-squared:  0.9855 
F-statistic:   205 on 2 and 4 DF,  p-value: 9.333e-05</code></pre>
<p><br></p>
<ul>
<li>Individual t-tests show that all coefficients are non-zero
<ul>
<li><span class="math inline">\beta_1 \neq 0</span> because corresponding p-value is <span class="math inline">p = 0.000283 &lt; 0.05</span></li>
<li><span class="math inline">\beta_2 \neq 0</span> because corresponding p-value is <span class="math inline">p = 0.000695 &lt; 0.05</span></li>
<li><span class="math inline">\beta_3 \neq 0</span> because corresponding p-value is <span class="math inline">p = 0.006760 &lt; 0.05</span></li>
</ul></li>
<li>In particular, this shows that the <em>extra quadratic term</em> is significant</li>
</ul>
</div>
</section>
<section id="section-16" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.999e+02  1.676e+01  11.928 0.000283 ***
height       7.083e-01  7.482e-02   9.467 0.000695 ***
I(height^2) -3.437e-04  6.678e-05  -5.147 0.006760 ** 
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 13.64 on 4 degrees of freedom
Multiple R-squared:  0.9903,    Adjusted R-squared:  0.9855 
F-statistic:   205 on 2 and 4 DF,  p-value: 9.333e-05</code></pre>
<p><br></p>
<ul>
<li>F-test for overall significance gives a p-value of <span class="math inline">p = 9.333 \times 10^{-05} &lt; 0.05</span>
<ul>
<li>This means we reject the null hypothesis that <span class="math display">
  \beta_2 = \beta_3 = 0
  </span></li>
<li>Hence, we have confirmation that at least one of the parameters is significant</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-17" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.999e+02  1.676e+01  11.928 0.000283 ***
height       7.083e-01  7.482e-02   9.467 0.000695 ***
I(height^2) -3.437e-04  6.678e-05  -5.147 0.006760 ** 
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 13.64 on 4 degrees of freedom
Multiple R-squared:  0.9903,    Adjusted R-squared:  0.9855 
F-statistic:   205 on 2 and 4 DF,  p-value: 9.333e-05</code></pre>
<p><br></p>
<ul>
<li>The coefficient of determination is <span class="math inline">R^2 = 0.9903</span>
<ul>
<li>This is quite high (close to <span class="math inline">1</span>)</li>
<li>The quadratic trajectory explains <span class="math inline">99\%</span> of variability in the data</li>
</ul></li>
<li><strong>Conclusion:</strong> Every indicator shows that the quadratic model fits quite well</li>
</ul>
</div>
</section>
<section id="linear-vs-quadratic" class="slide level2 smaller">
<h2>Linear Vs Quadratic</h2>
<ul>
<li><p>We have seen that both linear and quadratic models fit well</p></li>
<li><p>In particular, the coefficients of determination are <span class="math display">
R^2 \text{ for quadratic model} = 0.9903 &gt; R^2 \text{ for linear model} = 0.9264
</span></p></li>
<li><p>This confirms that the Quadratic model offers a better fit</p></li>
<li><p>However, need to confirm that Quadratic model makes <strong>better predictions</strong></p>
<ul>
<li>Can be done with <em>F-test for Model Selection</em></li>
</ul></li>
</ul>
<div style="font-size: 0.25em">
<p><br></p>
</div>
<div class="sourceCode" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># F-test for Model Selection</span></span>
<span id="cb21-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(linear, quadratic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-18" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Analysis of Variance Table

Model 1: distance ~ height
Model 2: distance ~ height + I(height^2)
  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)   
1      5 5671.2                               
2      4  744.1  1    4927.1 26.487 0.00676 **</code></pre>
<p><br></p>
<ul>
<li><p>First two lines say that the following 2 models are being compared <span class="math display">\begin{align*}
  \textbf{Model 1:} &amp; \quad {\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \varepsilon\\[10pt]
  \textbf{Model 2:} &amp; \quad {\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3  
\, {\rm height }^2 + \varepsilon
\end{align*}</span></p></li>
<li><p>The null hypothesis favors Model 1; The alternative favors Model 2 <span class="math display">\begin{align*}
H_0 \colon &amp; \,  \beta_{3}  = 0 \\[5pt]
H_1 \colon &amp; \,  \beta_{3} \neq 0
\end{align*}</span></p></li>
</ul>
</div>
</section>
<section id="section-19" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Analysis of Variance Table

Model 1: distance ~ height
Model 2: distance ~ height + I(height^2)
  Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)   
1      5 5671.2                               
2      4  744.1  1    4927.1 26.487 0.00676 **</code></pre>
<p><br></p>
<ul>
<li><p><strong>Note:</strong> Hypothesis for Model Selection coincides with hypothesis of significance of <span class="math inline">\beta_3</span> <span class="math display">\begin{align*}
H_0 \colon &amp; \,  \beta_{3}  = 0 \\[5pt]
H_1 \colon &amp; \,  \beta_{3} \neq 0
\end{align*}</span></p></li>
<li><p>In this case, t-test for significance of <span class="math inline">\beta_3</span> and F-test for Model Selection coincide</p></li>
<li><p>They both give a p-value of <span class="math inline">p = 0.00676 &lt; 0.05</span></p></li>
<li><p>This means we reject <span class="math inline">H_0 \quad \implies</span> the Quadratic term is needed</p></li>
<li><p><strong>Quadratic model has to be preferred to the linear one</strong></p></li>
</ul>
</div>
</section>
<section id="why-not-try-a-cubic-model" class="slide level2 smaller">
<h2>Why not try a Cubic model?</h2>
<p><br></p>
<p><span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3  
\, {\rm height }^2 + \beta_4 \, {\rm height }^3 + \varepsilon
</span></p>
<p><br></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit cubic model</span></span>
<span id="cb24-2"><a aria-hidden="true" tabindex="-1"></a>cubic <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height <span class="sc">+</span> <span class="fu">I</span>( height<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">+</span> <span class="fu">I</span> (height<span class="sc">^</span><span class="dv">3</span>))</span>
<span id="cb24-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print Summary</span></span>
<span id="cb24-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cubic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-20" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.558e+02  8.326e+00  18.710 0.000333 ***
height       1.115e+00  6.567e-02  16.983 0.000445 ***
I(height^2) -1.245e-03  1.384e-04  -8.994 0.002902 ** 
I(height^3)  5.477e-07  8.327e-08   6.577 0.007150 ** 
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 4.011 on 3 degrees of freedom
Multiple R-squared:  0.9994,    Adjusted R-squared:  0.9987 
F-statistic:  1595 on 3 and 3 DF,  p-value: 2.662e-05</code></pre>
<p><br></p>
<ul>
<li>Individual t-tests show that all coefficients are non-zero (p-values <span class="math inline">&lt; 0.05</span>)
<ul>
<li>In particular, this shows that the <em>extra cubic term</em> is significant</li>
</ul></li>
<li>F-test for overall significance gives a p-value of <span class="math inline">p = 2.662 \times 10^{-05} &lt; 0.05</span>
<ul>
<li>We have confirmation that at least one of the parameters is non-zero</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-21" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.558e+02  8.326e+00  18.710 0.000333 ***
height       1.115e+00  6.567e-02  16.983 0.000445 ***
I(height^2) -1.245e-03  1.384e-04  -8.994 0.002902 ** 
I(height^3)  5.477e-07  8.327e-08   6.577 0.007150 ** 
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 4.011 on 3 degrees of freedom
Multiple R-squared:  0.9994,    Adjusted R-squared:  0.9987 
F-statistic:  1595 on 3 and 3 DF,  p-value: 2.662e-05</code></pre>
<p><br></p>
<ul>
<li>The coefficient of determination is <span class="math inline">R^2 = 0.9994</span>
<ul>
<li>This is quite high (close to <span class="math inline">1</span>)</li>
</ul></li>
<li><strong>Conclusion:</strong> Every indicator shows that the Cubic model fits quite well</li>
</ul>
</div>
</section>
<section id="quadratic-vs-cubic" class="slide level2 smaller">
<h2>Quadratic vs Cubic</h2>
<ul>
<li><p>Both Quadratic and Cubic models fit well</p></li>
<li><p>In particular, the coefficients of determination are <span class="math display">
R^2 \text{ for Cubic model} = 0.9994 &gt; R^2 \text{ for Quadratic model} =  0.9903
</span></p></li>
<li><p>This confirms that the Cubic model offers a better fit</p>
<ul>
<li>Falling bodies follow cubic trajectories???</li>
<li>What is going on?</li>
</ul></li>
<li><p>Need to confirm that Cubic model makes <strong>better predictions</strong></p>
<ul>
<li>Can be done with <em>F-test for Model Selection</em></li>
</ul></li>
</ul>
<div style="font-size: 0.25em">
<p><br></p>
</div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># F-test for Model Selection</span></span>
<span id="cb27-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(quadratic, cubic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-22" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>
Analysis of Variance Table

Model 1: distance ~ height + I(height^2)
Model 2: distance ~ height + I(height^2) + I(height^3)
  Res.Df    RSS Df Sum of Sq     F  Pr(&gt;F)   
1      4 744.08                              
2      3  48.25  1    695.82 43.26 0.00715 **</code></pre>
<p><br></p>
<ul>
<li><p>First two lines say that the following 2 models are being compared <span class="math display">\begin{align*}
  \textbf{Model 1:} &amp; \quad {\rm distance} = \beta_1 + \beta_2 \, {\rm height } +  \beta_3  
\, {\rm height }^2  + \varepsilon\\[10pt]
  \textbf{Model 2:} &amp; \quad {\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3  
\, {\rm height }^2  + \beta_4  
\, {\rm height }^3 + \varepsilon
\end{align*}</span></p></li>
<li><p>The null hypothesis favors Model 1; The alternative favors Model 2 <span class="math display">\begin{align*}
H_0 \colon &amp; \,  \beta_{4}  = 0 \\[5pt]
H_1 \colon &amp; \,  \beta_{4} \neq 0
\end{align*}</span></p></li>
</ul>
</div>
</section>
<section id="section-23" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>
Analysis of Variance Table

Model 1: distance ~ height + I(height^2)
Model 2: distance ~ height + I(height^2) + I(height^3)
  Res.Df    RSS Df Sum of Sq     F  Pr(&gt;F)   
1      4 744.08                              
2      3  48.25  1    695.82 43.26 0.00715 **</code></pre>
<p><br></p>
<ul>
<li><p><strong>Note:</strong> Hypothesis for Model Selection coincides with hypothesis of significance of <span class="math inline">\beta_4</span> <span class="math display">\begin{align*}
H_0 \colon &amp; \,  \beta_{4}  = 0 \\[5pt]
H_1 \colon &amp; \,  \beta_{4} \neq 0
\end{align*}</span></p></li>
<li><p>In this case, t-test for significance of <span class="math inline">\beta_4</span> and F-test for Model Selection coincide</p></li>
<li><p>They both give a p-value of <span class="math inline">p = 0.00715 &lt; 0.05</span></p></li>
<li><p>This means we reject <span class="math inline">H_0 \quad \implies</span> the Cubic term is needed</p></li>
<li><p><strong>Cubic model has to be preferred to the Quadratic one</strong></p></li>
</ul>
</div>
</section>
<section id="conclusion" class="slide level2 smaller">
<h2>Conclusion</h2>
<div class="column" style="width:48%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Enter the data</span></span>
<span id="cb30-2"><a aria-hidden="true" tabindex="-1"></a>height <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">450</span>, <span class="dv">600</span>, <span class="dv">800</span>, <span class="dv">1000</span>)</span>
<span id="cb30-3"><a aria-hidden="true" tabindex="-1"></a>distance <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">253</span>, <span class="dv">337</span>, <span class="dv">395</span>, <span class="dv">451</span>, <span class="dv">495</span>, <span class="dv">534</span>, <span class="dv">573</span>)</span>
<span id="cb30-4"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb30-6"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height, distance, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb30-7"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb30-9"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Initial height"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb30-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Horizontal distance"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb30-11"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit quadratic model</span></span>
<span id="cb30-13"><a aria-hidden="true" tabindex="-1"></a>quadratic <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height <span class="sc">+</span> <span class="fu">I</span>( height<span class="sc">^</span><span class="dv">2</span> ))</span>
<span id="cb30-14"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit cubic model</span></span>
<span id="cb30-16"><a aria-hidden="true" tabindex="-1"></a>cubic <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height <span class="sc">+</span> <span class="fu">I</span>( height<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">+</span> <span class="fu">I</span> (height<span class="sc">^</span><span class="dv">3</span>))</span>
<span id="cb30-17"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot quadratic Vs Cubic</span></span>
<span id="cb30-19"><a aria-hidden="true" tabindex="-1"></a>polynomial <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(<span class="cf">function</span>(x, ps) {</span>
<span id="cb30-20"><a aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(ps)</span>
<span id="cb30-21"><a aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(ps<span class="sc">*</span>x<span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span>n<span class="dv">-1</span>))</span>
<span id="cb30-22"><a aria-hidden="true" tabindex="-1"></a>}, <span class="st">"x"</span>)</span>
<span id="cb30-23"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(quadratic)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb30-24"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(cubic)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb30-25"><a aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"quadratic"</span>, <span class="st">"cubic"</span>), </span>
<span id="cb30-26"><a aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">cex =</span> <span class="fl">2.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-10-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="font-size: 0.95em">
<ul>
<li><p>Cubic model works better than Quadratic model</p></li>
<li><p>The underlying relationship from Galileos data is Cubic and not Quadratic</p></li>
<li><p>Probably the <em>inclined plane</em> introduced <em>drag</em></p></li>
<li><p>Code can be downloaded here <a href="codes/galileo.R">galileo.R</a></p></li>
</ul>
</div>
</div></section>
<section id="why-not-try-higher-degree-polynomials" class="slide level2 smaller">
<h2>Why not try higher degree polynomials?</h2>
<p><br></p>
<p><span class="math display">
{\rm distance} = \beta_1 + \beta_2 \, {\rm height } + \beta_3  
\, {\rm height }^2 + \beta_4 \, {\rm height }^3
+ \beta_5 \, {\rm height }^4 + \varepsilon
</span></p>
<p><br></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Quartic model</span></span>
<span id="cb31-2"><a aria-hidden="true" tabindex="-1"></a>quartic <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance <span class="sc">~</span> height <span class="sc">+</span> <span class="fu">I</span>( height<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">+</span> <span class="fu">I</span> (height<span class="sc">^</span><span class="dv">3</span>) </span>
<span id="cb31-3"><a aria-hidden="true" tabindex="-1"></a>                                                <span class="sc">+</span> <span class="fu">I</span> (height<span class="sc">^</span><span class="dv">4</span>))</span>
<span id="cb31-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print summary</span></span>
<span id="cb31-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(quartic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-24" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)  1.383e+02  9.066e+00  15.254  0.00427 **
height       1.346e+00  1.061e-01  12.690  0.00615 **
I(height^2) -2.117e-03  3.793e-04  -5.582  0.03063 * 
I(height^3)  1.766e-06  5.186e-07   3.406  0.07644 . 
I(height^4) -5.610e-10  2.375e-10  -2.362  0.14201   
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 2.523 on 2 degrees of freedom
Multiple R-squared:  0.9998,    Adjusted R-squared:  0.9995 
F-statistic:  3024 on 4 and 2 DF,  p-value: 0.0003306</code></pre>
<p><br></p>
<ul>
<li>Individual t-tests show that:
<ul>
<li>Coefficients for <strong>Intercept</strong>, <strong>Linear</strong> and <strong>Quadratic</strong> terms are non-zero (<span class="math inline">p &lt; 0.05</span>)</li>
<li>Coefficients for <strong>Cubic</strong> and <strong>Quartic</strong> term are zero (<span class="math inline">p &gt; 0.05</span>)</li>
</ul></li>
<li>F-test for overall significance gives a p-value of <span class="math inline">p = 0.0003306 &lt; 0.05</span>
<ul>
<li>We have confirmation that at least one of the coefficients is non-zero</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-25" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)  1.383e+02  9.066e+00  15.254  0.00427 **
height       1.346e+00  1.061e-01  12.690  0.00615 **
I(height^2) -2.117e-03  3.793e-04  -5.582  0.03063 * 
I(height^3)  1.766e-06  5.186e-07   3.406  0.07644 . 
I(height^4) -5.610e-10  2.375e-10  -2.362  0.14201   
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 2.523 on 2 degrees of freedom
Multiple R-squared:  0.9998,    Adjusted R-squared:  0.9995 
F-statistic:  3024 on 4 and 2 DF,  p-value: 0.0003306</code></pre>
<p><br></p>
<ul>
<li>The coefficient of determination is <span class="math inline">R^2 = 0.9998</span>
<ul>
<li>This is almost <span class="math inline">1</span></li>
</ul></li>
<li><strong>Conclusion:</strong> There are signs that the model is overfitting
<ul>
<li>Coefficient <span class="math inline">R^2</span> extremely high</li>
<li>However, some terms (Cubic and Quartic) are not significant</li>
</ul></li>
</ul>
</div>
</section>
<section id="cubic-vs-quartic" class="slide level2 smaller">
<h2>Cubic vs Quartic</h2>
<div style="font-size: 0.96em">
<ul>
<li><p>We saw that the Cubic model fits data well</p></li>
<li><p>Quartic model shows some issues:</p>
<ul>
<li>Extremely high <span class="math inline">R^2</span> coefficient</li>
<li>However, some paramteres are non-significant</li>
</ul></li>
<li><p>Nevertheless, the coefficients of determination are <span class="math display">
R^2 \text{ for Quartic model} = 0.9998 &gt; R^2 \text{ for Cubic model} =  0.9994
</span></p></li>
<li><p>Maybe the Quartic model is actually better?</p></li>
<li><p>To compare predictions, use F-test for Model Selection</p></li>
</ul>
<div style="font-size: 0.25em">
<p><br></p>
</div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># F-test for Model Selection</span></span>
<span id="cb34-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(cubic, quartic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="section-26" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>
Analysis of Variance Table

Model 1: distance ~ height + I(height^2) + I(height^3)
Model 2: distance ~ height + I(height^2) + I(height^3) + I(height^4)
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1      3 48.254                           
2      2 12.732  1    35.522 5.5799  0.142</code></pre>
<p><br></p>
<ul>
<li><p>The null hypothesis favors Model 1; The alternative favors Model 2 <span class="math display">\begin{align*}
H_0 \colon &amp; \,  \beta_{5}  = 0 \\[5pt]
H_1 \colon &amp; \,  \beta_{5} \neq 0
\end{align*}</span></p></li>
<li><p>The p-value is <span class="math inline">p = 0.142 &gt; 0.05 \quad \implies \quad</span> do not reject <span class="math inline">H_0</span></p></li>
<li><p>This means <span class="math inline">\beta_5 = 0</span>, showing that the Quartic term is not improving predictions</p></li>
</ul>
</div>
</section>
<section id="section-27" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<pre class="verbatim"><code>
Analysis of Variance Table

Model 1: distance ~ height + I(height^2) + I(height^3)
Model 2: distance ~ height + I(height^2) + I(height^3) + I(height^4)
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1      3 48.254                           
2      2 12.732  1    35.522 5.5799  0.142</code></pre>
<p><br></p>
<p><strong>Conclusion:</strong> Cubic model has to be preferred to the Quartic one</p>
<ul>
<li><p>The Cubic model makes better predictions, despite lower <span class="math inline">R^2</span> coefficient</p></li>
<li><p>The underlying relationship from Galileos data is indeed cubic!</p></li>
</ul>
</div>
</section>
<section id="example-3-debunking-fake-news" class="slide level2 smaller">
<h2>Example 3: Debunking fake news</h2>
<p>Screenshot of a Daily Mirror article <a href="https://www.mirror.co.uk/news/uk-news/second-year-of-marriage-is-peak-time-337551?int_source=amp_continue_reading&amp;int_medium=amp&amp;int_campaign=continue_reading_button#amp-readmore-target">(link)</a></p>

<img data-src="images/mirror.png" style="width:100.0%" class="r-stretch"></section>
<section id="section-28" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>All the hallmarks of fake news are present</p>
<ul>
<li>Bold claim</li>
<li>No precise references</li>
<li>No actual data</li>
</ul></li>
<li><p>The original study on <a href="https://www.divorce-online.co.uk">Divorce-Online.co.uk</a> seems unavailable at present (2025)</p></li>
<li><p>However, the Daily Mirror article <a href="https://www.mirror.co.uk/news/uk-news/second-year-of-marriage-is-peak-time-337551?int_source=amp_continue_reading&amp;int_medium=amp&amp;int_campaign=continue_reading_button#amp-readmore-target">(link)</a> states the following:</p>
<ul>
<li><em>The poll [from Divorce-Online.co.uk] backs Office for National Statistics figures</em></li>
</ul></li>
<li><p>The dataset in question can be found on the ONS Website <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/divorce/datasets/divorcesinenglandandwalesageatmarriagedurationofmarriageandcohortanalyses">(Link to the Dataset)</a></p></li>
</ul>
</section>
<section id="the-divorces-dataset" class="slide level2 smaller">
<h2>The divorces dataset</h2>
<div class="column" style="width:48%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb37-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb37-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb37-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb37-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb37-7"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, percent, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb37-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb37-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Years of marriage"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb37-11"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Risk of divorce"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-11-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div style="font-size: 0.72em">
<table class="caption-top" style="width:50%;">
<colgroup>
<col style="width: 30%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Years of Marriage</strong></th>
<th style="text-align: left;"><strong>% divorces</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">3.51</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">9.50</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">8.91</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">9.35</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">8.18</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">6.43</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">5.31</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;">5.07</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9</td>
<td style="text-align: left;">3.65</td>
</tr>
<tr class="even">
<td style="text-align: left;">10</td>
<td style="text-align: left;">3.80</td>
</tr>
<tr class="odd">
<td style="text-align: left;">15</td>
<td style="text-align: left;">2.83</td>
</tr>
<tr class="even">
<td style="text-align: left;">20</td>
<td style="text-align: left;">1.51</td>
</tr>
<tr class="odd">
<td style="text-align: left;">25</td>
<td style="text-align: left;">1.27</td>
</tr>
<tr class="even">
<td style="text-align: left;">30</td>
<td style="text-align: left;">0.49</td>
</tr>
</tbody>
</table>
</div>
</div></section>
<section id="the-divorces-dataset-1" class="slide level2 smaller">
<h2>The divorces dataset</h2>
<div class="column" style="width:48%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb38-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb38-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb38-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb38-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb38-7"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, percent, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb38-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb38-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Years of marriage"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb38-11"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Risk of divorce"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-12-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div style="font-size: 0.95em">
<ul>
<li>From the plot: Divorce-risk is
<ul>
<li>First low</li>
<li>then peaks at year 2</li>
<li>then decreases</li>
</ul></li>
<li><em>Daily Mirror</em> claimed:
<ul>
<li>Divorce-risk peaks at year 2, then decreases thereafter</li>
<li>From the plot, the claim seems credible</li>
</ul></li>
</ul>
</div>
</div></section>
<section id="the-divorces-dataset-2" class="slide level2 smaller">
<h2>The divorces dataset</h2>
<div class="column" style="width:48%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb39-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb39-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb39-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb39-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb39-7"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, percent, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb39-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb39-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Years of marriage"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb39-11"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Risk of divorce"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-13-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div style="font-size: 0.95em">
<ul>
<li>We can fact check the claim with regression:
<ul>
<li>A peak in the data means there is a change of trend</li>
<li>This can only be explained by a polynomial model</li>
<li>Fit quadratic model</li>
</ul></li>
<li>If claim is to be believed:
<ul>
<li>quadratic model should do better than a linear one</li>
</ul></li>
</ul>
</div>
</div></section>
<section id="fitting-linear-model" class="slide level2 smaller">
<h2>Fitting linear model</h2>
<p><br></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb40-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb40-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb40-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb40-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb40-7"><a aria-hidden="true" tabindex="-1"></a>linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year)</span>
<span id="cb40-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot summary</span></span>
<span id="cb40-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-29" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  7.88575    0.78667  10.024 3.49e-07 ***
year        -0.27993    0.05846  -4.788 0.000442 ***
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 1.879 on 12 degrees of freedom
Multiple R-squared:  0.6564,    Adjusted R-squared:  0.6278 
F-statistic: 22.93 on 1 and 12 DF,  p-value: 0.0004422</code></pre>
<p><br></p>
<ul>
<li><p>t-test for <span class="math inline">\beta_2</span> is significant, since <span class="math inline">p = 0.0004 &lt; 0.05</span></p></li>
<li><p>Therefore <span class="math inline">\beta_2 \neq 0</span>, and the estimate is <span class="math inline">\hat \beta_2 = -0.27993</span></p></li>
<li><p>The risk of divorce decreases with years of marriage (because <span class="math inline">\hat \beta_2 &lt; 0</span>)</p></li>
<li><p>Coefficient of determination is <span class="math inline">R^2 = 0.6564</span>, which is reasonably high</p></li>
<li><p><strong>Conclusion:</strong> The linear model provides a good fit</p></li>
</ul>
</div>
</section>
<section id="fitting-quadratic-model" class="slide level2 smaller">
<h2>Fitting quadratic model</h2>
<ul>
<li><p>Linear model offered a reasonable explanation of the divorce data</p></li>
<li><p>Is a quadratic model better?</p></li>
</ul>
<p><br></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit quadratic model</span></span>
<span id="cb42-2"><a aria-hidden="true" tabindex="-1"></a>quadratic <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">2</span> ))</span>
<span id="cb42-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print summary</span></span>
<span id="cb42-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(quadratic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-30" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<pre class="verbatim"><code>Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  8.751048   1.258038   6.956  2.4e-05 ***
year        -0.482252   0.235701  -2.046   0.0654 .  
I(year^2)    0.006794   0.007663   0.887   0.3943    
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

Residual standard error: 1.896 on 11 degrees of freedom
Multiple R-squared:  0.6794,    Adjusted R-squared:  0.6211 
F-statistic: 11.65 on 2 and 11 DF,  p-value: 0.001919</code></pre>
<p><br></p>
<ul>
<li><p>t-test for <span class="math inline">\beta_3</span> is not significant, since <span class="math inline">p = 0.3943 &gt; 0.05</span></p></li>
<li><p>Cannot reject null hypothesis that <span class="math inline">\beta_3 = 0 \quad \implies \quad</span> Quadratic term not needed!</p></li>
<li><p><strong>Note:</strong> No need to run Model Selection to compare linear and quadratic models</p>
<ul>
<li>This is because, when comparing linear and quadratic models, the extra term corresponds to the parameter <span class="math inline">\beta_3</span></li>
<li>Therefore, F-test for Model Selection would give same p-value as t-test for <span class="math inline">\beta_3</span></li>
</ul></li>
</ul>
</div>
</section>
<section id="conclusions" class="slide level2 smaller">
<h2>Conclusions</h2>
<div style="font-size: 0.95em">
<ul>
<li>Daily Mirrors Claim: Divorce-risk peaks at year 2 then decreases thereafter
<ul>
<li>Claim suggests higher order model needed to explain change in trend</li>
</ul></li>
<li>Analysis conducted by us:
<ul>
<li>Fit linear and quadratic regression models</li>
<li>t-test of significance discarded quadratic term</li>
<li>This is equivalent to F-test for Model Selection: Quadratic model is discarded</li>
</ul></li>
<li>Our Findings: Claim in Daily Mirror article is <strong>misleading</strong>
<ul>
<li>Linear model is clearly better than quadratic model</li>
<li>This suggests divorce-risk generally decreases over time</li>
<li>Peak in year 2 can be explained by unusually low divorce-risk in 1st year</li>
<li>This means data for 1st year is <em>outlier</em></li>
</ul></li>
</ul>
</div>
</section>
<section id="visual-confirmation" class="slide level2 smaller">
<h2>Visual confirmation</h2>
<div class="column" style="width:48%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb44-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb44-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb44-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb44-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb44-7"><a aria-hidden="true" tabindex="-1"></a>linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year)</span>
<span id="cb44-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit quadratic model</span></span>
<span id="cb44-10"><a aria-hidden="true" tabindex="-1"></a>quadratic <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">2</span> ))</span>
<span id="cb44-11"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb44-13"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, percent, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb44-14"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-15"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb44-16"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Years of marriage"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb44-17"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Risk of divorce"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb44-18"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Linear Vs Quadratic</span></span>
<span id="cb44-20"><a aria-hidden="true" tabindex="-1"></a>polynomial <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(<span class="cf">function</span>(x, ps) {</span>
<span id="cb44-21"><a aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(ps)</span>
<span id="cb44-22"><a aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(ps<span class="sc">*</span>x<span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span>n<span class="dv">-1</span>))</span>
<span id="cb44-23"><a aria-hidden="true" tabindex="-1"></a>}, <span class="st">"x"</span>)</span>
<span id="cb44-24"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(linear)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb44-25"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(quadratic)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb44-26"><a aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"Linear"</span>, <span class="st">"Quadratic"</span>), </span>
<span id="cb44-27"><a aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">cex =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-14-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<p><br> <br></p>
<div style="font-size: 0.95em">
<ul>
<li><p>Linear model is evidently better at explaining decreasing divorce-risk</p></li>
<li><p>Peak in year 2 should be explained by unusually low divorce-risk in 1st year</p></li>
<li><p>This means Year 1 data is <em>outlier</em></p></li>
<li><p>Code is available here <a href="codes/divorces.R">divorces.R</a></p></li>
</ul>
</div>
</div></section>
<section id="why-not-try-higher-order-polynomials" class="slide level2 smaller">
<h2>Why not try higher order polynomials?</h2>
<ul>
<li><p>We can try fitting higher-order polynomial models to explain <em>peak in Year 2</em></p></li>
<li><p>The lowest-order polynomial that provides a good fit is degree 6 (try it yourself!)</p></li>
<li><p>Let us compare the <em>linear model</em> with the <em>degree 6 polynomial model</em></p></li>
</ul>
<p><br></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit order 6 model</span></span>
<span id="cb45-2"><a aria-hidden="true" tabindex="-1"></a>degree<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">3</span> ) <span class="sc">+</span> </span>
<span id="cb45-3"><a aria-hidden="true" tabindex="-1"></a>                              <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">4</span> ) <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">5</span> ) <span class="sc">+</span></span>
<span id="cb45-4"><a aria-hidden="true" tabindex="-1"></a>                              <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">6</span> ))</span>
<span id="cb45-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># F-test for Model Selection</span></span>
<span id="cb45-7"><a aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(linear, degree<span class="fl">.6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-31" class="slide level2 smaller">
<h2></h2>
<pre class="verbatim"><code>Model 1: percent ~ year
Model 2: percent ~ year + I(year^2) + I(year^3) + I(year^4) + I(year^5) + 
    +I(year^6)
  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   
1     12 42.375                                
2      7  3.724  5    38.651 14.531 0.001404 **</code></pre>
<p><br></p>
<ul>
<li><p>F-test for Model Selection is significant, since <span class="math inline">p = 0.001 &lt; 0.05</span></p></li>
<li><p>This means we reject the null hypothesis that <span class="math display">
\beta_3 = \beta_4 = \beta_5 = \beta_6 = 0
</span></p></li>
<li><p>The degree 6 model is better than the Linear model</p></li>
<li><p>Peak divorce-rate in Year 2 is well explained by order 6 regression</p></li>
<li><p>What is going on? Was the Daily Mirror right?</p>
<ul>
<li>Let us plot the fitted regression functions</li>
</ul></li>
</ul>
</section>
<section id="section-32" class="slide level2 smaller">
<h2></h2>
<div class="column" style="width:49%;">
<div class="cell">
<details class="code-fold">
<summary>Click here to show the full code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Divorces data</span></span>
<span id="cb47-2"><a aria-hidden="true" tabindex="-1"></a>year <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>)</span>
<span id="cb47-3"><a aria-hidden="true" tabindex="-1"></a>percent <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">3.51</span>, <span class="fl">9.5</span>, <span class="fl">8.91</span>, <span class="fl">9.35</span>, <span class="fl">8.18</span>, <span class="fl">6.43</span>, <span class="fl">5.31</span>, </span>
<span id="cb47-4"><a aria-hidden="true" tabindex="-1"></a>             <span class="fl">5.07</span>, <span class="fl">3.65</span>, <span class="fl">3.8</span>, <span class="fl">2.83</span>, <span class="fl">1.51</span>, <span class="fl">1.27</span>, <span class="fl">0.49</span>)</span>
<span id="cb47-5"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb47-7"><a aria-hidden="true" tabindex="-1"></a>linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year)</span>
<span id="cb47-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit degree 6 model</span></span>
<span id="cb47-10"><a aria-hidden="true" tabindex="-1"></a>degree<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(percent <span class="sc">~</span> year  <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">2</span> ) <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">3</span> ) <span class="sc">+</span> </span>
<span id="cb47-11"><a aria-hidden="true" tabindex="-1"></a>                                <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">4</span> ) <span class="sc">+</span> <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">5</span> ) <span class="sc">+</span></span>
<span id="cb47-12"><a aria-hidden="true" tabindex="-1"></a>                                <span class="fu">I</span>( year<span class="sc">^</span><span class="dv">6</span> ))</span>
<span id="cb47-13"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of data</span></span>
<span id="cb47-15"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(year, percent, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb47-16"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels</span></span>
<span id="cb47-18"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Years of marriage"</span>, <span class="at">side =</span> <span class="dv">1</span>, <span class="at">line =</span> <span class="dv">3</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb47-19"><a aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Risk of divorce"</span>, <span class="at">side =</span> <span class="dv">2</span>, <span class="at">line =</span> <span class="fl">2.5</span>, <span class="at">cex =</span> <span class="fl">2.1</span>)</span>
<span id="cb47-20"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-21"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Linear Vs Quadratic</span></span>
<span id="cb47-22"><a aria-hidden="true" tabindex="-1"></a>polynomial <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(<span class="cf">function</span>(x, ps) {</span>
<span id="cb47-23"><a aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(ps)</span>
<span id="cb47-24"><a aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(ps<span class="sc">*</span>x<span class="sc">^</span>(<span class="dv">1</span><span class="sc">:</span>n<span class="dv">-1</span>))</span>
<span id="cb47-25"><a aria-hidden="true" tabindex="-1"></a>}, <span class="st">"x"</span>)</span>
<span id="cb47-26"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(linear)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb47-27"><a aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">polynomial</span>(x, <span class="fu">coef</span>(degree<span class="fl">.6</span>)), <span class="at">add=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb47-28"><a aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"Linear"</span>, <span class="st">"Degree 6"</span>), </span>
<span id="cb47-29"><a aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">cex =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-15-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:49%;">
<div style="font-size: 0.92em">
<ul>
<li><p>Degree 6 model explains Peak at Year 2</p></li>
<li><p>However, the model introduces new peaks!</p>
<ul>
<li>We observe a decreasing risk of divorce for 23 years</li>
<li>But marriage gets boring after 27 years!</li>
</ul></li>
<li><p><strong>Degree 6 Model overfits</strong>:</p>
<ul>
<li>No, the Daily Mirror is not right</li>
<li>Data is very well explained</li>
<li>but predictions are not realistic</li>
</ul></li>
<li><p>Linear model should be preferred</p>
<ul>
<li>We will justify this rigorously with <strong>Stepwise Regression</strong></li>
</ul></li>
</ul>
</div>
</div></section></section>
<section>
<section id="part-3-regression-assumptions" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 3: <br> Regression Assumptions <br></h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="regression-modelling-assumptions" class="slide level2 smaller">
<h2>Regression modelling assumptions</h2>
<p>In Lecture 8 we have introduced the general linear regression model</p>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \beta_2 z_{i2} + \ldots + \beta_p z_{ip} + \varepsilon_i
</span></p>
<ul>
<li>There are <span class="math inline">p</span> predictor random variables</li>
</ul>
<p><span class="math display">
Z_1 \, , \,\, \ldots \, , \, Z_p
</span></p>
<ul>
<li><span class="math inline">Y_i</span> is the conditional distribution</li>
</ul>
<p><span class="math display">
Y | Z_1 = z_{i1} \,, \,\, \ldots \,, \,\, Z_p = z_{ip}
</span></p>
<ul>
<li>The errors <span class="math inline">\varepsilon_i</span> are random variables</li>
</ul>
</section>
<section id="regression-assumptions-on-y_i" class="slide level2 smaller">
<h2>Regression assumptions on <span class="math inline">Y_i</span></h2>
<ol type="1">
<li><p><strong>Predictor is known:</strong> The values <span class="math inline">z_{i1}, \ldots, z_{ip}</span> are known</p></li>
<li><p><strong>Normality:</strong> The distribution of <span class="math inline">Y_i</span> is normal</p></li>
<li><p><strong>Linear mean:</strong> There are parameters <span class="math inline">\beta_1,\ldots,\beta_p</span> such that <span class="math display">
{\rm I\kern-.3em E}[Y_i] = \beta_1 z_{i1} + \ldots + \beta_p z_{ip}  
</span></p></li>
<li><p><strong>Homoscedasticity:</strong> There is a parameter <span class="math inline">\sigma^2</span> such that <span class="math display">
{\rm Var}[Y_i] = \sigma^2
</span></p></li>
<li><p><strong>Independence:</strong> rv <span class="math inline">Y_1 , \ldots , Y_n</span> are independent, and thus uncorrelated</p></li>
</ol>
<p><span class="math display">
{\rm Cor}(Y_i,Y_j) = 0 \qquad \forall \,\, i \neq j
</span></p>
</section>
<section id="equivalent-assumptions-on-varepsilon_i" class="slide level2 smaller">
<h2>Equivalent assumptions on <span class="math inline">\varepsilon_i</span></h2>
<ol type="1">
<li><p><strong>Predictor is known:</strong> The values <span class="math inline">z_{i1}, \ldots, z_{ip}</span> are known</p></li>
<li><p><strong>Normality:</strong> The distribution of <span class="math inline">\varepsilon_i</span> is normal</p></li>
<li><p><strong>Linear mean:</strong> The errors have zero mean <span class="math display">
{\rm I\kern-.3em E}[\varepsilon_i] = 0
</span></p></li>
<li><p><strong>Homoscedasticity:</strong> There is a parameter <span class="math inline">\sigma^2</span> such that <span class="math display">
{\rm Var}[\varepsilon_i] = \sigma^2
</span></p></li>
<li><p><strong>Independence:</strong> Errors <span class="math inline">\varepsilon_1 , \ldots , \varepsilon_n</span> are independent, and thus uncorrelated</p></li>
</ol>
<p><span class="math display">
{\rm Cor}(\varepsilon_i, \varepsilon_j) = 0 \qquad \forall \,\, i \neq j
</span></p>
</section>
<section id="extra-assumption-on-design-matrix" class="slide level2 smaller">
<h2>Extra assumption on design matrix</h2>
<ol start="6" type="1">
<li>The design matrix <span class="math inline">Z</span> is such that</li>
</ol>
<p><span class="math display">
Z^T Z  \, \text{ is invertible}
</span></p>
<ul>
<li>Assumptions 1-6 allowed us to estimate the parameters</li>
</ul>
<p><span class="math display">
\beta = (\beta_1, \ldots, \beta_p)
</span></p>
<ul>
<li>By maximizing the likelihood, we obtained the MLE</li>
</ul>
<p><span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p>
</section>
<section id="violation-of-regression-assumptions" class="slide level2 smaller">
<h2>Violation of Regression Assumptions</h2>
<h3 id="we-consider-3-scenarios">We consider 3 scenarios</h3>
<ol type="i">
<li><strong>Heteroscedasticity:</strong> The violation of Assumption 4 of homoscedasticity</li>
</ol>
<p><span class="math display">
{\rm Var}[\varepsilon_i] \neq {\rm Var}[\varepsilon_j] \qquad \text{ for some } \,\, i \neq j
</span></p>
<ol start="2" type="i">
<li><strong>Autocorrelation:</strong> The violation of Assumption 5 of no-correlation</li>
</ol>
<p><span class="math display">
{\rm Cor}( \varepsilon_i, \varepsilon_j ) \neq 0  \qquad \text{ for some } \,\, i \neq j
</span></p>
<ol start="3" type="i">
<li><strong>Multicollinearity:</strong> The violation of Assumption 6 of invertibilty of the matrix</li>
</ol>
<p><span class="math display">
Z^T Z
</span></p>
</section></section>
<section>
<section id="part-4-heteroscedasticity" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 4: <br>Heteroscedasticity</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="heteroscedasticity" class="slide level2 smaller">
<h2>Heteroscedasticity</h2>
<ul>
<li>The general linear regression model is</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \beta_2 z_{i2} + \ldots + \beta_p z_{ip} + \varepsilon_i
</span></p>
<ul>
<li>Consider Assumption 4
<ul>
<li><strong>Homoscedasticity:</strong> There is a parameter <span class="math inline">\sigma^2</span> such that <span class="math display">
  {\rm Var}[\varepsilon_i] = \sigma^2 \qquad \forall \,\, i
  </span></li>
</ul></li>
<li><strong>Heteroscedasticity:</strong> The violation of Assumption 4</li>
</ul>
<p><span class="math display">
{\rm Var}[\varepsilon_i] \neq {\rm Var}[\varepsilon_j] \qquad \text{ for some } \,\, i \neq j
</span></p>
</section>
<section id="why-is-homoscedasticity-important" class="slide level2 smaller">
<h2>Why is homoscedasticity important?</h2>
<ul>
<li><p>In Lectures 9-10 we presented 4 methods to assess linear models</p>
<ul>
<li>Coefficient <span class="math inline">R^2</span></li>
<li><span class="math inline">t</span>-tests for individual parameters significance</li>
<li><span class="math inline">F</span>-test for Overall Significance</li>
<li><span class="math inline">F</span>-test for Model Selection</li>
</ul></li>
<li><p>The above methods <strong>rely heavily</strong> on homoscedasticity</p></li>
</ul>
</section>
<section id="section-33" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>For example, the maximum likelihood estimation relied on the calculation <span class="math display">\begin{align*}
  L &amp; = \prod_{i=1}^n  f_{Y_i} (y_i)  
      = \prod_{i=1}^n \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(y_i - \hat y_i)^2}{2\sigma^2} \right) \\[15pts]
    &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{\sum_{i=1}^n(y_i- \hat y_i)^2}{2\sigma^2}      \right) \\[15pts]
    &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{ \mathop{\mathrm{RSS}}}{2\sigma^2}      \right)
  \end{align*}</span></p></li>
<li><p>The calculation is only possible thanks to homoscedasticity</p></li>
</ul>
<p><span class="math display">
{\rm Var}[Y_i] = \sigma^2 \qquad \forall \,\, i
</span></p>
</section>
<section id="section-34" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Suppose the calculation in previous slide holds</li>
</ul>
<p><span class="math display">
L = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{ \mathop{\mathrm{RSS}}}{2\sigma^2}      \right)
</span></p>
<ul>
<li>Then maximizing the likelihood is equivalent to solving</li>
</ul>
<p><span class="math display">
\min_{\beta} \ \mathop{\mathrm{RSS}}
</span></p>
<ul>
<li>The above has the closed form solution</li>
</ul>
<p><span class="math display">
\hat \beta = (Z^T Z)^{-1} Z^T y
</span></p>
</section>
<section id="section-35" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Without homoscedasticity we would have</li>
</ul>
<p><span class="math display">
L \neq \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{ \mathop{\mathrm{RSS}}}{2\sigma^2}      \right)
</span></p>
<ul>
<li><p>Therefore, <span class="math inline">\hat \beta</span> would no longer maximize the likelihood!</p></li>
<li><p>But <span class="math inline">\hat \beta</span> would still be an unbiased estimator for <span class="math inline">\beta</span></p></li>
</ul>
<p><span class="math display">
{\rm I\kern-.3em E}[\hat \beta ] = \beta
</span></p>
</section>
<section id="section-36" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>However, the quantity <span class="math display">
S^2 = \frac{ \mathop{\mathrm{RSS}}(\hat \beta) }{n-p}
</span> is not anymore unbiased estimator for the population variance <span class="math inline">\sigma^2</span> <span class="math display">
{\rm I\kern-.3em E}[S^2] \neq \sigma^2
</span></p></li>
<li><p>This is a problem because the estimated standard error for <span class="math inline">\beta_j</span> involves <span class="math inline">S^2</span> <span class="math display">
\mathop{\mathrm{e.s.e.}}(\beta_j) = \xi_{jj}^{1/2} \, S  
</span></p></li>
<li><p>Therefore <span class="math inline">\mathop{\mathrm{e.s.e.}}</span> become <strong>unreliable</strong></p></li>
</ul>
</section>
<section id="section-37" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Then, also t-statistic for significance of <span class="math inline">\beta_j</span> becomes unreliable</p></li>
<li><p>This is because the t-statistic depends on <span class="math inline">\mathop{\mathrm{e.s.e.}}</span></p></li>
</ul>
<p><span class="math display">
t = \frac{ \hat\beta_j - \beta_j }{ \mathop{\mathrm{e.s.e.}}}
</span></p>
<ul>
<li><strong>Without homoscedasticity the regression maths does not work!</strong>
<ul>
<li>t-tests for significance of <span class="math inline">\beta_j</span></li>
<li>confidence intervals for <span class="math inline">\beta_j</span></li>
<li><span class="math inline">F</span>-tests for Model Selection</li>
<li>They all break down and become unreliable!</li>
</ul></li>
</ul>
</section>
<section id="is-heteroscedastcity-a-serious-problem" class="slide level2 smaller">
<h2>Is heteroscedastcity a serious problem?</h2>
<ul>
<li><p>Heteroscedasticity in linear regression is no longer a big problem</p></li>
<li><p>This is thanks to 1980s research on <em>robust standard errors</em> (<a href="https://en.wikipedia.org/wiki/Heteroskedasticity-consistent_standard_errors">more info here</a>)</p></li>
<li><p>Moreover, heteroscedasticity only becomes a problem when it is <strong>severe</strong></p></li>
</ul>
</section>
<section id="how-to-detect-heteroscedasticity" class="slide level2 smaller">
<h2>How to detect Heteroscedasticity</h2>
<p>Heteroscedasticity is commonly present in real-world datasets. We should be able to detect it</p>
<ol type="1">
<li>Graphical methods
<ul>
<li>Simple, robust and informative</li>
</ul></li>
<li>Statistical tests (see <span class="citation" data-cites="gujarati_porter">[<a href="#/references" role="doc-biblioref" onclick="">2</a>]</span>)
<ul>
<li>Goldfeldt-Quant test</li>
<li>Whites test for heteroscedasticity</li>
</ul></li>
</ol>
<p><strong>We do not cover statistical tests, only Graphical methods</strong></p>
</section>
<section id="graphical-methods-for-heteroscedasticity" class="slide level2 smaller">
<h2>Graphical methods for Heteroscedasticity</h2>
<ul>
<li>They involve studying the model <strong>residuals</strong></li>
</ul>
<p><span class="math display">
\hat{\varepsilon}_i := y_i - \hat y_i
</span></p>
<ul>
<li><p>By definition, <span class="math inline">\hat{\varepsilon}_i</span> is sampled from the error <span class="math inline">\varepsilon_i</span></p></li>
<li><p>We have heteroscedasticity if</p></li>
</ul>
<p><span class="math display">
{\rm Var}[\varepsilon_i] \neq {\rm Var}[\varepsilon_j] \, \quad \, \text{ for some } \, i \neq j
</span></p>
<ul>
<li>Hence, under heteroscedasticity, the residuals <span class="math inline">\hat{\varepsilon}_i</span> have <strong>different variance</strong></li>
</ul>
</section>
<section id="first-method-histogram-of-residuals" class="slide level2 smaller">
<h2>First method: Histogram of residuals</h2>
<ul>
<li>Yes Heteroscedasticity:
<ul>
<li>Residuals <span class="math inline">\varepsilon_i</span> have different variance</li>
<li>Histogram of <span class="math inline">\hat{\varepsilon}_i</span> will display <strong>asymetric pattern</strong></li>
</ul></li>
<li>No Heteroscedasticity:
<ul>
<li>Homoscedasticity assumption holds</li>
<li>Residuals <span class="math inline">\varepsilon_i</span> have same variance, with <span class="math inline">\varepsilon_i \sim N(0, \sigma^2)</span></li>
<li>Histogram of <span class="math inline">\hat{\varepsilon}_i</span> will look like <strong>normal</strong> distribution <span class="math inline">N(0,\sigma^2)</span></li>
</ul></li>
</ul>
</section>
<section id="interpretation-of-histograms" class="slide level2 smaller">
<h2>Interpretation of Histograms</h2>
<h3 id="left-homoscedastic-qquadquadquad-right-heteroscedastic">Left: Homoscedastic <span class="math inline">\qquad\quad\quad</span> Right: Heteroscedastic</h3>
<div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-16-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-17-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="second-method-residual-graphs" class="slide level2 smaller">
<h2>Second method: Residual graphs</h2>
<ul>
<li>Residual graphs are plots of
<ul>
<li>Residuals <span class="math inline">\hat{\varepsilon}_i</span> against fitted values <span class="math inline">\hat{y}_i</span></li>
</ul></li>
<li>Important:
<ul>
<li>No Heteroscedasticity <span class="math inline">\implies</span> Plots will look <strong>random</strong></li>
<li>Yes Heteroscedasticity <span class="math inline">\implies</span> Plots will show certain <strong>patterns</strong></li>
</ul></li>
<li>Good reference is the book <span class="citation" data-cites="draper_smith">[<a href="#/references" role="doc-biblioref" onclick="">3</a>]</span></li>
</ul>
</section>
<section id="interepretation-of-residual-graphs" class="slide level2 smaller">
<h2>Interepretation of Residual Graphs</h2>
<div class="column" style="width:47%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-18-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<ul>
<li><strong>No systematic pattern:</strong>
<ul>
<li>Suggests no heteroscedasticity</li>
<li>Corresponds to constant variance</li>
<li>Homoscedasticity assumption holds</li>
</ul></li>
<li>Residuals resemble sample <span class="math inline">N(0,\sigma^2)</span>
<ul>
<li>About half residuals negative and half positive</li>
<li>Vertical spread is comparable</li>
</ul></li>
</ul>
</div></section>
<section id="interepretation-of-residual-graphs-1" class="slide level2 smaller">
<h2>Interepretation of Residual Graphs</h2>
<h3 id="patterns-implying-heteroscedasticity">Patterns implying Heteroscedasticity</h3>
<ol type="1">
<li>Funnelling out of residuals:
<ul>
<li>Residuals close to 0 for small <span class="math inline">\hat{y}_i</span> values, and more spread out for large <span class="math inline">\hat{y}_i</span></li>
</ul></li>
<li>Funnelling in of residuals
<ul>
<li>Residuals spread out for small <span class="math inline">\hat{y}_i</span> values, and close to 0 for large <span class="math inline">\hat{y}_i</span></li>
</ul></li>
<li>Linear residuals
<ul>
<li>Residuals are proportional to <span class="math inline">\hat y_i</span></li>
</ul></li>
<li>Quadratic residuals
<ul>
<li>Residuals are proportional to <span class="math inline">\hat{y}^2_i</span></li>
</ul></li>
</ol>
<p><strong>In these special cases we can transform the data to avoid heteroscedasticity</strong></p>
</section>
<section id="funnelling-out-and-funnelling-in-residuals" class="slide level2 smaller">
<h2>Funnelling Out and Funnelling In residuals</h2>
<div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-19-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-20-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="linear-and-quadratic-residuals" class="slide level2">
<h2>Linear and Quadratic residuals</h2>
<div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-21-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="width:48%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-22-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></section>
<section id="what-to-do-in-case-of-heteroscedasticity" class="slide level2 smaller">
<h2>What to do in case of Heteroscedasticity?</h2>
<p>Assume you fitted the model</p>
<p><span class="math display">
Y = \beta_1 + \beta_2 X_2 + \ldots + \beta_p X_p + \varepsilon
</span></p>
<p>If heteroscedasticity is detected, we can transform the data:</p>
<ol type="1">
<li>Remedial transformations for <span class="math inline">Y</span>
<ul>
<li>Transform the data <span class="math inline">Y</span></li>
</ul></li>
<li>Remedial transformations for <span class="math inline">X_i</span>
<ul>
<li>Divide through by a suitable power of <span class="math inline">X_i</span></li>
</ul></li>
</ol>
</section>
<section id="remedial-transformations-for-y" class="slide level2 smaller">
<h2>Remedial transformations for <span class="math inline">Y</span></h2>
<p>To try and reduce heteroscedasticity we can <strong>transform the data <span class="math inline">y</span></strong></p>
<ul>
<li>A tranformation which often helps is
<ul>
<li><span class="math inline">\, \log y</span></li>
</ul></li>
<li>For linear and quadratic patterns you can try
<ul>
<li><span class="math inline">\, y^2</span></li>
<li><span class="math inline">\, \sqrt{y}</span></li>
</ul></li>
</ul>
</section>
<section id="remedial-transformations-for-x" class="slide level2 smaller">
<h2>Remedial transformations for <span class="math inline">X</span></h2>
<p>Heteroscedasticity can also be associated with some of the <span class="math inline">X</span>-variables</p>
<ul>
<li>To detect it, plot the residuals <span class="math inline">\hat{\varepsilon}_i</span> against <span class="math inline">X</span></li>
</ul>
<p>The book <span class="citation" data-cites="gujarati_porter">[<a href="#/references" role="doc-biblioref" onclick="">2</a>]</span> discusses two cases</p>
<ol type="1">
<li><p>The error variance is proportional to <span class="math inline">X^2_i</span> <span class="math display">
{\rm Var}[\varepsilon_i] \, \approx \, \sigma^2 \, X^2_i
</span></p></li>
<li><p>The error variance is proportional to <span class="math inline">X_i</span> <span class="math display">
{\rm Var}[\varepsilon_i] \, \approx \, \sigma^2 \, X_i
</span> <strong>In each case, divide through by the square root of the offending <span class="math inline">X</span>-term</strong></p></li>
</ol>
</section>
<section id="error-variance-proportional-to-x_i2" class="slide level2 smaller">
<h2>Error variance proportional to <span class="math inline">X_i^2</span></h2>
<ul>
<li>For example, consider the model</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 + \beta_2 X_{i} + \varepsilon_i
</span></p>
<ul>
<li>Assume that error variance is proportional to <span class="math inline">X_i^2</span>, that is,</li>
</ul>
<p><span class="math display">
\varepsilon_i \,\, \text{ independent } \,\, N(0,\sigma^2 X_i^2)
</span></p>
<ul>
<li>Divide through by <span class="math inline">X_i</span></li>
</ul>
<p><span class="math display">\begin{equation} \tag{1}
\frac{Y_i}{X_i} = \frac{\beta_1}{X_i}+\beta_2+\frac{\varepsilon_i}{X_i}
\end{equation}</span></p>
</section>
<section id="section-38" class="slide level2 smaller">
<h2></h2>
<ul>
<li>Consider the substitutions</li>
</ul>
<p><span class="math display">
\widetilde{Y}_i = \frac{Y_i}{X_i} \,, \qquad \widetilde{X}_i = \frac{1}{X_i} \,, \qquad  \tilde{\varepsilon}_i = \frac{\varepsilon_i}{X_i}
</span></p>
<ul>
<li>The model in (1) is therefore equivalent to</li>
</ul>
<p><span class="math display">\begin{equation} \tag{2}
\widetilde{Y}_i = \beta_1 + \beta_2 \widetilde{X}_i + \tilde{\varepsilon}_i
\end{equation}</span></p>
<ul>
<li>By assumption, we have <span class="math inline">\varepsilon_i</span> independent and <span class="math inline">N(0,\sigma^2 X_i^2)</span>. Therefore,</li>
</ul>
<p><span class="math display">
\tilde{\varepsilon}_i \,\, \text{ iid } \,\, N(0,\sigma^2)
</span></p>
<ul>
<li>Thus, the model in (2) satisfies all the Regression Assumptions</li>
</ul>
</section>
<section id="section-39" class="slide level2 smaller">
<h2></h2>
<ul>
<li><p>Assume we now want to make predictions for the value <span class="math inline">x</span></p></li>
<li><p>First, fit the simple regression model in (2). This gives MLEs <span class="math inline">\hat{\beta}_1, \hat{\beta}_2</span></p></li>
<li><p>Recalling the substitution <span class="math inline">\widetilde{X} = 1 / X</span>, we define</p></li>
</ul>
<p><span class="math display">
\widetilde{x} = 1/x
</span></p>
<ul>
<li>The prediction of Model (2) for such value is</li>
</ul>
<p><span class="math display">
\widetilde{y} = \hat{\beta}_1 + \hat{\beta}_2 \widetilde{x}
</span></p>
<ul>
<li>Now, recall that <span class="math inline">\widetilde{Y} = Y / X</span>. Therefore, <span class="math inline">Y = \widetilde{Y}X</span>, and the prediction is</li>
</ul>
<p><span class="math display">
\hat{y} = \widetilde{y} \cdot x
</span></p>
</section>
<section id="error-variance-proportional-to-x_i" class="slide level2 smaller">
<h2>Error variance proportional to <span class="math inline">X_i</span></h2>
<ul>
<li>For example, consider the model</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 + \beta_2 X_{i} + \varepsilon_i
</span></p>
<ul>
<li>Assume error variance is proportional to <span class="math inline">X_i</span>, that is,</li>
</ul>
<p><span class="math display">
\varepsilon_i \,\, \text{ independent } \,\, N(0,\sigma^2 X_i)
</span></p>
<ul>
<li>Divide through by <span class="math inline">\sqrt{X_i}</span></li>
</ul>
<p><span class="math display">\begin{equation} \tag{3}
\frac{Y_i}{\sqrt{X_i}} = \frac{\beta_1}{\sqrt{X_i}}+\beta_2 \sqrt{X_i} + \frac{\varepsilon_i}{\sqrt{X_i}}
\end{equation}</span></p>
<ul>
<li>With suitable substitutions, we can fit simple regression to the model in (3)</li>
</ul>
</section>
<section id="analysis-of-regression-residuals-in-r" class="slide level2 smaller">
<h2>Analysis of regression residuals in R</h2>
<p>We need R commands to compute <strong>residuals</strong> and <strong>fitted values</strong></p>
<ol type="1">
<li>Fit linear model as usual</li>
</ol>
<div class="sourceCode" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear model</span></span>
<span id="cb48-2"><a aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(formula)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p>
<ol start="2" type="1">
<li>To obtain fitted values <span class="math inline">\hat y_i</span> and residual values <span class="math inline">\hat{\varepsilon}_i = y_i - \hat y_i</span></li>
</ol>
<div class="sourceCode" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute fitted values</span></span>
<span id="cb49-2"><a aria-hidden="true" tabindex="-1"></a>fitted.values <span class="ot">&lt;-</span> model<span class="sc">$</span>fitted</span>
<span id="cb49-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residual values</span></span>
<span id="cb49-5"><a aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> model<span class="sc">$</span>resid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="example-stock-vs-gold-prices" class="slide level2 smaller">
<h2>Example: Stock Vs Gold prices</h2>
<ul>
<li><p>The full code for the example is available here <a href="codes/heteroscedasticity.R">heteroscedasticity.R</a></p></li>
<li><p>Stock Vs Gold prices data is available here <a href="datasets/stock_gold.txt">stock_gold.txt</a></p></li>
<li><p>Read data into R and fit simple regression</p></li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset on Stock Vs Gold prices</span></span>
<span id="cb50-2"><a aria-hidden="true" tabindex="-1"></a>prices <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">file =</span> <span class="st">"stock_gold.txt"</span>,</span>
<span id="cb50-3"><a aria-hidden="true" tabindex="-1"></a>                    <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb50-4"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Store data-frame into 2 vectors</span></span>
<span id="cb50-6"><a aria-hidden="true" tabindex="-1"></a>stock.price <span class="ot">&lt;-</span> prices[ , <span class="dv">1</span>]</span>
<span id="cb50-7"><a aria-hidden="true" tabindex="-1"></a>gold.price <span class="ot">&lt;-</span> prices[ , <span class="dv">2</span>]</span>
<span id="cb50-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit regression model</span></span>
<span id="cb50-10"><a aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(gold.price <span class="sc">~</span> stock.price)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-40" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<p><strong>Scatter Plot:</strong> of <span class="math inline">y</span> against <span class="math inline">x</span>, with regression line</p>
<ul>
<li>Most points are below the line</li>
<li>Points under the line appear more distant</li>
<li>This means errors have different variance <span class="math inline">\implies</span> heteroscedasticity</li>
</ul>
</div>
<div class="columns" style="display: flex !important; height: 60%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="sourceCode" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb51-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(stock.price, </span>
<span id="cb51-3"><a aria-hidden="true" tabindex="-1"></a>     gold.price, </span>
<span id="cb51-4"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Stock Price"</span>, </span>
<span id="cb51-5"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Gold Price"</span>,</span>
<span id="cb51-6"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb51-7"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="dv">2</span>) </span>
<span id="cb51-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot regression line</span></span>
<span id="cb51-10"><a aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(model, </span>
<span id="cb51-11"><a aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">"red"</span>, </span>
<span id="cb51-12"><a aria-hidden="true" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-23-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-41" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<p><strong>Histogram of residuals:</strong> Confirms initial intuition of heteroscedasticity</p>
<ul>
<li>Residuals are not normally distributed</li>
<li>Residuals have different variance (skewed histogram)</li>
</ul>
</div>
<div class="columns" style="display: flex !important; height: 60%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="sourceCode" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals</span></span>
<span id="cb52-2"><a aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> model<span class="sc">$</span>resid</span>
<span id="cb52-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of residuals</span></span>
<span id="cb52-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(residuals,</span>
<span id="cb52-6"><a aria-hidden="true" tabindex="-1"></a><span class="at">xlab =</span> <span class="st">"Residuals"</span>,</span>
<span id="cb52-7"><a aria-hidden="true" tabindex="-1"></a><span class="at">ylab =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb52-8"><a aria-hidden="true" tabindex="-1"></a><span class="at">col =</span> <span class="st">"skyblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-24-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-42" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.93em">
<p><strong>Residual Graph:</strong> Plot residuals against fitted values</p>
<ul>
<li>Displays funnelling out pattern</li>
<li>We definitely have <strong>heteroscedasticity</strong></li>
</ul>
</div>
<div class="columns" style="display: flex !important; height: 65%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="sourceCode" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute fitted values</span></span>
<span id="cb53-2"><a aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">&lt;-</span> model<span class="sc">$</span>fitted</span>
<span id="cb53-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the residual graph</span></span>
<span id="cb53-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitted, residuals,</span>
<span id="cb53-6"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Fitted Values"</span>, </span>
<span id="cb53-7"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Residuals"</span>,</span>
<span id="cb53-8"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb53-9"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb53-10"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-11"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add y = 0 line for reference</span></span>
<span id="cb53-12"><a aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-25-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-43" class="slide level2 smaller">
<h2></h2>
<ul>
<li><strong>Remedial transformation:</strong> To try and reduce heteroscedasticity take
<ul>
<li><span class="math inline">\, \log y</span></li>
</ul></li>
<li>This means, we fit the model</li>
</ul>
<p><span class="math display">
\log Y_i = \alpha + \beta X_i + \varepsilon_i
</span></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Transform data via log(y)</span></span>
<span id="cb54-2"><a aria-hidden="true" tabindex="-1"></a>log.gold.price <span class="ot">&lt;-</span> <span class="fu">log</span>(gold.price)</span>
<span id="cb54-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model with log(y) data</span></span>
<span id="cb54-5"><a aria-hidden="true" tabindex="-1"></a>log.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.gold.price <span class="sc">~</span> stock.price)</span>
<span id="cb54-6"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-7"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals for log model</span></span>
<span id="cb54-8"><a aria-hidden="true" tabindex="-1"></a>log.residuals <span class="ot">&lt;-</span> log.model<span class="sc">$</span>resid</span>
<span id="cb54-9"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-10"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute fitted values for log model</span></span>
<span id="cb54-11"><a aria-hidden="true" tabindex="-1"></a>log.fitted <span class="ot">&lt;-</span> log.model<span class="sc">$</span>fitted</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section></section>
<section id="section-44" class="title-slide slide level1 smaller center">
<h1></h1>
<p>Heteroscedasticity has definitely reduced</p>
<ul>
<li>Left: Residual plot for original model</li>
<li>Right: Residual plot for <span class="math inline">\log y</span> data model</li>
</ul>
<div class="columns" style="display: flex !important; height: 50%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-26-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-27-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>

<section>
<section id="section-45" class="title-slide slide level1 smaller center">
<h1></h1>
<p>Heteroscedasticity has definitely reduced</p>
<ul>
<li>Left: Histogram of residuals for original model</li>
<li>Right: Histogram of residuals for <span class="math inline">\log y</span> data model</li>
</ul>
<div class="columns" style="display: flex !important; height: 50%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-28-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-29-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-46" class="slide level2 smaller">
<h2></h2>
<p><strong>Conclusion:</strong> The log model seems to better satisfy the Regression Assumptions<br>
(due to less heteroschedasticity)</p>
<ul>
<li>Predictions should be done using the second model</li>
</ul>
<p><span class="math display">
\log Y = \alpha + \beta X + \varepsilon
</span></p>
<ul>
<li><p>Given a data point <span class="math inline">x</span>, the log model predicts <span class="math display">
\widetilde{y} = \log y
</span></p></li>
<li><p>The actual prediction is <span class="math display">
y = e^{\widetilde{y}}
</span></p></li>
<li><p>How do we make predictions on new values?</p></li>
</ul>
</section>
<section id="predictions-for-linear-models" class="slide level2 smaller">
<h2>Predictions for linear models</h2>
<p>The function <code>predict</code> is used to make different types of predictions</p>
<p><span class="math display">
\text{predict(model, newdata = ..., interval = ..., level = ...)}
</span></p>
<ul>
<li><p><code>model</code> is the output of an <em>lm model</em></p></li>
<li><p>Predictors are given as argument in <code>newdata</code></p>
<ul>
<li>newdata has to be a data frame</li>
<li>names of predictors have to match those used in the model formula</li>
</ul></li>
<li><p>The optional argument <code>interval</code> requests a prediction confidence interval</p>
<ul>
<li>This is a confidence interval around the prediction value</li>
</ul></li>
<li><p>The optional argument <code>level</code> specifies the amplitude of the confidence interval</p>
<ul>
<li>Default in <span class="math inline">0.95</span>, which computes a <span class="math inline">95\%</span> prediction interval</li>
</ul></li>
</ul>
</section>
<section id="back-to-the-example-stock-vs-gold-prices" class="slide level2 smaller">
<h2>Back to the Example: Stock Vs Gold prices</h2>
<ul>
<li>We want to predict the price of <em>Gold</em> for the following stock prices</li>
</ul>
<table class="caption-top">
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Stock price</strong></td>
<td style="text-align: left;">1.2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">3.1</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">6</td>
</tr>
</tbody>
</table>
<ul>
<li>Predictions will be done with the logarithmic model</li>
</ul>
<p><span class="math display">
\log(Y) = \alpha + \beta X + \varepsilon
</span></p>
<ul>
<li><p>This is because the log model shows less heteroscedasticity</p></li>
<li><p>Recall that</p>
<ul>
<li><span class="math inline">X =</span> Stock Price, which is stored in <code>stock.price</code></li>
<li><span class="math inline">Y =</span> Gold Price, which is stored in <code>gold.price</code></li>
<li><span class="math inline">\log(Y)</span> is stored in <code>log.gold.price</code></li>
</ul></li>
</ul>
</section>
<section id="section-47" class="slide level2 smaller">
<h2></h2>
<div class="sourceCode" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit log model</span></span>
<span id="cb55-2"><a aria-hidden="true" tabindex="-1"></a>log.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.gold.price <span class="sc">~</span> stock.price)</span>
<span id="cb55-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataframe for predictors</span></span>
<span id="cb55-5"><a aria-hidden="true" tabindex="-1"></a>predictors <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">stock.price =</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="dv">2</span>, <span class="fl">3.1</span>, <span class="dv">4</span>, <span class="dv">6</span>))</span>
<span id="cb55-6"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb55-8"><a aria-hidden="true" tabindex="-1"></a>log.predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(log.model, predictors, <span class="at">inter =</span> <span class="st">"pred"</span>)</span>
<span id="cb55-9"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Print predictions</span></span>
<span id="cb55-11"><a aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(log.predictions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 3.396117 2.4684428 4.323791
2 3.132980 2.2263949 4.039564
3 2.771166 1.8732920 3.669039
4 2.475136 1.5665173 3.383755
5 1.817292 0.8310317 2.803553</code></pre>
</div>
</div>
<ul>
<li><p>These are predictions for the log model, that is, <span class="math inline">\widetilde{y} = \log y</span></p></li>
<li><p>We need to rescale to obtain the desired predictions <span class="math inline">y = e^{\widetilde{y}}</span></p></li>
</ul>
</section>
<section id="section-48" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.95em">
<ul>
<li>Predictions with log model are in vector <code>log.predictions</code></li>
</ul>
<div class="sourceCode" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Rescale log predictions</span></span>
<span id="cb57-2"><a aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">exp</span>(log.predictions)</span>
<span id="cb57-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(predictions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 29.84797 11.804051 75.47422
2 22.94223  9.266399 56.80158
3 15.97725  6.509691 39.21421
4 11.88332  4.789937 29.48125
5  6.15517  2.295686 16.50318</code></pre>
</div>
</div>
<p><strong>Reading the output:</strong> For example, the first line says that:</p>
<ul>
<li>For Stock Price of <span class="math inline">1.2</span>, the model predicts Gold Price of <span class="math inline">29.84797</span></li>
<li><span class="math inline">95\%</span> confidence interval for the predicted Gold Price is <span class="math inline">[11.804051, 75.47422]</span></li>
<li>When Stock Price is <span class="math inline">1.2</span>, the interval contains the true Gold Price <span class="math inline">95\%</span> of the times</li>
</ul>
</div>
</section></section>
<section>
<section id="part-5-autocorrelation" class="title-slide slide level1 center" data-background-color="#cc0164" data-visibility="uncounted">
<h1>Part 5: <br>Autocorrelation</h1>
<div class="footer">
<div color="#cc0164">

</div>
</div>
</section>
<section id="autocorrelation" class="slide level2 smaller">
<h2>Autocorrelation</h2>
<ul>
<li>The general linear regression model is</li>
</ul>
<p><span class="math display">
Y_i = \beta_1 z_{i1} + \beta_2 z_{i2} + \ldots + \beta_p z_{ip} + \varepsilon_i
</span></p>
<ul>
<li>Consider Assumption 5
<ul>
<li><strong>Independence:</strong> Errors <span class="math inline">\varepsilon_1, \ldots, \varepsilon_n</span> are independent, and thus uncorrelated <span class="math display">
  {\rm Cor}(\varepsilon_i , \varepsilon_j) = 0 \qquad \forall \,\, i \neq j
  </span></li>
</ul></li>
<li><strong>Autocorrelation:</strong> The violation of Assumption 5</li>
</ul>
<p><span class="math display">
{\rm Cor}(\varepsilon_i , \varepsilon_j) = 0 \qquad \text{ for some } \,\, i \neq j
</span></p>
</section>
<section id="why-is-independence-important" class="slide level2 smaller">
<h2>Why is independence important?</h2>
<ul>
<li><p>Recall the methods to assess linear models</p>
<ul>
<li>Coefficient <span class="math inline">R^2</span></li>
<li><span class="math inline">t</span>-tests for parameters significance</li>
<li><span class="math inline">F</span>-test for model selection</li>
</ul></li>
<li><p>The above methods <strong>rely heavily</strong> on independence</p></li>
</ul>
</section>
<section id="why-is-independence-important-1" class="slide level2 smaller">
<h2>Why is independence important?</h2>
<ul>
<li><p>Once again, let us consider the likelihood calculation <span class="math display">\begin{align*}
  L &amp; = f(y_1, \ldots, y_n) =  \prod_{i=1}^n  f_{Y_i} (y_i)  
       \\[15pts]
    &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{\sum_{i=1}^n(y_i- \hat y_i)^2}{2\sigma^2}      \right) \\[15pts]
    &amp; = \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{ \mathop{\mathrm{RSS}}}{2\sigma^2}      \right)
  \end{align*}</span></p></li>
<li><p>The second equality is only possible thanks to independence of</p></li>
</ul>
<p><span class="math display">
Y_1 , \ldots, Y_n
</span></p>
</section>
<section id="why-is-independence-important-2" class="slide level2 smaller">
<h2>Why is independence important?</h2>
<ul>
<li>If we have <strong>autocorrelation</strong> then</li>
</ul>
<p><span class="math display">
{\rm Cor}(\varepsilon_i,\varepsilon_j) \neq 0 \quad \text{ for some } \, i \neq j
</span></p>
<ul>
<li>In particualar we would have</li>
</ul>
<p><span class="math display">
\varepsilon_i \, \text{ and } \, \varepsilon_j \, \text{ dependent } \quad \implies \quad Y_i \, \text{ and } \, Y_j \, \text{ dependent }
</span></p>
<ul>
<li>Therefore the calculation in previous slide breaks down</li>
</ul>
<p><span class="math display">
L \neq \frac{1}{(2\pi \sigma^2)^{n/2}} \, \exp   \left(   -\frac{ \mathop{\mathrm{RSS}}}{2\sigma^2}      \right)
</span></p>
</section>
<section id="why-is-independence-important-3" class="slide level2 smaller">
<h2>Why is independence important?</h2>
<ul>
<li><p>In this case <span class="math inline">\hat \beta</span> does no longer maximize the likelihood!</p></li>
<li><p>As already seen, this implies that</p></li>
</ul>
<p><span class="math display">
\mathop{\mathrm{e.s.e.}}(\beta_j) \,\, \text{ is unreliable}
</span></p>
<ul>
<li><strong>Without independence, the regression maths does not work!</strong>
<ul>
<li>t-tests for significance of <span class="math inline">\beta_j</span></li>
<li>confidence intervals for <span class="math inline">\beta_j</span></li>
<li><span class="math inline">F</span>-tests for Model Selection</li>
<li>They all break down and become unreliable!</li>
</ul></li>
</ul>
</section>
<section id="causes-of-autocorrelation" class="slide level2 smaller">
<h2>Causes of Autocorrelation</h2>
<h3 id="time-series-data">Time-series data</h3>
<ul>
<li>Autocorrelation means that</li>
</ul>
<p><span class="math display">
{\rm Cor}(\varepsilon_i,\varepsilon_j) \neq 0 \quad \text{ for some } \, i \neq j
</span></p>
<ul>
<li><p>Autocorrelation if often unavoidable</p></li>
<li><p>Typically associated with <strong>time series data</strong></p>
<ul>
<li>Observations ordered wrt time or space are usually correlated</li>
<li>This is because observations taken close together may take similar values</li>
</ul></li>
</ul>
</section>
<section id="example-financial-data" class="slide level2 smaller">
<h2>Example: Financial data</h2>
<ul>
<li>Autocorrelation is especially likely for datasets in
<ul>
<li>Accounting</li>
<li>Finance</li>
<li>Economics</li>
</ul></li>
<li>Autocorrelation is likely if the data have been recorded over time
<ul>
<li>E.g. daily, weekly, monthly, quarterly, yearly</li>
</ul></li>
<li>Example: Datasetet on <em>Stock prices</em> and <em>Gold prices</em>
<ul>
<li>General linear regression model assumes uncorrelated errors</li>
<li>Not realistic to assume that price observations for say 2020 and 2021 would be independent</li>
</ul></li>
</ul>
</section>
<section id="causes-of-autocorrelation-1" class="slide level2 smaller">
<h2>Causes of Autocorrelation</h2>
<h3 id="inertia">Inertia</h3>
<ul>
<li><p>Economic time series tend to exhibit <strong>cyclical behaviour</strong></p></li>
<li><p>Examples: GNP, price indices, production figures, employment statistics etc.</p></li>
<li><p>These series tend to be quite slow moving</p>
<ul>
<li>Effect of inertia is that successive observations are highly correlated</li>
</ul></li>
</ul>
<p><strong>This is an extremely common phenomenon in financial and economic time series</strong></p>
</section>
<section id="causes-of-autocorrelation-2" class="slide level2 smaller">
<h2>Causes of Autocorrelation</h2>
<h3 id="cobweb-phenomenon">Cobweb Phenomenon</h3>
<ul>
<li><p>Characteristic of industries in which a large amount of time passes between</p>
<ul>
<li>the decision to produce something</li>
<li>and its arrival on the market</li>
</ul></li>
<li><p>Cobweb phenomenon is common with agricultural commodities</p></li>
<li><p>Economic agents (e.g.&nbsp;farmers) decide</p>
<ul>
<li>how many goods to supply to the market</li>
<li>based on previous year price</li>
</ul></li>
</ul>
</section>
<section id="causes-of-autocorrelation-3" class="slide level2 smaller">
<h2>Causes of Autocorrelation</h2>
<h3 id="cobweb-phenomenon-1">Cobweb Phenomenon</h3>
<ul>
<li><strong>Example:</strong> the amount of crops farmers supply to the market at time <span class="math inline">t</span> might be</li>
</ul>
<p><span class="math display">\begin{equation} \tag{3}
{\rm Supply}_t = \beta_1 + \beta_2 \, {\rm Price}_{t-1} + \varepsilon_t
\end{equation}</span></p>
<ul>
<li><p>Errors <span class="math inline">\varepsilon_t</span> in equation (3) are unlikely to be completely random and patternless</p></li>
<li><p>This is because</p>
<ol type="1">
<li>They represent actions of intelligent economic agents (e.g.&nbsp;farmers)</li>
<li>Price from previous year influences supply for current year</li>
</ol></li>
</ul>
<p><strong>Error terms are likely to be autocorrelated</strong></p>
</section>
<section id="causes-of-autocorrelation-4" class="slide level2 smaller">
<h2>Causes of Autocorrelation</h2>
<h3 id="data-manipulation">Data manipulation</h3>
<p><strong>Examples:</strong></p>
<ul>
<li><p>Quarterly data may smooth out the wild fluctuations in monthly sales figures</p></li>
<li><p>Low frequency economic survey data may be interpolated</p></li>
</ul>
<p><strong>However:</strong> Such data transformations may be inevitable</p>
<ul>
<li><p>In social sciences data quality may be variable</p></li>
<li><p>This may induce systematic patterns and autocorrelation</p></li>
</ul>
<p><strong>No magic solution  Autocorrelation is unavoidable and must be considered</strong></p>
</section>
<section id="how-to-detect-autocorrelation" class="slide level2 smaller">
<h2>How to detect Autocorrelation</h2>
<p>Autocorrelation is often unavoidable. We should be able to detect it:</p>
<ol type="1">
<li>Graphical methods
<ul>
<li>Simple, robust and informative</li>
</ul></li>
<li>Statistical tests
<ul>
<li>Runs test</li>
<li>Durbin-Watson test</li>
</ul></li>
</ol>
<p><strong>Graphical and statistical methods can be useful cross-check of each other!</strong></p>
</section>
<section id="graphical-methods-for-autocorrelation" class="slide level2 smaller">
<h2>Graphical methods for Autocorrelation</h2>
<ol type="1">
<li>Time-series plot of residuals:
<ul>
<li>Plot residuals <span class="math inline">\hat{\varepsilon}_t</span> over time</li>
</ul></li>
<li>Autocorrelation plot of residuals:
<ul>
<li>Plot residuals <span class="math inline">\hat{\varepsilon}_t</span> against lagged residuals <span class="math inline">\hat{\varepsilon}_{t-1}</span></li>
</ul></li>
</ol>
<p>Check to see if any evidence of a systematic pattern exists:</p>
<ul>
<li>No Autocorrelation: Plots will look <strong>random</strong></li>
<li>Yes Autocorrelation: Plots will show certain <strong>patterns</strong></li>
</ul>
</section>
<section id="example-stock-vs-gold-prices-1" class="slide level2 smaller">
<h2>Example: Stock Vs Gold prices</h2>
<ul>
<li><p>Code for this example is available here <a href="codes/autocorrelation.R">autocorrelation.R</a></p></li>
<li><p>Stock Vs Gold prices data is available here <a href="datasets/stock_gold.txt">stock_gold.txt</a></p></li>
<li><p>Read data into R and fit simple regression</p></li>
</ul>
<div class="sourceCode" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb59-2"><a aria-hidden="true" tabindex="-1"></a>prices <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">file =</span> <span class="st">"stock_gold.txt"</span>,</span>
<span id="cb59-3"><a aria-hidden="true" tabindex="-1"></a>                    <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb59-4"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-5"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Store data-frame into 2 vectors</span></span>
<span id="cb59-6"><a aria-hidden="true" tabindex="-1"></a>stock.price <span class="ot">&lt;-</span> prices[ , <span class="dv">1</span>]</span>
<span id="cb59-7"><a aria-hidden="true" tabindex="-1"></a>gold.price <span class="ot">&lt;-</span> prices[ , <span class="dv">2</span>]</span>
<span id="cb59-8"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-9"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Fit regression model</span></span>
<span id="cb59-10"><a aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(gold.price <span class="sc">~</span> stock.price)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-49" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.94em">
<p><strong>Time-series plot of residuals:</strong> Plot the residuals <span class="math inline">\hat{\varepsilon}_i</span></p>
<ul>
<li>Time series plot suggests some evidence for autocorrelation</li>
<li>Look for successive <em>runs</em> of residuals either side of line <span class="math inline">y = 0 \,</span> (see <span class="math inline">t = 15</span>)</li>
</ul>
</div>
<div class="columns" style="display: flex !important; height: 60%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="sourceCode" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals</span></span>
<span id="cb60-2"><a aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> model<span class="sc">$</span>resid</span>
<span id="cb60-3"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Time-series plot of residuals</span></span>
<span id="cb60-5"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(residuals,</span>
<span id="cb60-6"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Time"</span>, </span>
<span id="cb60-7"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Residuals"</span>,</span>
<span id="cb60-8"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb60-9"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="dv">2</span>)</span>
<span id="cb60-10"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-11"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Add line y = 0 for reference</span></span>
<span id="cb60-12"><a aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-32-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-50" class="slide level2 smaller">
<h2></h2>
<div class="columns" style="display: flex !important; height: 90%;">
<div class="column" style="display: flex; align-items: center;">
<div style="font-size: 0.94em">
<p><strong>Autocorrelation plot of residuals:</strong></p>
<ul>
<li>Want to plot <span class="math inline">\hat{\varepsilon}_t</span> against <span class="math inline">\hat{\varepsilon}_{t-1}</span></li>
<li>Shift <span class="math inline">\hat{\varepsilon}_t</span> by 1 to get <span class="math inline">\hat{\varepsilon}_{t-1}</span></li>
<li>Can only plot magenta pairs</li>
<li>We have 1 pair less than the actual number of residuals</li>
</ul>
</div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<p><img data-src="images/shifted_vectors.png" style="width:110.0%"> <img data-src="images/shifted_vectors_2.png" style="width:110.0%"></p>
</div></div>
</section>
<section id="section-51" class="slide level2 smaller">
<h2></h2>
<ul>
<li>We want to plot <span class="math inline">\hat{\varepsilon}_t</span> against <span class="math inline">\hat{\varepsilon}_{t-1}</span>
<ul>
<li>Residuals <span class="math inline">\hat{\varepsilon}_t</span> are stored in vector <span class="math inline">\,\, \texttt{residuals}</span></li>
<li>We need to create a shifted version of <span class="math inline">\,\, \texttt{residuals}</span></li>
<li>First compute the length of <span class="math inline">\,\, \texttt{residuals}</span></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Compute length of residuals</span></span>
<span id="cb61-2"><a aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(residuals)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 33</code></pre>
</div>
</div>
<ul>
<li>Need to generate the <span class="math inline">33-1</span> pairs for plotting</li>
</ul>
</section>
<section id="section-52" class="slide level2 smaller">
<h2></h2>
<ul>
<li><strong>Lag 0:</strong>
<ul>
<li>This is the original vector with no lag</li>
<li>Lose one observation from <span class="math inline">\,\, \texttt{residuals}</span>  the first observation</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a aria-hidden="true" tabindex="-1"></a>residuals.lag<span class="fl">.0</span> <span class="ot">&lt;-</span> residuals[<span class="dv">2</span><span class="sc">:</span><span class="dv">33</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong>Lag 1:</strong>
<ul>
<li>This is the original vector, shifted by 1</li>
<li>Lose one observation from <span class="math inline">\,\, \texttt{residuals}</span>  the last observation</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a aria-hidden="true" tabindex="-1"></a>residuals.lag<span class="fl">.1</span> <span class="ot">&lt;-</span> residuals[<span class="dv">1</span><span class="sc">:</span><span class="dv">32</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="section-53" class="slide level2 smaller">
<h2></h2>
<div style="font-size: 0.94em">
<p><strong>Autocorrelation plot of residuals:</strong> Plot <span class="math inline">\hat{\varepsilon}_t</span> against <span class="math inline">\hat{\varepsilon}_{t-1}</span></p>
<ul>
<li>Plot suggests positive autocorrelation of residuals</li>
<li>This means <span class="math inline">\, \hat{\varepsilon}_t \, \approx \, a + b \, \hat{\varepsilon}_{t-1} \,</span> with <span class="math inline">b &gt; 0</span></li>
</ul>
</div>
<div class="columns" style="display: flex !important; height: 60%;">
<div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="sourceCode" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Lag0 against Lag1 residuals</span></span>
<span id="cb65-2"><a aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(residuals.lag<span class="fl">.1</span>, </span>
<span id="cb65-4"><a aria-hidden="true" tabindex="-1"></a>     residuals.lag<span class="fl">.0</span>,</span>
<span id="cb65-5"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Residuals Lag 1"</span>, </span>
<span id="cb65-6"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Residuals Lag 0"</span>,</span>
<span id="cb65-7"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb65-8"><a aria-hidden="true" tabindex="-1"></a>     <span class="at">cex =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="display: flex; justify-content: center; align-items: center;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_10_files/figure-revealjs/unnamed-chunk-34-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
</section>
<section id="section-54" class="slide level2 smaller">
<h2></h2>
<p><strong>Conclusions:</strong> The dataset Gold Price vs Stock Price exhibits Autocorrelation</p>
<ul>
<li>Autocorrelation was detected by both graphical methods:
<ul>
<li>Time-series of residuals</li>
<li>Autocorrelation plot of residuals</li>
</ul></li>
<li>This was expected, given that the dataset represents a time-series of prices</li>
</ul>
</section>
<section id="statistical-tests-for-autocorrelation" class="slide level2 smaller">
<h2>Statistical tests for Autocorrelation</h2>
<ul>
<li>Runs test:
<ul>
<li>If Regression Assumptions are satisfied, the residuals are <span class="math inline">\varepsilon_i \sim N(0,\sigma^2)</span></li>
<li>This means residuals <span class="math inline">\hat{\varepsilon}_i</span> are equally likely to be positive or negative</li>
<li>The runs test uses this observation to formulate a test for autocorrelation</li>
</ul></li>
<li>Durbin-Watson test:
<ul>
<li>Test to see if residuals are AR(1) - Auto-regressive of order 1</li>
<li>This means testing if there exists a linear relation of the form <span class="math display">
  \hat{\varepsilon}_t = a + b \hat{\varepsilon}_{t-1} + \delta_t
  </span> where <span class="math inline">\delta_t \sim N(0,\sigma^2)</span> is an error term</li>
</ul></li>
</ul>
<p><strong>We do not cover these tests</strong></p>
</section>
<section id="what-to-do-in-case-of-autocorrelation" class="slide level2 smaller">
<h2>What to do in case of Autocorrelation?</h2>
<ul>
<li>Consider the simple regression model</li>
</ul>
<p><span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i
</span></p>
<ul>
<li>Suppose that autocorrelation occurs</li>
</ul>
<p><span class="math display">
{\rm Cor}(\hat{\varepsilon}_i, \hat{\varepsilon}_j ) \neq 0 \quad \text{ for some } \, i \neq j
</span></p>
<ul>
<li>Also, suppose that autocorrelation is Auto-Regressive of Order 1</li>
</ul>
<p><span class="math display">
\hat{\varepsilon}_t = a + b \, \hat{\varepsilon}_{t-1} + \delta_t \,, \qquad
\delta_t \,\, \text{ iid } \,\, N(0,\sigma^2)
</span></p>
<ul>
<li>Example: This is the case for dataset <em>Stock prices</em> Vs <em>Gold prices</em></li>
</ul>
</section>
<section id="section-55" class="slide level2 smaller">
<h2></h2>
<ul>
<li>In this case, predictions from the simple linear model are not reliable</li>
</ul>
<p><span class="math display">
Y_i = \alpha + \beta x_i + \varepsilon_i
</span></p>
<ul>
<li><p>Instead, substitute into the model the relation <span class="math inline">\hat{\varepsilon}_t = a + b \, \hat{\varepsilon}_{t-1} + \delta_t</span></p></li>
<li><p>We obtain the new linear model (up to relabelling coefficients)</p></li>
</ul>
<p><span class="math display">
Y_t = \alpha + \beta x_t + \rho \hat{\varepsilon}_{t-1} + \delta_t  \,, \qquad
\delta_t \,\, \text{ iid } \,\, N(0,\sigma^2)
</span></p>
<ul>
<li>The above is an <strong>Autoregressive linear Model</strong> of order 1<br>
(because time <span class="math inline">t-1</span> influences time <span class="math inline">t</span>)
<ul>
<li>These models couple regression with time-series analysis (ARIMA models)</li>
<li>Good reference is book by Shumway and Stoffer <span class="citation" data-cites="shumway">[<a href="#/references" role="doc-biblioref" onclick="">4</a>]</span></li>
</ul></li>
</ul>
<p><strong>You will see ARIMA models next year</strong></p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>

<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p><a href="../index.html">Homepage</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="../license.html">License</a> &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.silviofanzon.com/contact">Contact</a></p>
</div>
</div>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-drake_galileo" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Drake, Stillman, MacLachlan, James, Galileos discovery of the parabolic trajectory, Scientific American. 232 (1975) 102111. <a href="http://www.jstor.org/stable/24949756">http://www.jstor.org/stable/24949756</a>.</div>
</div>
<div id="ref-gujarati_porter" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Gujarati, D. N., Porter, D. C., Basic econometric, fifth edition, McGraw-Hill, 2009.</div>
</div>
<div id="ref-draper_smith" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Draper, N. R., Smith, H., Applied regression analysis, Wiley, 1998.</div>
</div>
<div id="ref-shumway" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Shumway, R. H., Stoffer, D. S., Time series analysis and its applications, fourth edition, Springer, 2017.</div>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>